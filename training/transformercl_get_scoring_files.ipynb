{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transformercl_get_scoring_files.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"rTwxgvLNSzDK"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0q-7RWqYrMbI"},"source":["# install transformers\n","!pip install pytorch_transformers\n","!pip install -r drive/MyDrive/transformers_cl/requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"usnOsVlpmIoA"},"source":["# Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\n","# !git clone https://github.com/NVIDIA/apex\n","# !cd apex\n","# !pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n","\n","# packages needed for running other scoring_functions\n","# !pip install fasttext\n","# !pip install gensim==3.8.3 \n","\n","# this is for calculating other difficulty criterion scores\n","# !python drive/MyDrive/transformers_cl/calculate_scoring_function.py \\\n","# --dataset_path drive/MyDrive/MSDialog/train.tsv \\\n","# --output_path drive/MyDrive/MSDialog/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u1xW73iHCLNl"},"source":["# after fine-tuning the BERT model and evaluate on the training dataset\n","# we can get a file containing predictions of labels\n","# for each training sample, we have one prediction for its relevant answer\n","# and one prediction for its irrelevant answer \n","# this code is calculating the difference between them \n","# and for generating scoring files based on bert predictions\n","import pandas as pd\n","seed = 42\n","common_path = \"drive/MyDrive/transformers_cl\"\n","task_name = \"ms_v2\"\n","model_name = \"bert\" \n","end = [\"6\"]\n","for i in end:\n","  path = common_path + '/' + task_name + '_' + model_name + '_' + str(i)\n","  df = pd.read_csv(path+\"/preds_run_cl__seed_\"+str(seed), names=[\"preds_run_\"+str(seed)])\n","  difs_df = []\n","  for i in range(len(df)):\n","    if i % 2 != 0:\n","      difs_df.append(df.values[i-1][0]-df.values[i][0])\n","  difs_df = pd.DataFrame(difs_df, columns = [\"preds_dif_run_\"+str(seed)])\n","  difs_df.to_csv(path + \"/preds_dif_c_values_3\", header=False, index=False)\t\t"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MPW4aiTbTCQd"},"source":["def read_scores_file(path):    \n","    with open(path,'r') as f:\n","        scores = [float(l.split(\"\\n\")[0]) for l in f.readlines()]\n","    return scores"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gp6Ydft-6dLD"},"source":["# Fine-tuning logs for generating prediction files"]},{"cell_type":"markdown","metadata":{"id":"E2skx_k4Izaf"},"source":["# -----------------------------------------------------------Mantis----------------------------------------------------"]},{"cell_type":"markdown","metadata":{"id":"X8er9aoWDqoG"},"source":["# 08-05 batch size = 8, logging_step = 1000, trained epoch = 1, map = 0.93"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k8eQad6-Vc4A","outputId":"650a0d44-a877-4319-e4a4-454cb0130cee"},"source":["# have generated 9 ns with bm25 sampler\n","# added fp16 to save memory, not sure if helpful, removed because don't bother making it work\n","# 8 hours 0.7 epoch\n","!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/transformer_rankers \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=8   \\\n","    --per_gpu_train_batch_size=8   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 1000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/05/2021 09:22:22 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/05/2021 09:22:22 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpdqhhvmm_\n","100% 433/433 [00:00<00:00, 557267.15B/s]\n","08/05/2021 09:22:22 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpdqhhvmm_ to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/05/2021 09:22:22 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/05/2021 09:22:22 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpdqhhvmm_\n","08/05/2021 09:22:22 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/05/2021 09:22:22 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/05/2021 09:22:23 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp82nlanl8\n","100% 231508/231508 [00:00<00:00, 941746.39B/s]\n","08/05/2021 09:22:23 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp82nlanl8 to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/05/2021 09:22:23 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/05/2021 09:22:23 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp82nlanl8\n","08/05/2021 09:22:23 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/05/2021 09:22:24 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmp60djy_5v\n","100% 440473133/440473133 [00:11<00:00, 39301474.77B/s]\n","08/05/2021 09:22:35 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp60djy_5v to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/05/2021 09:22:37 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/05/2021 09:22:37 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp60djy_5v\n","08/05/2021 09:22:37 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/05/2021 09:22:39 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/05/2021 09:22:39 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/05/2021 09:22:51 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/transformer_rankers', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=1000, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise=0.0, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","08/05/2021 09:22:51 - INFO - __main__ -   Creating features from dataset file at drive/MyDrive/transformer_rankers\n","08/05/2021 09:22:51 - INFO - utils_glue -   LOOKING AT drive/MyDrive/transformer_rankers/train.tsv\n","08/05/2021 09:23:02 - INFO - utils_glue -   Writing example 0 of 164544\n","08/05/2021 09:23:02 - INFO - utils_glue -   *** Example ***\n","08/05/2021 09:23:02 - INFO - utils_glue -   guid: train-0\n","08/05/2021 09:23:02 - INFO - utils_glue -   tokens: [CLS] im using windows 8 my system is : intel core ##2 ##du ##o t ##64 ##00 2 . 0 ghz 2 ##mb cache ##6 gb dd ##r ##3 103 ##3 mhz ram ##n ##vid ##ia 960 ##0 ##mg ##s gp ##uan ##d i have 500 gb hd ##d i love to play games so i prefer windows 8 for games but i would [SEP] u ##bu ##nt ##u ' s system requirements are quite modest according to the [ system requirements page ] ( https : / / help . u ##bu ##nt ##u . com / community / installation / system ##re ##qui ##rem ##ents ) . the la ##g that you experienced before might be due to the fact that your video card drivers [SEP]\n","08/05/2021 09:23:02 - INFO - utils_glue -   input_ids: 101 10047 2478 3645 1022 2026 2291 2003 1024 13420 4563 2475 8566 2080 1056 21084 8889 1016 1012 1014 29066 1016 14905 17053 2575 16351 20315 2099 2509 9800 2509 11413 8223 2078 17258 2401 26637 2692 24798 2015 14246 13860 2094 1045 2031 3156 16351 10751 2094 1045 2293 2000 2377 2399 2061 1045 9544 3645 1022 2005 2399 2021 1045 2052 102 1057 8569 3372 2226 1005 1055 2291 5918 2024 3243 10754 2429 2000 1996 1031 2291 5918 3931 1033 1006 16770 1024 1013 1013 2393 1012 1057 8569 3372 2226 1012 4012 1013 2451 1013 8272 1013 2291 2890 15549 28578 11187 1007 1012 1996 2474 2290 2008 2017 5281 2077 2453 2022 2349 2000 1996 2755 2008 2115 2678 4003 6853 102\n","08/05/2021 09:23:02 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 09:23:02 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 09:23:02 - INFO - utils_glue -   label: 1 (id = 1)\n","08/05/2021 09:23:02 - INFO - utils_glue -   *** Example ***\n","08/05/2021 09:23:02 - INFO - utils_glue -   guid: train-1\n","08/05/2021 09:23:02 - INFO - utils_glue -   tokens: [CLS] im using windows 8 my system is : intel core ##2 ##du ##o t ##64 ##00 2 . 0 ghz 2 ##mb cache ##6 gb dd ##r ##3 103 ##3 mhz ram ##n ##vid ##ia 960 ##0 ##mg ##s gp ##uan ##d i have 500 gb hd ##d i love to play games so i prefer windows 8 for games but i would [SEP] i get the impression you are new to u ##bu ##nt ##u . drivers are not installed by coa ##xing the operating system to look in a certain place and find them , the way windows has always been . in u ##bu ##nt ##u , and all versions of linux i ' ve ever used , there ' s a procedure [SEP]\n","08/05/2021 09:23:02 - INFO - utils_glue -   input_ids: 101 10047 2478 3645 1022 2026 2291 2003 1024 13420 4563 2475 8566 2080 1056 21084 8889 1016 1012 1014 29066 1016 14905 17053 2575 16351 20315 2099 2509 9800 2509 11413 8223 2078 17258 2401 26637 2692 24798 2015 14246 13860 2094 1045 2031 3156 16351 10751 2094 1045 2293 2000 2377 2399 2061 1045 9544 3645 1022 2005 2399 2021 1045 2052 102 1045 2131 1996 8605 2017 2024 2047 2000 1057 8569 3372 2226 1012 6853 2024 2025 5361 2011 28155 19612 1996 4082 2291 2000 2298 1999 1037 3056 2173 1998 2424 2068 1010 1996 2126 3645 2038 2467 2042 1012 1999 1057 8569 3372 2226 1010 1998 2035 4617 1997 11603 1045 1005 2310 2412 2109 1010 2045 1005 1055 1037 7709 102\n","08/05/2021 09:23:02 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 09:23:02 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 09:23:02 - INFO - utils_glue -   label: 0 (id = 0)\n","08/05/2021 09:23:02 - INFO - utils_glue -   *** Example ***\n","08/05/2021 09:23:02 - INFO - utils_glue -   guid: train-2\n","08/05/2021 09:23:02 - INFO - utils_glue -   tokens: [CLS] im using windows 8 my system is : intel core ##2 ##du ##o t ##64 ##00 2 . 0 ghz 2 ##mb cache ##6 gb dd ##r ##3 103 ##3 mhz ram ##n ##vid ##ia 960 ##0 ##mg ##s gp ##uan ##d i have 500 gb hd ##d i love to play games so i prefer windows 8 for games but i would [SEP] after installation , follow the steps on [ this guide ] ( http : / / www . how ##open ##so ##ur ##ce . com / 2012 / 10 / install - n ##vid ##ia - ge ##force - driver - in - u ##bu ##nt ##u - 12 - 10 - 12 - 04 - using - pp ##a / ) [SEP]\n","08/05/2021 09:23:02 - INFO - utils_glue -   input_ids: 101 10047 2478 3645 1022 2026 2291 2003 1024 13420 4563 2475 8566 2080 1056 21084 8889 1016 1012 1014 29066 1016 14905 17053 2575 16351 20315 2099 2509 9800 2509 11413 8223 2078 17258 2401 26637 2692 24798 2015 14246 13860 2094 1045 2031 3156 16351 10751 2094 1045 2293 2000 2377 2399 2061 1045 9544 3645 1022 2005 2399 2021 1045 2052 102 2044 8272 1010 3582 1996 4084 2006 1031 2023 5009 1033 1006 8299 1024 1013 1013 7479 1012 2129 26915 6499 3126 3401 1012 4012 1013 2262 1013 2184 1013 16500 1011 1050 17258 2401 1011 16216 14821 1011 4062 1011 1999 1011 1057 8569 3372 2226 1011 2260 1011 2184 1011 2260 1011 5840 1011 2478 1011 4903 2050 1013 1007 102\n","08/05/2021 09:23:02 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 09:23:02 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 09:23:02 - INFO - utils_glue -   label: 1 (id = 1)\n","08/05/2021 09:23:02 - INFO - utils_glue -   *** Example ***\n","08/05/2021 09:23:02 - INFO - utils_glue -   guid: train-3\n","08/05/2021 09:23:02 - INFO - utils_glue -   tokens: [CLS] im using windows 8 my system is : intel core ##2 ##du ##o t ##64 ##00 2 . 0 ghz 2 ##mb cache ##6 gb dd ##r ##3 103 ##3 mhz ram ##n ##vid ##ia 960 ##0 ##mg ##s gp ##uan ##d i have 500 gb hd ##d i love to play games so i prefer windows 8 for games but i would [SEP] u ##bu ##nt ##u ' s system requirements are quite modest according to the [ system requirements page ] ( https : / / help . u ##bu ##nt ##u . com / community / installation / system ##re ##qui ##rem ##ents ) . the la ##g that you experienced before might be due to the fact that your video card drivers [SEP]\n","08/05/2021 09:23:02 - INFO - utils_glue -   input_ids: 101 10047 2478 3645 1022 2026 2291 2003 1024 13420 4563 2475 8566 2080 1056 21084 8889 1016 1012 1014 29066 1016 14905 17053 2575 16351 20315 2099 2509 9800 2509 11413 8223 2078 17258 2401 26637 2692 24798 2015 14246 13860 2094 1045 2031 3156 16351 10751 2094 1045 2293 2000 2377 2399 2061 1045 9544 3645 1022 2005 2399 2021 1045 2052 102 1057 8569 3372 2226 1005 1055 2291 5918 2024 3243 10754 2429 2000 1996 1031 2291 5918 3931 1033 1006 16770 1024 1013 1013 2393 1012 1057 8569 3372 2226 1012 4012 1013 2451 1013 8272 1013 2291 2890 15549 28578 11187 1007 1012 1996 2474 2290 2008 2017 5281 2077 2453 2022 2349 2000 1996 2755 2008 2115 2678 4003 6853 102\n","08/05/2021 09:23:02 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 09:23:02 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 09:23:02 - INFO - utils_glue -   label: 0 (id = 0)\n","08/05/2021 09:23:02 - INFO - utils_glue -   *** Example ***\n","08/05/2021 09:23:02 - INFO - utils_glue -   guid: train-4\n","08/05/2021 09:23:02 - INFO - utils_glue -   tokens: [CLS] im using windows 8 my system is : intel core ##2 ##du ##o t ##64 ##00 2 . 0 ghz 2 ##mb cache ##6 gb dd ##r ##3 103 ##3 mhz ram ##n ##vid ##ia 960 ##0 ##mg ##s gp ##uan ##d i have 500 gb hd ##d i love to play games so i prefer windows 8 for games but i would l ##Ä± ##ke to use u ##bu ##nt ##u for my daily use i am [SEP] seems either gr ##ub is not installed or is not working . read on and try the steps [ here ] ( http : / / u ##bu ##nt ##uf ##orum ##s . org / show ##th ##rea ##d . php ? t = 217 ##6 ##27 [SEP]\n","08/05/2021 09:23:02 - INFO - utils_glue -   input_ids: 101 10047 2478 3645 1022 2026 2291 2003 1024 13420 4563 2475 8566 2080 1056 21084 8889 1016 1012 1014 29066 1016 14905 17053 2575 16351 20315 2099 2509 9800 2509 11413 8223 2078 17258 2401 26637 2692 24798 2015 14246 13860 2094 1045 2031 3156 16351 10751 2094 1045 2293 2000 2377 2399 2061 1045 9544 3645 1022 2005 2399 2021 1045 2052 1048 11722 3489 2000 2224 1057 8569 3372 2226 2005 2026 3679 2224 1045 2572 102 3849 2593 24665 12083 2003 2025 5361 2030 2003 2025 2551 1012 3191 2006 1998 3046 1996 4084 1031 2182 1033 1006 8299 1024 1013 1013 1057 8569 3372 16093 20527 2015 1012 8917 1013 2265 2705 16416 2094 1012 25718 1029 1056 1027 20335 2575 22907 102\n","08/05/2021 09:23:02 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 09:23:02 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 09:23:02 - INFO - utils_glue -   label: 1 (id = 1)\n","08/05/2021 09:24:11 - INFO - utils_glue -   Writing example 10000 of 164544\n","08/05/2021 09:25:37 - INFO - utils_glue -   Writing example 20000 of 164544\n","08/05/2021 09:27:05 - INFO - utils_glue -   Writing example 30000 of 164544\n","08/05/2021 09:28:33 - INFO - utils_glue -   Writing example 40000 of 164544\n","08/05/2021 09:29:54 - INFO - utils_glue -   Writing example 50000 of 164544\n","08/05/2021 09:31:24 - INFO - utils_glue -   Writing example 60000 of 164544\n","08/05/2021 09:32:48 - INFO - utils_glue -   Writing example 70000 of 164544\n","08/05/2021 09:34:15 - INFO - utils_glue -   Writing example 80000 of 164544\n","08/05/2021 09:36:03 - INFO - utils_glue -   Writing example 90000 of 164544\n","08/05/2021 09:38:08 - INFO - utils_glue -   Writing example 100000 of 164544\n","08/05/2021 09:40:01 - INFO - utils_glue -   Writing example 110000 of 164544\n","08/05/2021 09:41:59 - INFO - utils_glue -   Writing example 120000 of 164544\n","08/05/2021 09:43:50 - INFO - utils_glue -   Writing example 130000 of 164544\n","08/05/2021 09:45:47 - INFO - utils_glue -   Writing example 140000 of 164544\n","08/05/2021 09:47:48 - INFO - utils_glue -   Writing example 150000 of 164544\n","08/05/2021 09:49:46 - INFO - utils_glue -   Writing example 160000 of 164544\n","08/05/2021 09:50:34 - INFO - __main__ -   Saving features into cached file drive/MyDrive/transformer_rankers/cached_train_bert-base-uncased_128_mantis_10\n","08/05/2021 09:50:58 - INFO - __main__ -   ***** Running training *****\n","08/05/2021 09:50:58 - INFO - __main__ -     Num examples = 164544\n","08/05/2021 09:50:58 - INFO - __main__ -     Num Epochs = 1\n","08/05/2021 09:50:58 - INFO - __main__ -     Instantaneous batch size per GPU = 8\n","08/05/2021 09:50:58 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 8\n","08/05/2021 09:50:58 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/05/2021 09:50:58 - INFO - __main__ -     Total optimization steps = 20568\n","08/05/2021 09:50:58 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/05/2021 09:50:58 - INFO - __main__ -     data_loaders = [('all_random_batches', <torch.utils.data.dataloader.DataLoader object at 0x7f0d32ed09d0>)]\n","08/05/2021 09:50:58 - INFO - __main__ -   Starting epoch 1\n","08/05/2021 09:50:58 - INFO - __main__ -   Training with all_random_batches\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/05/2021 09:54:40 - INFO - __main__ -   Iter = 1000\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/05/2021 09:54:40 - INFO - __main__ -   lr = 1.9027615713730068e-05\n","08/05/2021 09:54:40 - INFO - __main__ -   loss = 0.5881358795911074\n","08/05/2021 09:54:40 - INFO - __main__ -   Creating features from dataset file at drive/MyDrive/transformer_rankers\n","08/05/2021 09:54:40 - INFO - utils_glue -   LOOKING AT drive/MyDrive/transformer_rankers/valid.tsv\n","08/05/2021 09:54:52 - INFO - utils_glue -   Writing example 0 of 180960\n","08/05/2021 09:54:52 - INFO - utils_glue -   *** Example ***\n","08/05/2021 09:54:52 - INFO - utils_glue -   guid: dev-0\n","08/05/2021 09:54:52 - INFO - utils_glue -   tokens: [CLS] you are right it didn ##ot , next test will be on pic ##32 , just to prove the concept . in all cases thanks a lot for the well written and improved answer : ) you deserve more than a silly bounty , i am keeping it open just to allow others to contribute ( only 95 views of the question so far ) by the way how did you draw these diagrams of clock ? [ [SEP] @ electrons great news ! ! so my morning guess was good . i was struggling with that to right now . you might put your findings in your question for others that might needed . not the source code but at least some gui ##dan ##c [SEP]\n","08/05/2021 09:54:52 - INFO - utils_glue -   input_ids: 101 2017 2024 2157 2009 2134 4140 1010 2279 3231 2097 2022 2006 27263 16703 1010 2074 2000 6011 1996 4145 1012 1999 2035 3572 4283 1037 2843 2005 1996 2092 2517 1998 5301 3437 1024 1007 2017 10107 2062 2084 1037 10021 17284 1010 1045 2572 4363 2009 2330 2074 2000 3499 2500 2000 9002 1006 2069 5345 5328 1997 1996 3160 2061 2521 1007 2011 1996 2126 2129 2106 2017 4009 2122 26309 1997 5119 1029 1031 102 1030 15057 2307 2739 999 999 2061 2026 2851 3984 2001 2204 1012 1045 2001 8084 2007 2008 2000 2157 2085 1012 2017 2453 2404 2115 9556 1999 2115 3160 2005 2500 2008 2453 2734 1012 2025 1996 3120 3642 2021 2012 2560 2070 26458 7847 2278 102\n","08/05/2021 09:54:52 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 09:54:52 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 09:54:52 - INFO - utils_glue -   label: 1 (id = 1)\n","08/05/2021 09:54:52 - INFO - utils_glue -   *** Example ***\n","08/05/2021 09:54:52 - INFO - utils_glue -   guid: dev-1\n","08/05/2021 09:54:52 - INFO - utils_glue -   tokens: [CLS] you are right it didn ##ot , next test will be on pic ##32 , just to prove the concept . in all cases thanks a lot for the well written and improved answer : ) you deserve more than a silly bounty , i am keeping it open just to allow others to contribute ( only 95 views of the question so far ) by the [SEP] @ electrons might not work with d ##ma because i see it uses sp ##i transfer done and i suppose it ' s related with sp ##i data ready that has half clock delay . you might need to write two words in the tx buffer before starting the tx d ##ma to have the buffer always f [SEP]\n","08/05/2021 09:54:52 - INFO - utils_glue -   input_ids: 101 2017 2024 2157 2009 2134 4140 1010 2279 3231 2097 2022 2006 27263 16703 1010 2074 2000 6011 1996 4145 1012 1999 2035 3572 4283 1037 2843 2005 1996 2092 2517 1998 5301 3437 1024 1007 2017 10107 2062 2084 1037 10021 17284 1010 1045 2572 4363 2009 2330 2074 2000 3499 2500 2000 9002 1006 2069 5345 5328 1997 1996 3160 2061 2521 1007 2011 1996 102 1030 15057 2453 2025 2147 2007 1040 2863 2138 1045 2156 2009 3594 11867 2072 4651 2589 1998 1045 6814 2009 1005 1055 3141 2007 11867 2072 2951 3201 2008 2038 2431 5119 8536 1012 2017 2453 2342 2000 4339 2048 2616 1999 1996 19067 17698 2077 3225 1996 19067 1040 2863 2000 2031 1996 17698 2467 1042 102\n","08/05/2021 09:54:52 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 09:54:52 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 09:54:52 - INFO - utils_glue -   label: 0 (id = 0)\n","08/05/2021 09:54:52 - INFO - utils_glue -   *** Example ***\n","08/05/2021 09:54:52 - INFO - utils_glue -   guid: dev-2\n","08/05/2021 09:54:52 - INFO - utils_glue -   tokens: [CLS] you are right it didn ##ot , next test will be on pic ##32 , just to prove the concept . in all cases thanks a lot for the well written and improved answer : ) you deserve more than a silly bounty , i am keeping it open just to allow others to contribute ( only 95 views of the question so [SEP] @ thomas , assuming you are using sp ##i interface built into your mc ##u , your program will be writing and reading sp ##i registers as atomic operation and you will not use lose any data , even if interrupted . ( you could also implement a sp ##i handler using interrupt ##s . ) the clock ##ing and writing and [SEP]\n","08/05/2021 09:54:52 - INFO - utils_glue -   input_ids: 101 2017 2024 2157 2009 2134 4140 1010 2279 3231 2097 2022 2006 27263 16703 1010 2074 2000 6011 1996 4145 1012 1999 2035 3572 4283 1037 2843 2005 1996 2092 2517 1998 5301 3437 1024 1007 2017 10107 2062 2084 1037 10021 17284 1010 1045 2572 4363 2009 2330 2074 2000 3499 2500 2000 9002 1006 2069 5345 5328 1997 1996 3160 2061 102 1030 2726 1010 10262 2017 2024 2478 11867 2072 8278 2328 2046 2115 11338 2226 1010 2115 2565 2097 2022 3015 1998 3752 11867 2072 18687 2004 9593 3169 1998 2017 2097 2025 2224 4558 2151 2951 1010 2130 2065 7153 1012 1006 2017 2071 2036 10408 1037 11867 2072 28213 2478 17938 2015 1012 1007 1996 5119 2075 1998 3015 1998 102\n","08/05/2021 09:54:52 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 09:54:52 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 09:54:52 - INFO - utils_glue -   label: 0 (id = 0)\n","08/05/2021 09:54:52 - INFO - utils_glue -   *** Example ***\n","08/05/2021 09:54:52 - INFO - utils_glue -   guid: dev-3\n","08/05/2021 09:54:52 - INFO - utils_glue -   tokens: [CLS] you are right it didn ##ot , next test will be on pic ##32 , just to prove the concept . in all cases thanks a lot for the well written and improved answer : ) you deserve more than a silly bounty , i am keeping it open just to allow others to contribute ( only 95 views of the question so far ) by [SEP] @ electrons i think i was wrong , maybe not feeding the sp ##i tx register raise an error that prevents further readings . try first to feed two words then pool the sp ##i transfer complete for further writes . 100 % a break between words is not needed , after all it ' s a sl ##a [SEP]\n","08/05/2021 09:54:52 - INFO - utils_glue -   input_ids: 101 2017 2024 2157 2009 2134 4140 1010 2279 3231 2097 2022 2006 27263 16703 1010 2074 2000 6011 1996 4145 1012 1999 2035 3572 4283 1037 2843 2005 1996 2092 2517 1998 5301 3437 1024 1007 2017 10107 2062 2084 1037 10021 17284 1010 1045 2572 4363 2009 2330 2074 2000 3499 2500 2000 9002 1006 2069 5345 5328 1997 1996 3160 2061 2521 1007 2011 102 1030 15057 1045 2228 1045 2001 3308 1010 2672 2025 8521 1996 11867 2072 19067 4236 5333 2019 7561 2008 16263 2582 15324 1012 3046 2034 2000 5438 2048 2616 2059 4770 1996 11867 2072 4651 3143 2005 2582 7009 1012 2531 1003 1037 3338 2090 2616 2003 2025 2734 1010 2044 2035 2009 1005 1055 1037 22889 2050 102\n","08/05/2021 09:54:52 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 09:54:52 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 09:54:52 - INFO - utils_glue -   label: 0 (id = 0)\n","08/05/2021 09:54:52 - INFO - utils_glue -   *** Example ***\n","08/05/2021 09:54:52 - INFO - utils_glue -   guid: dev-4\n","08/05/2021 09:54:52 - INFO - utils_glue -   tokens: [CLS] you are right it didn ##ot , next test will be on pic ##32 , just to prove the concept . in all cases thanks a lot for the well written and improved answer : ) you deserve more than a silly bounty , i am keeping it open just to allow others to contribute ( only 95 views of the question so [SEP] @ user ##33 ##37 ##9 : there is no gui application that let you set up the sp ##i if that is what you are asking . in the data ##sh ##eet is says : sync ##hr ##ono ##us clock rates up to 1 / 2 of the device clock frequency and the max clock frequency is 32 ##m ##h ##z so [SEP]\n","08/05/2021 09:54:52 - INFO - utils_glue -   input_ids: 101 2017 2024 2157 2009 2134 4140 1010 2279 3231 2097 2022 2006 27263 16703 1010 2074 2000 6011 1996 4145 1012 1999 2035 3572 4283 1037 2843 2005 1996 2092 2517 1998 5301 3437 1024 1007 2017 10107 2062 2084 1037 10021 17284 1010 1045 2572 4363 2009 2330 2074 2000 3499 2500 2000 9002 1006 2069 5345 5328 1997 1996 3160 2061 102 1030 5310 22394 24434 2683 1024 2045 2003 2053 26458 4646 2008 2292 2017 2275 2039 1996 11867 2072 2065 2008 2003 2054 2017 2024 4851 1012 1999 1996 2951 4095 15558 2003 2758 1024 26351 8093 17175 2271 5119 6165 2039 2000 1015 1013 1016 1997 1996 5080 5119 6075 1998 1996 4098 5119 6075 2003 3590 2213 2232 2480 2061 102\n","08/05/2021 09:54:52 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 09:54:52 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 09:54:52 - INFO - utils_glue -   label: 0 (id = 0)\n","08/05/2021 09:56:10 - INFO - utils_glue -   Writing example 10000 of 180960\n","08/05/2021 09:57:43 - INFO - utils_glue -   Writing example 20000 of 180960\n","08/05/2021 09:59:19 - INFO - utils_glue -   Writing example 30000 of 180960\n","08/05/2021 10:00:56 - INFO - utils_glue -   Writing example 40000 of 180960\n","08/05/2021 10:02:25 - INFO - utils_glue -   Writing example 50000 of 180960\n","08/05/2021 10:04:01 - INFO - utils_glue -   Writing example 60000 of 180960\n","08/05/2021 10:05:39 - INFO - utils_glue -   Writing example 70000 of 180960\n","08/05/2021 10:07:20 - INFO - utils_glue -   Writing example 80000 of 180960\n","08/05/2021 10:09:26 - INFO - utils_glue -   Writing example 90000 of 180960\n","08/05/2021 10:11:43 - INFO - utils_glue -   Writing example 100000 of 180960\n","08/05/2021 10:13:42 - INFO - utils_glue -   Writing example 110000 of 180960\n","08/05/2021 10:16:00 - INFO - utils_glue -   Writing example 120000 of 180960\n","08/05/2021 10:18:09 - INFO - utils_glue -   Writing example 130000 of 180960\n","08/05/2021 10:20:09 - INFO - utils_glue -   Writing example 140000 of 180960\n","08/05/2021 10:22:15 - INFO - utils_glue -   Writing example 150000 of 180960\n","08/05/2021 10:24:22 - INFO - utils_glue -   Writing example 160000 of 180960\n","08/05/2021 10:26:32 - INFO - utils_glue -   Writing example 170000 of 180960\n","08/05/2021 10:28:36 - INFO - utils_glue -   Writing example 180000 of 180960\n","08/05/2021 10:28:46 - INFO - __main__ -   Saving features into cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/05/2021 10:29:12 - INFO - __main__ -   ***** Running evaluation  *****\n","08/05/2021 10:29:12 - INFO - __main__ -     Num examples = 180960\n","08/05/2021 10:29:12 - INFO - __main__ -     Batch size = 8\n","08/05/2021 10:55:31 - INFO - __main__ -   ***** Eval results  *****\n","08/05/2021 10:55:31 - INFO - __main__ -     map = 0.6684099265995962\n","08/05/2021 10:55:31 - INFO - __main__ -     ndcg = 0.7480736108918342\n","08/05/2021 10:55:33 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/checkpoint-best_run_cl__seed_42\n","08/05/2021 10:59:26 - INFO - __main__ -   Iter = 2000\n","08/05/2021 10:59:26 - INFO - __main__ -   lr = 1.8055231427460135e-05\n","08/05/2021 10:59:26 - INFO - __main__ -   loss = 0.5410367204025388\n","08/05/2021 10:59:26 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/05/2021 10:59:43 - INFO - __main__ -   ***** Running evaluation  *****\n","08/05/2021 10:59:43 - INFO - __main__ -     Num examples = 180960\n","08/05/2021 10:59:43 - INFO - __main__ -     Batch size = 8\n","08/05/2021 11:26:22 - INFO - __main__ -   ***** Eval results  *****\n","08/05/2021 11:26:22 - INFO - __main__ -     map = 0.6922392302780364\n","08/05/2021 11:26:22 - INFO - __main__ -     ndcg = 0.7665165966471473\n","08/05/2021 11:26:24 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/checkpoint-best_run_cl__seed_42\n","08/05/2021 11:30:17 - INFO - __main__ -   Iter = 3000\n","08/05/2021 11:30:17 - INFO - __main__ -   lr = 1.70828471411902e-05\n","08/05/2021 11:30:17 - INFO - __main__ -   loss = 0.5453529948107898\n","08/05/2021 11:30:17 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/05/2021 11:30:34 - INFO - __main__ -   ***** Running evaluation  *****\n","08/05/2021 11:30:34 - INFO - __main__ -     Num examples = 180960\n","08/05/2021 11:30:34 - INFO - __main__ -     Batch size = 8\n","08/05/2021 11:57:18 - INFO - __main__ -   ***** Eval results  *****\n","08/05/2021 11:57:18 - INFO - __main__ -     map = 0.6881504989263757\n","08/05/2021 11:57:18 - INFO - __main__ -     ndcg = 0.7632510180188748\n","08/05/2021 12:01:11 - INFO - __main__ -   Iter = 4000\n","08/05/2021 12:01:11 - INFO - __main__ -   lr = 1.6110462854920264e-05\n","08/05/2021 12:01:11 - INFO - __main__ -   loss = 0.5316106058508158\n","08/05/2021 12:01:11 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/05/2021 12:01:28 - INFO - __main__ -   ***** Running evaluation  *****\n","08/05/2021 12:01:28 - INFO - __main__ -     Num examples = 180960\n","08/05/2021 12:01:28 - INFO - __main__ -     Batch size = 8\n","08/05/2021 12:28:09 - INFO - __main__ -   ***** Eval results  *****\n","08/05/2021 12:28:09 - INFO - __main__ -     map = 0.6984899758606793\n","08/05/2021 12:28:09 - INFO - __main__ -     ndcg = 0.7711809595678915\n","08/05/2021 12:28:11 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/checkpoint-best_run_cl__seed_42\n","08/05/2021 12:32:04 - INFO - __main__ -   Iter = 5000\n","08/05/2021 12:32:04 - INFO - __main__ -   lr = 1.5138078568650333e-05\n","08/05/2021 12:32:04 - INFO - __main__ -   loss = 0.5276273206993938\n","08/05/2021 12:32:04 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/05/2021 12:32:21 - INFO - __main__ -   ***** Running evaluation  *****\n","08/05/2021 12:32:21 - INFO - __main__ -     Num examples = 180960\n","08/05/2021 12:32:21 - INFO - __main__ -     Batch size = 8\n","08/05/2021 12:59:04 - INFO - __main__ -   ***** Eval results  *****\n","08/05/2021 12:59:04 - INFO - __main__ -     map = 0.6968293878854371\n","08/05/2021 12:59:04 - INFO - __main__ -     ndcg = 0.7696535389040438\n","08/05/2021 12:59:06 - INFO - __main__ -   Saving model checkpoint to drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/checkpoint-5000\n","08/05/2021 13:02:59 - INFO - __main__ -   Iter = 6000\n","08/05/2021 13:02:59 - INFO - __main__ -   lr = 1.4165694282380397e-05\n","08/05/2021 13:02:59 - INFO - __main__ -   loss = 0.5173596032708884\n","08/05/2021 13:02:59 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/05/2021 13:03:17 - INFO - __main__ -   ***** Running evaluation  *****\n","08/05/2021 13:03:17 - INFO - __main__ -     Num examples = 180960\n","08/05/2021 13:03:17 - INFO - __main__ -     Batch size = 8\n","08/05/2021 13:30:01 - INFO - __main__ -   ***** Eval results  *****\n","08/05/2021 13:30:01 - INFO - __main__ -     map = 0.7084017295763131\n","08/05/2021 13:30:01 - INFO - __main__ -     ndcg = 0.7783178527110941\n","08/05/2021 13:30:03 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/checkpoint-best_run_cl__seed_42\n","08/05/2021 13:33:57 - INFO - __main__ -   Iter = 7000\n","08/05/2021 13:33:57 - INFO - __main__ -   lr = 1.3193309996110464e-05\n","08/05/2021 13:33:57 - INFO - __main__ -   loss = 0.502302540294826\n","08/05/2021 13:33:57 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/05/2021 13:34:15 - INFO - __main__ -   ***** Running evaluation  *****\n","08/05/2021 13:34:15 - INFO - __main__ -     Num examples = 180960\n","08/05/2021 13:34:15 - INFO - __main__ -     Batch size = 8\n","08/05/2021 14:00:58 - INFO - __main__ -   ***** Eval results  *****\n","08/05/2021 14:00:58 - INFO - __main__ -     map = 0.7039847006441976\n","08/05/2021 14:00:58 - INFO - __main__ -     ndcg = 0.7753812715262222\n","08/05/2021 14:04:52 - INFO - __main__ -   Iter = 8000\n","08/05/2021 14:04:52 - INFO - __main__ -   lr = 1.222092570984053e-05\n","08/05/2021 14:04:52 - INFO - __main__ -   loss = 0.49456619606912133\n","08/05/2021 14:04:52 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/05/2021 14:05:09 - INFO - __main__ -   ***** Running evaluation  *****\n","08/05/2021 14:05:09 - INFO - __main__ -     Num examples = 180960\n","08/05/2021 14:05:09 - INFO - __main__ -     Batch size = 8\n","08/05/2021 14:31:52 - INFO - __main__ -   ***** Eval results  *****\n","08/05/2021 14:31:52 - INFO - __main__ -     map = 0.7113377024476323\n","08/05/2021 14:31:52 - INFO - __main__ -     ndcg = 0.7812545287319344\n","08/05/2021 14:31:54 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/checkpoint-best_run_cl__seed_42\n","08/05/2021 14:35:47 - INFO - __main__ -   Iter = 9000\n","08/05/2021 14:35:47 - INFO - __main__ -   lr = 1.1248541423570595e-05\n","08/05/2021 14:35:47 - INFO - __main__ -   loss = 0.484058710180223\n","08/05/2021 14:35:47 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/05/2021 14:36:05 - INFO - __main__ -   ***** Running evaluation  *****\n","08/05/2021 14:36:05 - INFO - __main__ -     Num examples = 180960\n","08/05/2021 14:36:05 - INFO - __main__ -     Batch size = 8\n","08/05/2021 15:02:49 - INFO - __main__ -   ***** Eval results  *****\n","08/05/2021 15:02:49 - INFO - __main__ -     map = 0.7133154261925975\n","08/05/2021 15:02:49 - INFO - __main__ -     ndcg = 0.7824319923992069\n","08/05/2021 15:02:50 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/checkpoint-best_run_cl__seed_42\n","08/05/2021 15:06:44 - INFO - __main__ -   Iter = 10000\n","08/05/2021 15:06:44 - INFO - __main__ -   lr = 1.0276157137300662e-05\n","08/05/2021 15:06:44 - INFO - __main__ -   loss = 0.4825124966390431\n","08/05/2021 15:06:44 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/05/2021 15:07:02 - INFO - __main__ -   ***** Running evaluation  *****\n","08/05/2021 15:07:02 - INFO - __main__ -     Num examples = 180960\n","08/05/2021 15:07:02 - INFO - __main__ -     Batch size = 8\n","08/05/2021 15:33:48 - INFO - __main__ -   ***** Eval results  *****\n","08/05/2021 15:33:48 - INFO - __main__ -     map = 0.711557890544975\n","08/05/2021 15:33:48 - INFO - __main__ -     ndcg = 0.781088834494346\n","08/05/2021 15:33:50 - INFO - __main__ -   Saving model checkpoint to drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/checkpoint-10000\n","08/05/2021 15:37:44 - INFO - __main__ -   Iter = 11000\n","08/05/2021 15:37:44 - INFO - __main__ -   lr = 9.303772851030728e-06\n","08/05/2021 15:37:44 - INFO - __main__ -   loss = 0.47939702866971495\n","08/05/2021 15:37:44 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/05/2021 15:38:02 - INFO - __main__ -   ***** Running evaluation  *****\n","08/05/2021 15:38:02 - INFO - __main__ -     Num examples = 180960\n","08/05/2021 15:38:02 - INFO - __main__ -     Batch size = 8\n","08/05/2021 16:04:46 - INFO - __main__ -   ***** Eval results  *****\n","08/05/2021 16:04:46 - INFO - __main__ -     map = 0.7137008485607781\n","08/05/2021 16:04:46 - INFO - __main__ -     ndcg = 0.7831002896536171\n","08/05/2021 16:04:48 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/checkpoint-best_run_cl__seed_42\n","08/05/2021 16:08:41 - INFO - __main__ -   Iter = 12000\n","08/05/2021 16:08:41 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/05/2021 16:08:41 - INFO - __main__ -   loss = 0.47755181904137134\n","08/05/2021 16:08:41 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/05/2021 16:08:58 - INFO - __main__ -   ***** Running evaluation  *****\n","08/05/2021 16:08:58 - INFO - __main__ -     Num examples = 180960\n","08/05/2021 16:08:58 - INFO - __main__ -     Batch size = 8\n","08/05/2021 16:35:41 - INFO - __main__ -   ***** Eval results  *****\n","08/05/2021 16:35:41 - INFO - __main__ -     map = 0.7138500528048098\n","08/05/2021 16:35:41 - INFO - __main__ -     ndcg = 0.782464395604773\n","08/05/2021 16:35:42 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/checkpoint-best_run_cl__seed_42\n","08/05/2021 16:39:36 - INFO - __main__ -   Iter = 13000\n","08/05/2021 16:39:36 - INFO - __main__ -   lr = 7.35900427849086e-06\n","08/05/2021 16:39:36 - INFO - __main__ -   loss = 0.4528183136284351\n","08/05/2021 16:39:36 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/05/2021 16:39:53 - INFO - __main__ -   ***** Running evaluation  *****\n","08/05/2021 16:39:53 - INFO - __main__ -     Num examples = 180960\n","08/05/2021 16:39:53 - INFO - __main__ -     Batch size = 8\n","08/05/2021 17:06:33 - INFO - __main__ -   ***** Eval results  *****\n","08/05/2021 17:06:33 - INFO - __main__ -     map = 0.717153575989799\n","08/05/2021 17:06:33 - INFO - __main__ -     ndcg = 0.7855563198607224\n","08/05/2021 17:06:35 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/checkpoint-best_run_cl__seed_42\n","08/05/2021 17:10:28 - INFO - __main__ -   Iter = 14000\n","08/05/2021 17:10:28 - INFO - __main__ -   lr = 6.386619992220926e-06\n","08/05/2021 17:10:28 - INFO - __main__ -   loss = 0.46409817643091084\n","08/05/2021 17:10:28 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/05/2021 17:10:45 - INFO - __main__ -   ***** Running evaluation  *****\n","08/05/2021 17:10:45 - INFO - __main__ -     Num examples = 180960\n","08/05/2021 17:10:45 - INFO - __main__ -     Batch size = 8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yP7ISZvSII7Y","executionInfo":{"status":"ok","timestamp":1628232703090,"user_tz":-120,"elapsed":1739527,"user":{"displayName":"Chen Qian","photoUrl":"","userId":"11245437508655380561"}},"outputId":"734bcc80-343c-44e6-9e31-06f28a312bc5"},"source":["!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/transformer_rankers \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=8   \\\n","    --per_gpu_train_batch_size=8   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 1000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/06/2021 06:22:47 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/06/2021 06:22:47 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmp1_a9f6uj\n","100% 433/433 [00:00<00:00, 391070.98B/s]\n","08/06/2021 06:22:47 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp1_a9f6uj to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/06/2021 06:22:47 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/06/2021 06:22:47 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp1_a9f6uj\n","08/06/2021 06:22:47 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/06/2021 06:22:47 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/06/2021 06:22:47 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmplzmqgf0o\n","100% 231508/231508 [00:00<00:00, 945241.04B/s]\n","08/06/2021 06:22:48 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmplzmqgf0o to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/06/2021 06:22:48 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/06/2021 06:22:48 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmplzmqgf0o\n","08/06/2021 06:22:48 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/06/2021 06:22:48 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmp5_oybbav\n","100% 440473133/440473133 [00:11<00:00, 38284121.38B/s]\n","08/06/2021 06:23:00 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp5_oybbav to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/06/2021 06:23:01 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/06/2021 06:23:01 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp5_oybbav\n","08/06/2021 06:23:01 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/06/2021 06:23:05 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/06/2021 06:23:05 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/06/2021 06:23:16 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/transformer_rankers', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=False, eval_all_checkpoints=True, eval_difficult=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=1000, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise=0.0, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","08/06/2021 06:23:24 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_train_bert-base-uncased_128_mantis_10\n","08/06/2021 06:23:48 - INFO - __main__ -   ***** Running evaluation best_run_cl__seed_42 *****\n","08/06/2021 06:23:48 - INFO - __main__ -     Num examples = 164544\n","08/06/2021 06:23:48 - INFO - __main__ -     Batch size = 2\n","08/06/2021 06:51:38 - INFO - __main__ -   ***** Eval results best_run_cl__seed_42 *****\n","08/06/2021 06:51:38 - INFO - __main__ -     map = 0.9323463632827693\n","08/06/2021 06:51:38 - INFO - __main__ -     ndcg = 0.9505779985304578\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iKnLoFeK6FgV"},"source":["# 08-05 batch size = 32, logging_step = 1000, trained epoch = 1, map = 0.93"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EEuHiRu16NnA","executionInfo":{"status":"ok","timestamp":1628176808782,"user_tz":-120,"elapsed":12964772,"user":{"displayName":"çæ¢¦çª","photoUrl":"","userId":"17110178610712270742"}},"outputId":"0d92c11f-2dda-4c6a-f04b-96da9c5fef2a"},"source":["# have generated 9 ns with bm25 sampler\n","# added fp16 to save memory, not sure if helpful, removed because don't bother making it work\n","# 3h30m\n","!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/transformer_rankers \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=32   \\\n","    --per_gpu_train_batch_size=32   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_10_bert_bm25_3/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 1000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/05/2021 11:44:08 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/05/2021 11:44:08 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpa8b04wor\n","100% 433/433 [00:00<00:00, 381701.06B/s]\n","08/05/2021 11:44:09 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpa8b04wor to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/05/2021 11:44:09 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/05/2021 11:44:09 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpa8b04wor\n","08/05/2021 11:44:09 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/05/2021 11:44:09 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/05/2021 11:44:09 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpetgqp1g2\n","100% 231508/231508 [00:00<00:00, 857783.25B/s]\n","08/05/2021 11:44:09 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpetgqp1g2 to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/05/2021 11:44:09 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/05/2021 11:44:09 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpetgqp1g2\n","08/05/2021 11:44:09 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/05/2021 11:44:10 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmp4vq142qg\n","100% 440473133/440473133 [00:12<00:00, 35629447.83B/s]\n","08/05/2021 11:44:22 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp4vq142qg to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/05/2021 11:44:24 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/05/2021 11:44:24 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp4vq142qg\n","08/05/2021 11:44:24 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/05/2021 11:44:27 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/05/2021 11:44:27 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/05/2021 11:44:39 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/transformer_rankers', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=1000, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise=0.0, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_3/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=32, per_gpu_train_batch_size=32, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","08/05/2021 11:44:39 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_train_bert-base-uncased_128_mantis_10\n","08/05/2021 11:44:59 - INFO - __main__ -   ***** Running training *****\n","08/05/2021 11:44:59 - INFO - __main__ -     Num examples = 164544\n","08/05/2021 11:44:59 - INFO - __main__ -     Num Epochs = 1\n","08/05/2021 11:44:59 - INFO - __main__ -     Instantaneous batch size per GPU = 32\n","08/05/2021 11:44:59 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32\n","08/05/2021 11:44:59 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/05/2021 11:44:59 - INFO - __main__ -     Total optimization steps = 5142\n","08/05/2021 11:44:59 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/05/2021 11:44:59 - INFO - __main__ -     data_loaders = [('all_random_batches', <torch.utils.data.dataloader.DataLoader object at 0x7fde573af310>)]\n","08/05/2021 11:44:59 - INFO - __main__ -   Starting epoch 1\n","08/05/2021 11:44:59 - INFO - __main__ -   Training with all_random_batches\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/05/2021 11:57:56 - INFO - __main__ -   Iter = 1000\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/05/2021 11:57:56 - INFO - __main__ -   lr = 1.6110462854920264e-05\n","08/05/2021 11:57:56 - INFO - __main__ -   loss = 0.5480994514524936\n","08/05/2021 11:57:56 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/05/2021 11:58:17 - INFO - __main__ -   ***** Running evaluation  *****\n","08/05/2021 11:58:17 - INFO - __main__ -     Num examples = 180960\n","08/05/2021 11:58:17 - INFO - __main__ -     Batch size = 32\n","08/05/2021 12:21:52 - INFO - __main__ -   ***** Eval results  *****\n","08/05/2021 12:21:52 - INFO - __main__ -     map = 0.6971363705738847\n","08/05/2021 12:21:52 - INFO - __main__ -     ndcg = 0.7702963073472167\n","08/05/2021 12:21:54 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_bm25_3/checkpoint-best_run_cl__seed_42\n","08/05/2021 12:34:55 - INFO - __main__ -   Iter = 2000\n","08/05/2021 12:34:55 - INFO - __main__ -   lr = 1.222092570984053e-05\n","08/05/2021 12:34:55 - INFO - __main__ -   loss = 0.5044776321947575\n","08/05/2021 12:34:55 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/05/2021 12:35:16 - INFO - __main__ -   ***** Running evaluation  *****\n","08/05/2021 12:35:16 - INFO - __main__ -     Num examples = 180960\n","08/05/2021 12:35:16 - INFO - __main__ -     Batch size = 32\n","08/05/2021 12:58:50 - INFO - __main__ -   ***** Eval results  *****\n","08/05/2021 12:58:50 - INFO - __main__ -     map = 0.7025516908060172\n","08/05/2021 12:58:50 - INFO - __main__ -     ndcg = 0.7743708227188757\n","08/05/2021 12:58:52 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_bm25_3/checkpoint-best_run_cl__seed_42\n","08/05/2021 13:11:53 - INFO - __main__ -   Iter = 3000\n","08/05/2021 13:11:53 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/05/2021 13:11:53 - INFO - __main__ -   loss = 0.48063795916736124\n","08/05/2021 13:11:53 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/05/2021 13:12:14 - INFO - __main__ -   ***** Running evaluation  *****\n","08/05/2021 13:12:14 - INFO - __main__ -     Num examples = 180960\n","08/05/2021 13:12:14 - INFO - __main__ -     Batch size = 32\n","08/05/2021 13:35:49 - INFO - __main__ -   ***** Eval results  *****\n","08/05/2021 13:35:49 - INFO - __main__ -     map = 0.7100582387759274\n","08/05/2021 13:35:49 - INFO - __main__ -     ndcg = 0.7804766841997133\n","08/05/2021 13:35:50 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_bm25_3/checkpoint-best_run_cl__seed_42\n","08/05/2021 13:48:52 - INFO - __main__ -   Iter = 4000\n","08/05/2021 13:48:52 - INFO - __main__ -   lr = 4.441851419681058e-06\n","08/05/2021 13:48:52 - INFO - __main__ -   loss = 0.4690999641567469\n","08/05/2021 13:48:52 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/05/2021 13:49:13 - INFO - __main__ -   ***** Running evaluation  *****\n","08/05/2021 13:49:13 - INFO - __main__ -     Num examples = 180960\n","08/05/2021 13:49:13 - INFO - __main__ -     Batch size = 32\n","08/05/2021 14:12:50 - INFO - __main__ -   ***** Eval results  *****\n","08/05/2021 14:12:50 - INFO - __main__ -     map = 0.7165615175852402\n","08/05/2021 14:12:50 - INFO - __main__ -     ndcg = 0.7850543072444378\n","08/05/2021 14:12:52 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_bm25_3/checkpoint-best_run_cl__seed_42\n","08/05/2021 14:25:54 - INFO - __main__ -   Iter = 5000\n","08/05/2021 14:25:54 - INFO - __main__ -   lr = 5.523142746013224e-07\n","08/05/2021 14:25:54 - INFO - __main__ -   loss = 0.4592566175162792\n","08/05/2021 14:25:54 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/05/2021 14:26:14 - INFO - __main__ -   ***** Running evaluation  *****\n","08/05/2021 14:26:14 - INFO - __main__ -     Num examples = 180960\n","08/05/2021 14:26:14 - INFO - __main__ -     Batch size = 32\n","08/05/2021 14:49:53 - INFO - __main__ -   ***** Eval results  *****\n","08/05/2021 14:49:53 - INFO - __main__ -     map = 0.71931381397978\n","08/05/2021 14:49:53 - INFO - __main__ -     ndcg = 0.7871427875588334\n","08/05/2021 14:49:55 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_bm25_3/checkpoint-best_run_cl__seed_42\n","08/05/2021 14:49:56 - INFO - __main__ -   Saving model checkpoint to drive/MyDrive/transformers_cl/mantis_10_bert_bm25_3/checkpoint-5000\n","08/05/2021 14:51:48 - INFO - __main__ -   Finished epoch with 5142 iterations.\n","08/05/2021 14:51:48 - INFO - __main__ -    global_step = 5143, average loss = 0.49135152055390635\n","08/05/2021 14:51:51 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_train_bert-base-uncased_128_mantis_10\n","08/05/2021 14:52:09 - INFO - __main__ -   ***** Running evaluation best_run_cl__seed_42 *****\n","08/05/2021 14:52:09 - INFO - __main__ -     Num examples = 164544\n","08/05/2021 14:52:09 - INFO - __main__ -     Batch size = 2\n","08/05/2021 15:19:51 - INFO - __main__ -   ***** Eval results best_run_cl__seed_42 *****\n","08/05/2021 15:19:51 - INFO - __main__ -     map = 0.9343275962660443\n","08/05/2021 15:19:51 - INFO - __main__ -     ndcg = 0.9513944462265117\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C092-OxFc9C1"},"source":["# 08-05 batch size = 64, logging_step = 1000, trained epoch = 1, map = 0.92"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-PLPOAjw652T","executionInfo":{"status":"ok","timestamp":1628168838580,"user_tz":-120,"elapsed":11020884,"user":{"displayName":"xy GG","photoUrl":"","userId":"06169222138223251748"}},"outputId":"66d7e54d-69af-457e-cc32-1973ccc56812"},"source":["# have generated 9 ns with bm25 sampler\n","# 3h3m\n","!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/transformer_rankers \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_10_bert_bm25_64/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 1000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/05/2021 10:03:42 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/05/2021 10:03:42 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmp8rmq56su\n","100% 433/433 [00:00<00:00, 422454.90B/s]\n","08/05/2021 10:03:43 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp8rmq56su to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/05/2021 10:03:43 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/05/2021 10:03:43 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp8rmq56su\n","08/05/2021 10:03:43 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/05/2021 10:03:43 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/05/2021 10:03:43 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpcrve6jp0\n","100% 231508/231508 [00:00<00:00, 858682.13B/s]\n","08/05/2021 10:03:43 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpcrve6jp0 to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/05/2021 10:03:43 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/05/2021 10:03:43 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpcrve6jp0\n","08/05/2021 10:03:43 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/05/2021 10:03:44 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpli5mircd\n","100% 440473133/440473133 [00:13<00:00, 33146120.11B/s]\n","08/05/2021 10:03:57 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpli5mircd to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/05/2021 10:03:59 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/05/2021 10:03:59 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpli5mircd\n","08/05/2021 10:03:59 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/05/2021 10:04:02 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/05/2021 10:04:02 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/05/2021 10:04:13 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/transformer_rankers', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=1000, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise=0.0, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_64/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","08/05/2021 10:04:13 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_train_bert-base-uncased_128_mantis_10\n","08/05/2021 10:04:35 - INFO - __main__ -   ***** Running training *****\n","08/05/2021 10:04:35 - INFO - __main__ -     Num examples = 164544\n","08/05/2021 10:04:35 - INFO - __main__ -     Num Epochs = 1\n","08/05/2021 10:04:35 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/05/2021 10:04:35 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/05/2021 10:04:35 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/05/2021 10:04:35 - INFO - __main__ -     Total optimization steps = 2571\n","08/05/2021 10:04:35 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/05/2021 10:04:35 - INFO - __main__ -     data_loaders = [('all_random_batches', <torch.utils.data.dataloader.DataLoader object at 0x7f8a83684f10>)]\n","08/05/2021 10:04:35 - INFO - __main__ -   Starting epoch 1\n","08/05/2021 10:04:35 - INFO - __main__ -   Training with all_random_batches\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/05/2021 10:31:26 - INFO - __main__ -   Iter = 1000\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/05/2021 10:31:26 - INFO - __main__ -   lr = 1.222092570984053e-05\n","08/05/2021 10:31:26 - INFO - __main__ -   loss = 0.5317195907831193\n","08/05/2021 10:31:26 - INFO - __main__ -   Creating features from dataset file at drive/MyDrive/transformer_rankers\n","08/05/2021 10:31:38 - INFO - utils_glue -   Writing example 0 of 180960\n","08/05/2021 10:31:38 - INFO - utils_glue -   *** Example ***\n","08/05/2021 10:31:38 - INFO - utils_glue -   guid: dev-0\n","08/05/2021 10:31:38 - INFO - utils_glue -   tokens: [CLS] you are right it didn ##ot , next test will be on pic ##32 , just to prove the concept . in all cases thanks a lot for the well written and improved answer : ) you deserve more than a silly bounty , i am keeping it open just to allow others to contribute ( only 95 views of the question so far ) by the way how did you draw these diagrams of clock ? [ [SEP] @ electrons great news ! ! so my morning guess was good . i was struggling with that to right now . you might put your findings in your question for others that might needed . not the source code but at least some gui ##dan ##c [SEP]\n","08/05/2021 10:31:38 - INFO - utils_glue -   input_ids: 101 2017 2024 2157 2009 2134 4140 1010 2279 3231 2097 2022 2006 27263 16703 1010 2074 2000 6011 1996 4145 1012 1999 2035 3572 4283 1037 2843 2005 1996 2092 2517 1998 5301 3437 1024 1007 2017 10107 2062 2084 1037 10021 17284 1010 1045 2572 4363 2009 2330 2074 2000 3499 2500 2000 9002 1006 2069 5345 5328 1997 1996 3160 2061 2521 1007 2011 1996 2126 2129 2106 2017 4009 2122 26309 1997 5119 1029 1031 102 1030 15057 2307 2739 999 999 2061 2026 2851 3984 2001 2204 1012 1045 2001 8084 2007 2008 2000 2157 2085 1012 2017 2453 2404 2115 9556 1999 2115 3160 2005 2500 2008 2453 2734 1012 2025 1996 3120 3642 2021 2012 2560 2070 26458 7847 2278 102\n","08/05/2021 10:31:38 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 10:31:38 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 10:31:38 - INFO - utils_glue -   label: 1 (id = 1)\n","08/05/2021 10:31:38 - INFO - utils_glue -   *** Example ***\n","08/05/2021 10:31:38 - INFO - utils_glue -   guid: dev-1\n","08/05/2021 10:31:38 - INFO - utils_glue -   tokens: [CLS] you are right it didn ##ot , next test will be on pic ##32 , just to prove the concept . in all cases thanks a lot for the well written and improved answer : ) you deserve more than a silly bounty , i am keeping it open just to allow others to contribute ( only 95 views of the question so far ) by the [SEP] @ electrons might not work with d ##ma because i see it uses sp ##i transfer done and i suppose it ' s related with sp ##i data ready that has half clock delay . you might need to write two words in the tx buffer before starting the tx d ##ma to have the buffer always f [SEP]\n","08/05/2021 10:31:38 - INFO - utils_glue -   input_ids: 101 2017 2024 2157 2009 2134 4140 1010 2279 3231 2097 2022 2006 27263 16703 1010 2074 2000 6011 1996 4145 1012 1999 2035 3572 4283 1037 2843 2005 1996 2092 2517 1998 5301 3437 1024 1007 2017 10107 2062 2084 1037 10021 17284 1010 1045 2572 4363 2009 2330 2074 2000 3499 2500 2000 9002 1006 2069 5345 5328 1997 1996 3160 2061 2521 1007 2011 1996 102 1030 15057 2453 2025 2147 2007 1040 2863 2138 1045 2156 2009 3594 11867 2072 4651 2589 1998 1045 6814 2009 1005 1055 3141 2007 11867 2072 2951 3201 2008 2038 2431 5119 8536 1012 2017 2453 2342 2000 4339 2048 2616 1999 1996 19067 17698 2077 3225 1996 19067 1040 2863 2000 2031 1996 17698 2467 1042 102\n","08/05/2021 10:31:38 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 10:31:38 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 10:31:38 - INFO - utils_glue -   label: 0 (id = 0)\n","08/05/2021 10:31:38 - INFO - utils_glue -   *** Example ***\n","08/05/2021 10:31:38 - INFO - utils_glue -   guid: dev-2\n","08/05/2021 10:31:38 - INFO - utils_glue -   tokens: [CLS] you are right it didn ##ot , next test will be on pic ##32 , just to prove the concept . in all cases thanks a lot for the well written and improved answer : ) you deserve more than a silly bounty , i am keeping it open just to allow others to contribute ( only 95 views of the question so [SEP] @ thomas , assuming you are using sp ##i interface built into your mc ##u , your program will be writing and reading sp ##i registers as atomic operation and you will not use lose any data , even if interrupted . ( you could also implement a sp ##i handler using interrupt ##s . ) the clock ##ing and writing and [SEP]\n","08/05/2021 10:31:38 - INFO - utils_glue -   input_ids: 101 2017 2024 2157 2009 2134 4140 1010 2279 3231 2097 2022 2006 27263 16703 1010 2074 2000 6011 1996 4145 1012 1999 2035 3572 4283 1037 2843 2005 1996 2092 2517 1998 5301 3437 1024 1007 2017 10107 2062 2084 1037 10021 17284 1010 1045 2572 4363 2009 2330 2074 2000 3499 2500 2000 9002 1006 2069 5345 5328 1997 1996 3160 2061 102 1030 2726 1010 10262 2017 2024 2478 11867 2072 8278 2328 2046 2115 11338 2226 1010 2115 2565 2097 2022 3015 1998 3752 11867 2072 18687 2004 9593 3169 1998 2017 2097 2025 2224 4558 2151 2951 1010 2130 2065 7153 1012 1006 2017 2071 2036 10408 1037 11867 2072 28213 2478 17938 2015 1012 1007 1996 5119 2075 1998 3015 1998 102\n","08/05/2021 10:31:38 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 10:31:38 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 10:31:38 - INFO - utils_glue -   label: 0 (id = 0)\n","08/05/2021 10:31:38 - INFO - utils_glue -   *** Example ***\n","08/05/2021 10:31:38 - INFO - utils_glue -   guid: dev-3\n","08/05/2021 10:31:38 - INFO - utils_glue -   tokens: [CLS] you are right it didn ##ot , next test will be on pic ##32 , just to prove the concept . in all cases thanks a lot for the well written and improved answer : ) you deserve more than a silly bounty , i am keeping it open just to allow others to contribute ( only 95 views of the question so far ) by [SEP] @ electrons i think i was wrong , maybe not feeding the sp ##i tx register raise an error that prevents further readings . try first to feed two words then pool the sp ##i transfer complete for further writes . 100 % a break between words is not needed , after all it ' s a sl ##a [SEP]\n","08/05/2021 10:31:38 - INFO - utils_glue -   input_ids: 101 2017 2024 2157 2009 2134 4140 1010 2279 3231 2097 2022 2006 27263 16703 1010 2074 2000 6011 1996 4145 1012 1999 2035 3572 4283 1037 2843 2005 1996 2092 2517 1998 5301 3437 1024 1007 2017 10107 2062 2084 1037 10021 17284 1010 1045 2572 4363 2009 2330 2074 2000 3499 2500 2000 9002 1006 2069 5345 5328 1997 1996 3160 2061 2521 1007 2011 102 1030 15057 1045 2228 1045 2001 3308 1010 2672 2025 8521 1996 11867 2072 19067 4236 5333 2019 7561 2008 16263 2582 15324 1012 3046 2034 2000 5438 2048 2616 2059 4770 1996 11867 2072 4651 3143 2005 2582 7009 1012 2531 1003 1037 3338 2090 2616 2003 2025 2734 1010 2044 2035 2009 1005 1055 1037 22889 2050 102\n","08/05/2021 10:31:38 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 10:31:38 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 10:31:38 - INFO - utils_glue -   label: 0 (id = 0)\n","08/05/2021 10:31:38 - INFO - utils_glue -   *** Example ***\n","08/05/2021 10:31:38 - INFO - utils_glue -   guid: dev-4\n","08/05/2021 10:31:38 - INFO - utils_glue -   tokens: [CLS] you are right it didn ##ot , next test will be on pic ##32 , just to prove the concept . in all cases thanks a lot for the well written and improved answer : ) you deserve more than a silly bounty , i am keeping it open just to allow others to contribute ( only 95 views of the question so [SEP] @ user ##33 ##37 ##9 : there is no gui application that let you set up the sp ##i if that is what you are asking . in the data ##sh ##eet is says : sync ##hr ##ono ##us clock rates up to 1 / 2 of the device clock frequency and the max clock frequency is 32 ##m ##h ##z so [SEP]\n","08/05/2021 10:31:38 - INFO - utils_glue -   input_ids: 101 2017 2024 2157 2009 2134 4140 1010 2279 3231 2097 2022 2006 27263 16703 1010 2074 2000 6011 1996 4145 1012 1999 2035 3572 4283 1037 2843 2005 1996 2092 2517 1998 5301 3437 1024 1007 2017 10107 2062 2084 1037 10021 17284 1010 1045 2572 4363 2009 2330 2074 2000 3499 2500 2000 9002 1006 2069 5345 5328 1997 1996 3160 2061 102 1030 5310 22394 24434 2683 1024 2045 2003 2053 26458 4646 2008 2292 2017 2275 2039 1996 11867 2072 2065 2008 2003 2054 2017 2024 4851 1012 1999 1996 2951 4095 15558 2003 2758 1024 26351 8093 17175 2271 5119 6165 2039 2000 1015 1013 1016 1997 1996 5080 5119 6075 1998 1996 4098 5119 6075 2003 3590 2213 2232 2480 2061 102\n","08/05/2021 10:31:38 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 10:31:38 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/05/2021 10:31:38 - INFO - utils_glue -   label: 0 (id = 0)\n","08/05/2021 10:32:57 - INFO - utils_glue -   Writing example 10000 of 180960\n","08/05/2021 10:34:30 - INFO - utils_glue -   Writing example 20000 of 180960\n","08/05/2021 10:36:07 - INFO - utils_glue -   Writing example 30000 of 180960\n","08/05/2021 10:37:44 - INFO - utils_glue -   Writing example 40000 of 180960\n","08/05/2021 10:39:14 - INFO - utils_glue -   Writing example 50000 of 180960\n","08/05/2021 10:40:48 - INFO - utils_glue -   Writing example 60000 of 180960\n","08/05/2021 10:42:28 - INFO - utils_glue -   Writing example 70000 of 180960\n","08/05/2021 10:44:08 - INFO - utils_glue -   Writing example 80000 of 180960\n","08/05/2021 10:46:14 - INFO - utils_glue -   Writing example 90000 of 180960\n","08/05/2021 10:48:32 - INFO - utils_glue -   Writing example 100000 of 180960\n","08/05/2021 10:50:32 - INFO - utils_glue -   Writing example 110000 of 180960\n","08/05/2021 10:52:51 - INFO - utils_glue -   Writing example 120000 of 180960\n","08/05/2021 10:54:59 - INFO - utils_glue -   Writing example 130000 of 180960\n","08/05/2021 10:56:59 - INFO - utils_glue -   Writing example 140000 of 180960\n","08/05/2021 10:59:05 - INFO - utils_glue -   Writing example 150000 of 180960\n","08/05/2021 11:01:13 - INFO - utils_glue -   Writing example 160000 of 180960\n","08/05/2021 11:03:24 - INFO - utils_glue -   Writing example 170000 of 180960\n","08/05/2021 11:05:28 - INFO - utils_glue -   Writing example 180000 of 180960\n","08/05/2021 11:05:39 - INFO - __main__ -   Saving features into cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/05/2021 11:06:08 - INFO - __main__ -   ***** Running evaluation  *****\n","08/05/2021 11:06:08 - INFO - __main__ -     Num examples = 180960\n","08/05/2021 11:06:08 - INFO - __main__ -     Batch size = 64\n","08/05/2021 11:31:14 - INFO - __main__ -   ***** Eval results  *****\n","08/05/2021 11:31:14 - INFO - __main__ -     map = 0.7041978276353429\n","08/05/2021 11:31:14 - INFO - __main__ -     ndcg = 0.7759315104667264\n","08/05/2021 11:31:16 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_bm25_64/checkpoint-best_run_cl__seed_42\n","08/05/2021 11:58:06 - INFO - __main__ -   Iter = 2000\n","08/05/2021 11:58:06 - INFO - __main__ -   lr = 4.441851419681058e-06\n","08/05/2021 11:58:06 - INFO - __main__ -   loss = 0.47874257200956344\n","08/05/2021 11:58:06 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/05/2021 11:58:23 - INFO - __main__ -   ***** Running evaluation  *****\n","08/05/2021 11:58:23 - INFO - __main__ -     Num examples = 180960\n","08/05/2021 11:58:23 - INFO - __main__ -     Batch size = 64\n","08/05/2021 12:23:41 - INFO - __main__ -   ***** Eval results  *****\n","08/05/2021 12:23:41 - INFO - __main__ -     map = 0.7175569361991915\n","08/05/2021 12:23:41 - INFO - __main__ -     ndcg = 0.7861626123389798\n","08/05/2021 12:23:43 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_bm25_64/checkpoint-best_run_cl__seed_42\n","08/05/2021 12:39:05 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/05/2021 12:39:05 - INFO - __main__ -    global_step = 2572, average loss = 0.49544971621078243\n","08/05/2021 12:39:08 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_train_bert-base-uncased_128_mantis_10\n","08/05/2021 12:39:27 - INFO - __main__ -   ***** Running evaluation best_run_cl__seed_42 *****\n","08/05/2021 12:39:27 - INFO - __main__ -     Num examples = 164544\n","08/05/2021 12:39:27 - INFO - __main__ -     Batch size = 2\n","08/05/2021 13:07:15 - INFO - __main__ -   ***** Eval results best_run_cl__seed_42 *****\n","08/05/2021 13:07:15 - INFO - __main__ -     map = 0.929964021781408\n","08/05/2021 13:07:15 - INFO - __main__ -     ndcg = 0.9486894024862811\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6XJJtxn_VLui"},"source":["# --------------------------failed trials-----------------------------"]},{"cell_type":"code","metadata":{"id":"Qa4Xg1A3S3Tq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ef6d7f7a-be12-4f17-fbee-ce3a08e49898"},"source":["# have generated 9 ns with random sampler, try again     \n","!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/transformer_rankers/mantis_random_9 \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=8   \\\n","    --per_gpu_train_batch_size=8   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_10_bert_valid_random/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 1000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/04/2021 16:52:07 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/04/2021 16:52:08 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpud79atmm\n","100% 433/433 [00:00<00:00, 389561.05B/s]\n","08/04/2021 16:52:08 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpud79atmm to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/04/2021 16:52:08 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/04/2021 16:52:08 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpud79atmm\n","08/04/2021 16:52:08 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/04/2021 16:52:08 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/04/2021 16:52:08 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpaoannua9\n","100% 231508/231508 [00:00<00:00, 933921.44B/s]\n","08/04/2021 16:52:09 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpaoannua9 to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/04/2021 16:52:09 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/04/2021 16:52:09 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpaoannua9\n","08/04/2021 16:52:09 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/04/2021 16:52:09 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpixye4z18\n","100% 440473133/440473133 [00:11<00:00, 38452940.64B/s]\n","08/04/2021 16:52:21 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpixye4z18 to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/04/2021 16:52:22 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/04/2021 16:52:22 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpixye4z18\n","08/04/2021 16:52:22 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/04/2021 16:52:26 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/04/2021 16:52:26 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/04/2021 16:52:37 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/transformer_rankers/mantis_random_9', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=1000, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise=0.0, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_10_bert_valid_random/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","08/04/2021 16:52:38 - INFO - __main__ -   Creating features from dataset file at drive/MyDrive/transformer_rankers/mantis_random_9\n","08/04/2021 16:52:38 - INFO - utils_glue -   LOOKING AT drive/MyDrive/transformer_rankers/mantis_random_9/train.tsv\n","08/04/2021 16:52:48 - INFO - utils_glue -   Writing example 0 of 164544\n","08/04/2021 16:52:48 - INFO - utils_glue -   *** Example ***\n","08/04/2021 16:52:48 - INFO - utils_glue -   guid: train-0\n","08/04/2021 16:52:48 - INFO - utils_glue -   tokens: [CLS] im using windows 8 my system is : intel core ##2 ##du ##o t ##64 ##00 2 . 0 ghz 2 ##mb cache ##6 gb dd ##r ##3 103 ##3 mhz ram ##n ##vid ##ia 960 ##0 ##mg ##s gp ##uan ##d i have 500 gb hd ##d i love to play games so i prefer windows 8 for games but i would [SEP] u ##bu ##nt ##u ' s system requirements are quite modest according to the [ system requirements page ] ( https : / / help . u ##bu ##nt ##u . com / community / installation / system ##re ##qui ##rem ##ents ) . the la ##g that you experienced before might be due to the fact that your video card drivers [SEP]\n","08/04/2021 16:52:48 - INFO - utils_glue -   input_ids: 101 10047 2478 3645 1022 2026 2291 2003 1024 13420 4563 2475 8566 2080 1056 21084 8889 1016 1012 1014 29066 1016 14905 17053 2575 16351 20315 2099 2509 9800 2509 11413 8223 2078 17258 2401 26637 2692 24798 2015 14246 13860 2094 1045 2031 3156 16351 10751 2094 1045 2293 2000 2377 2399 2061 1045 9544 3645 1022 2005 2399 2021 1045 2052 102 1057 8569 3372 2226 1005 1055 2291 5918 2024 3243 10754 2429 2000 1996 1031 2291 5918 3931 1033 1006 16770 1024 1013 1013 2393 1012 1057 8569 3372 2226 1012 4012 1013 2451 1013 8272 1013 2291 2890 15549 28578 11187 1007 1012 1996 2474 2290 2008 2017 5281 2077 2453 2022 2349 2000 1996 2755 2008 2115 2678 4003 6853 102\n","08/04/2021 16:52:48 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/04/2021 16:52:48 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/04/2021 16:52:48 - INFO - utils_glue -   label: 1 (id = 1)\n","08/04/2021 16:52:48 - INFO - utils_glue -   *** Example ***\n","08/04/2021 16:52:48 - INFO - utils_glue -   guid: train-1\n","08/04/2021 16:52:48 - INFO - utils_glue -   tokens: [CLS] im using windows 8 my system is : intel core ##2 ##du ##o t ##64 ##00 2 . 0 ghz 2 ##mb cache ##6 gb dd ##r ##3 103 ##3 mhz ram ##n ##vid ##ia 960 ##0 ##mg ##s gp ##uan ##d i have 500 gb hd ##d i love to play games so i prefer windows 8 for games but i would l ##Ä± ##ke to use u ##bu ##nt ##u for my daily use i am thinking to use it alongside [SEP] you will love me : - ) : http : / / www . per ##cona . com / doc / per ##cona - tool ##kit / 2 . 2 / pt - online - sc ##hema - change . h ##t [SEP]\n","08/04/2021 16:52:48 - INFO - utils_glue -   input_ids: 101 10047 2478 3645 1022 2026 2291 2003 1024 13420 4563 2475 8566 2080 1056 21084 8889 1016 1012 1014 29066 1016 14905 17053 2575 16351 20315 2099 2509 9800 2509 11413 8223 2078 17258 2401 26637 2692 24798 2015 14246 13860 2094 1045 2031 3156 16351 10751 2094 1045 2293 2000 2377 2399 2061 1045 9544 3645 1022 2005 2399 2021 1045 2052 1048 11722 3489 2000 2224 1057 8569 3372 2226 2005 2026 3679 2224 1045 2572 3241 2000 2224 2009 4077 102 2017 2097 2293 2033 1024 1011 1007 1024 8299 1024 1013 1013 7479 1012 2566 24366 1012 4012 1013 9986 1013 2566 24366 1011 6994 23615 1013 1016 1012 1016 1013 13866 1011 3784 1011 8040 28433 1011 2689 1012 1044 2102 102\n","08/04/2021 16:52:48 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/04/2021 16:52:48 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/04/2021 16:52:48 - INFO - utils_glue -   label: 0 (id = 0)\n","08/04/2021 16:52:48 - INFO - utils_glue -   *** Example ***\n","08/04/2021 16:52:48 - INFO - utils_glue -   guid: train-2\n","08/04/2021 16:52:48 - INFO - utils_glue -   tokens: [CLS] im using windows 8 my system is : intel core ##2 ##du ##o t ##64 ##00 2 . 0 ghz 2 ##mb cache ##6 gb dd ##r ##3 103 ##3 mhz ram ##n ##vid ##ia 960 ##0 ##mg ##s gp ##uan ##d i have 500 gb hd ##d i love to play games so i prefer windows 8 for games but i would [SEP] after installation , follow the steps on [ this guide ] ( http : / / www . how ##open ##so ##ur ##ce . com / 2012 / 10 / install - n ##vid ##ia - ge ##force - driver - in - u ##bu ##nt ##u - 12 - 10 - 12 - 04 - using - pp ##a / ) [SEP]\n","08/04/2021 16:52:48 - INFO - utils_glue -   input_ids: 101 10047 2478 3645 1022 2026 2291 2003 1024 13420 4563 2475 8566 2080 1056 21084 8889 1016 1012 1014 29066 1016 14905 17053 2575 16351 20315 2099 2509 9800 2509 11413 8223 2078 17258 2401 26637 2692 24798 2015 14246 13860 2094 1045 2031 3156 16351 10751 2094 1045 2293 2000 2377 2399 2061 1045 9544 3645 1022 2005 2399 2021 1045 2052 102 2044 8272 1010 3582 1996 4084 2006 1031 2023 5009 1033 1006 8299 1024 1013 1013 7479 1012 2129 26915 6499 3126 3401 1012 4012 1013 2262 1013 2184 1013 16500 1011 1050 17258 2401 1011 16216 14821 1011 4062 1011 1999 1011 1057 8569 3372 2226 1011 2260 1011 2184 1011 2260 1011 5840 1011 2478 1011 4903 2050 1013 1007 102\n","08/04/2021 16:52:48 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/04/2021 16:52:48 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/04/2021 16:52:48 - INFO - utils_glue -   label: 1 (id = 1)\n","08/04/2021 16:52:48 - INFO - utils_glue -   *** Example ***\n","08/04/2021 16:52:48 - INFO - utils_glue -   guid: train-3\n","08/04/2021 16:52:48 - INFO - utils_glue -   tokens: [CLS] im using windows 8 my system is : intel core ##2 ##du ##o t ##64 ##00 2 . 0 ghz 2 ##mb cache ##6 gb dd ##r ##3 103 ##3 mhz ram ##n ##vid ##ia 960 ##0 ##mg ##s gp ##uan ##d i have 500 gb hd ##d i love to play games so i prefer windows 8 for games but i would [SEP] ( 1 ) your error didn ' t make it into your comment ; ( 2 ) the most useful way to get feedback is to provide a [ rep ##rod ##ucible example ] ( http : / / tiny ##ur ##l . com / rep ##rod ##ucible - 000 ) - - that way we don ' t have to go [SEP]\n","08/04/2021 16:52:48 - INFO - utils_glue -   input_ids: 101 10047 2478 3645 1022 2026 2291 2003 1024 13420 4563 2475 8566 2080 1056 21084 8889 1016 1012 1014 29066 1016 14905 17053 2575 16351 20315 2099 2509 9800 2509 11413 8223 2078 17258 2401 26637 2692 24798 2015 14246 13860 2094 1045 2031 3156 16351 10751 2094 1045 2293 2000 2377 2399 2061 1045 9544 3645 1022 2005 2399 2021 1045 2052 102 1006 1015 1007 2115 7561 2134 1005 1056 2191 2009 2046 2115 7615 1025 1006 1016 1007 1996 2087 6179 2126 2000 2131 12247 2003 2000 3073 1037 1031 16360 14127 21104 2742 1033 1006 8299 1024 1013 1013 4714 3126 2140 1012 4012 1013 16360 14127 21104 1011 2199 1007 1011 1011 2008 2126 2057 2123 1005 1056 2031 2000 2175 102\n","08/04/2021 16:52:48 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/04/2021 16:52:48 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/04/2021 16:52:48 - INFO - utils_glue -   label: 0 (id = 0)\n","08/04/2021 16:52:48 - INFO - utils_glue -   *** Example ***\n","08/04/2021 16:52:48 - INFO - utils_glue -   guid: train-4\n","08/04/2021 16:52:48 - INFO - utils_glue -   tokens: [CLS] im using windows 8 my system is : intel core ##2 ##du ##o t ##64 ##00 2 . 0 ghz 2 ##mb cache ##6 gb dd ##r ##3 103 ##3 mhz ram ##n ##vid ##ia 960 ##0 ##mg ##s gp ##uan ##d i have 500 gb hd ##d i love to play games so i prefer windows 8 for games but i would l ##Ä± ##ke to use u ##bu ##nt ##u for my daily use i am [SEP] seems either gr ##ub is not installed or is not working . read on and try the steps [ here ] ( http : / / u ##bu ##nt ##uf ##orum ##s . org / show ##th ##rea ##d . php ? t = 217 ##6 ##27 [SEP]\n","08/04/2021 16:52:48 - INFO - utils_glue -   input_ids: 101 10047 2478 3645 1022 2026 2291 2003 1024 13420 4563 2475 8566 2080 1056 21084 8889 1016 1012 1014 29066 1016 14905 17053 2575 16351 20315 2099 2509 9800 2509 11413 8223 2078 17258 2401 26637 2692 24798 2015 14246 13860 2094 1045 2031 3156 16351 10751 2094 1045 2293 2000 2377 2399 2061 1045 9544 3645 1022 2005 2399 2021 1045 2052 1048 11722 3489 2000 2224 1057 8569 3372 2226 2005 2026 3679 2224 1045 2572 102 3849 2593 24665 12083 2003 2025 5361 2030 2003 2025 2551 1012 3191 2006 1998 3046 1996 4084 1031 2182 1033 1006 8299 1024 1013 1013 1057 8569 3372 16093 20527 2015 1012 8917 1013 2265 2705 16416 2094 1012 25718 1029 1056 1027 20335 2575 22907 102\n","08/04/2021 16:52:48 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/04/2021 16:52:48 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/04/2021 16:52:48 - INFO - utils_glue -   label: 1 (id = 1)\n","08/04/2021 16:53:54 - INFO - utils_glue -   Writing example 10000 of 164544\n","08/04/2021 16:55:16 - INFO - utils_glue -   Writing example 20000 of 164544\n","08/04/2021 16:56:40 - INFO - utils_glue -   Writing example 30000 of 164544\n","08/04/2021 16:58:05 - INFO - utils_glue -   Writing example 40000 of 164544\n","08/04/2021 16:59:23 - INFO - utils_glue -   Writing example 50000 of 164544\n","08/04/2021 17:00:49 - INFO - utils_glue -   Writing example 60000 of 164544\n","08/04/2021 17:02:09 - INFO - utils_glue -   Writing example 70000 of 164544\n","08/04/2021 17:03:33 - INFO - utils_glue -   Writing example 80000 of 164544\n","08/04/2021 17:05:17 - INFO - utils_glue -   Writing example 90000 of 164544\n","08/04/2021 17:07:16 - INFO - utils_glue -   Writing example 100000 of 164544\n","08/04/2021 17:09:07 - INFO - utils_glue -   Writing example 110000 of 164544\n","08/04/2021 17:10:59 - INFO - utils_glue -   Writing example 120000 of 164544\n","08/04/2021 17:12:48 - INFO - utils_glue -   Writing example 130000 of 164544\n","08/04/2021 17:14:42 - INFO - utils_glue -   Writing example 140000 of 164544\n","08/04/2021 17:16:38 - INFO - utils_glue -   Writing example 150000 of 164544\n","08/04/2021 17:18:31 - INFO - utils_glue -   Writing example 160000 of 164544\n","08/04/2021 17:19:19 - INFO - __main__ -   Saving features into cached file drive/MyDrive/transformer_rankers/mantis_random_9/cached_train_bert-base-uncased_128_mantis_10\n","08/04/2021 17:19:43 - INFO - __main__ -   ***** Running training *****\n","08/04/2021 17:19:43 - INFO - __main__ -     Num examples = 164544\n","08/04/2021 17:19:43 - INFO - __main__ -     Num Epochs = 1\n","08/04/2021 17:19:43 - INFO - __main__ -     Instantaneous batch size per GPU = 8\n","08/04/2021 17:19:43 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 8\n","08/04/2021 17:19:43 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/04/2021 17:19:43 - INFO - __main__ -     Total optimization steps = 20568\n","08/04/2021 17:19:43 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/04/2021 17:19:43 - INFO - __main__ -     data_loaders = [('all_random_batches', <torch.utils.data.dataloader.DataLoader object at 0x7f4881b08e10>)]\n","08/04/2021 17:19:43 - INFO - __main__ -   Starting epoch 1\n","08/04/2021 17:19:43 - INFO - __main__ -   Training with all_random_batches\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/04/2021 17:23:32 - INFO - __main__ -   Iter = 1000\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/04/2021 17:23:32 - INFO - __main__ -   lr = 1.9027615713730068e-05\n","08/04/2021 17:23:32 - INFO - __main__ -   loss = 0.45060701698437333\n","08/04/2021 17:23:32 - INFO - __main__ -   Creating features from dataset file at drive/MyDrive/transformer_rankers/mantis_random_9\n","08/04/2021 17:23:32 - INFO - utils_glue -   LOOKING AT drive/MyDrive/transformer_rankers/mantis_random_9/valid.tsv\n","08/04/2021 17:23:43 - INFO - utils_glue -   Writing example 0 of 180960\n","08/04/2021 17:23:43 - INFO - utils_glue -   *** Example ***\n","08/04/2021 17:23:43 - INFO - utils_glue -   guid: dev-0\n","08/04/2021 17:23:43 - INFO - utils_glue -   tokens: [CLS] you are right it didn ##ot , next test will be on pic ##32 , just to prove the concept . in all cases thanks a lot for the well written and improved answer : ) you deserve more than a silly bounty , i am keeping it open just to allow others to contribute ( only 95 views of the question so far ) by the way how did you draw these diagrams of clock ? [ [SEP] @ electrons great news ! ! so my morning guess was good . i was struggling with that to right now . you might put your findings in your question for others that might needed . not the source code but at least some gui ##dan ##c [SEP]\n","08/04/2021 17:23:43 - INFO - utils_glue -   input_ids: 101 2017 2024 2157 2009 2134 4140 1010 2279 3231 2097 2022 2006 27263 16703 1010 2074 2000 6011 1996 4145 1012 1999 2035 3572 4283 1037 2843 2005 1996 2092 2517 1998 5301 3437 1024 1007 2017 10107 2062 2084 1037 10021 17284 1010 1045 2572 4363 2009 2330 2074 2000 3499 2500 2000 9002 1006 2069 5345 5328 1997 1996 3160 2061 2521 1007 2011 1996 2126 2129 2106 2017 4009 2122 26309 1997 5119 1029 1031 102 1030 15057 2307 2739 999 999 2061 2026 2851 3984 2001 2204 1012 1045 2001 8084 2007 2008 2000 2157 2085 1012 2017 2453 2404 2115 9556 1999 2115 3160 2005 2500 2008 2453 2734 1012 2025 1996 3120 3642 2021 2012 2560 2070 26458 7847 2278 102\n","08/04/2021 17:23:43 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/04/2021 17:23:43 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/04/2021 17:23:43 - INFO - utils_glue -   label: 1 (id = 1)\n","08/04/2021 17:23:43 - INFO - utils_glue -   *** Example ***\n","08/04/2021 17:23:43 - INFO - utils_glue -   guid: dev-1\n","08/04/2021 17:23:43 - INFO - utils_glue -   tokens: [CLS] you are right it didn ##ot , next test will be on pic ##32 , just to prove the concept . in all cases thanks a lot for the well written and improved answer : ) you deserve more than a silly bounty , i am keeping it open just to allow others to contribute ( only 95 views of the question so far ) by the way how did you draw these diagrams of clock ? [ utter ##ance _ sep ] there is an online tool , don ' t have - it handy now . you ' re right [SEP] ok so you need a 150 ~ 250 ##w power supply or else you can go really slow with 12 ##v on a [SEP]\n","08/04/2021 17:23:43 - INFO - utils_glue -   input_ids: 101 2017 2024 2157 2009 2134 4140 1010 2279 3231 2097 2022 2006 27263 16703 1010 2074 2000 6011 1996 4145 1012 1999 2035 3572 4283 1037 2843 2005 1996 2092 2517 1998 5301 3437 1024 1007 2017 10107 2062 2084 1037 10021 17284 1010 1045 2572 4363 2009 2330 2074 2000 3499 2500 2000 9002 1006 2069 5345 5328 1997 1996 3160 2061 2521 1007 2011 1996 2126 2129 2106 2017 4009 2122 26309 1997 5119 1029 1031 14395 6651 1035 19802 1033 2045 2003 2019 3784 6994 1010 2123 1005 1056 2031 1011 2009 18801 2085 1012 2017 1005 2128 2157 102 7929 2061 2017 2342 1037 5018 1066 5539 2860 2373 4425 2030 2842 2017 2064 2175 2428 4030 2007 2260 2615 2006 1037 102\n","08/04/2021 17:23:43 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/04/2021 17:23:43 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/04/2021 17:23:43 - INFO - utils_glue -   label: 0 (id = 0)\n","08/04/2021 17:23:43 - INFO - utils_glue -   *** Example ***\n","08/04/2021 17:23:43 - INFO - utils_glue -   guid: dev-2\n","08/04/2021 17:23:43 - INFO - utils_glue -   tokens: [CLS] you are right it didn ##ot , next test will be on pic ##32 , just to prove the concept . in all cases thanks a lot for the well written and improved answer : ) you deserve more than a silly bounty , i am keeping it open just to allow others to contribute ( only 95 views of the question so far ) by [SEP] people get exactly the same ` j ##ste ##st : operation not permitted ` and the devices still work flawless ##ly with hd ##ap ##s , but on older devices . reference : https : / / forums . gen ##to ##o . org / view ##top ##ic - p - 72 ##38 ##13 ##6 . html from 20 [SEP]\n","08/04/2021 17:23:43 - INFO - utils_glue -   input_ids: 101 2017 2024 2157 2009 2134 4140 1010 2279 3231 2097 2022 2006 27263 16703 1010 2074 2000 6011 1996 4145 1012 1999 2035 3572 4283 1037 2843 2005 1996 2092 2517 1998 5301 3437 1024 1007 2017 10107 2062 2084 1037 10021 17284 1010 1045 2572 4363 2009 2330 2074 2000 3499 2500 2000 9002 1006 2069 5345 5328 1997 1996 3160 2061 2521 1007 2011 102 2111 2131 3599 1996 2168 1036 1046 13473 3367 1024 3169 2025 7936 1036 1998 1996 5733 2145 2147 27503 2135 2007 10751 9331 2015 1010 2021 2006 3080 5733 1012 4431 1024 16770 1024 1013 1013 21415 1012 8991 3406 2080 1012 8917 1013 3193 14399 2594 1011 1052 1011 5824 22025 17134 2575 1012 16129 2013 2322 102\n","08/04/2021 17:23:43 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/04/2021 17:23:43 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/04/2021 17:23:43 - INFO - utils_glue -   label: 0 (id = 0)\n","08/04/2021 17:23:43 - INFO - utils_glue -   *** Example ***\n","08/04/2021 17:23:43 - INFO - utils_glue -   guid: dev-3\n","08/04/2021 17:23:43 - INFO - utils_glue -   tokens: [CLS] you are right it didn ##ot , next test will be on pic ##32 , just to prove the concept . in all cases thanks a lot for the well written and improved answer : ) you deserve more than a silly bounty , i am keeping it open just to allow others to contribute ( only 95 views of the question so far ) by the way how did you draw these diagrams of clock ? [ utter ##ance [SEP] the solar ir ##rad ##iance spectrum answers that question . here ' s a plot of it : https : / / en . wikipedia . org / wi ##ki / sunlight # / media / file : solar _ spectrum _ en . s [SEP]\n","08/04/2021 17:23:43 - INFO - utils_glue -   input_ids: 101 2017 2024 2157 2009 2134 4140 1010 2279 3231 2097 2022 2006 27263 16703 1010 2074 2000 6011 1996 4145 1012 1999 2035 3572 4283 1037 2843 2005 1996 2092 2517 1998 5301 3437 1024 1007 2017 10107 2062 2084 1037 10021 17284 1010 1045 2572 4363 2009 2330 2074 2000 3499 2500 2000 9002 1006 2069 5345 5328 1997 1996 3160 2061 2521 1007 2011 1996 2126 2129 2106 2017 4009 2122 26309 1997 5119 1029 1031 14395 6651 102 1996 5943 20868 12173 28335 8674 6998 2008 3160 1012 2182 1005 1055 1037 5436 1997 2009 1024 16770 1024 1013 1013 4372 1012 16948 1012 8917 1013 15536 3211 1013 9325 1001 1013 2865 1013 5371 1024 5943 1035 8674 1035 4372 1012 1055 102\n","08/04/2021 17:23:43 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/04/2021 17:23:43 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/04/2021 17:23:43 - INFO - utils_glue -   label: 0 (id = 0)\n","08/04/2021 17:23:43 - INFO - utils_glue -   *** Example ***\n","08/04/2021 17:23:43 - INFO - utils_glue -   guid: dev-4\n","08/04/2021 17:23:43 - INFO - utils_glue -   tokens: [CLS] you are right it didn ##ot , next test will be on pic ##32 , just to prove the concept . in all cases thanks a lot for the well written and improved answer : ) you deserve more than a silly bounty , i am keeping it open just to allow others to contribute ( only 95 views of the question so far ) by the way how did you draw these diagrams of clock ? [ utter ##ance _ sep ] there is an online tool , don ' t have - it handy now . you ' re right , i should [SEP] yes it ca you can , you can do sud ##o ' apt - get install h ##fs ##pro ##g [SEP]\n","08/04/2021 17:23:43 - INFO - utils_glue -   input_ids: 101 2017 2024 2157 2009 2134 4140 1010 2279 3231 2097 2022 2006 27263 16703 1010 2074 2000 6011 1996 4145 1012 1999 2035 3572 4283 1037 2843 2005 1996 2092 2517 1998 5301 3437 1024 1007 2017 10107 2062 2084 1037 10021 17284 1010 1045 2572 4363 2009 2330 2074 2000 3499 2500 2000 9002 1006 2069 5345 5328 1997 1996 3160 2061 2521 1007 2011 1996 2126 2129 2106 2017 4009 2122 26309 1997 5119 1029 1031 14395 6651 1035 19802 1033 2045 2003 2019 3784 6994 1010 2123 1005 1056 2031 1011 2009 18801 2085 1012 2017 1005 2128 2157 1010 1045 2323 102 2748 2009 6187 2017 2064 1010 2017 2064 2079 19219 2080 1005 26794 1011 2131 16500 1044 10343 21572 2290 102\n","08/04/2021 17:23:43 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/04/2021 17:23:43 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","08/04/2021 17:23:43 - INFO - utils_glue -   label: 0 (id = 0)\n","08/04/2021 17:24:54 - INFO - utils_glue -   Writing example 10000 of 180960\n","08/04/2021 17:26:21 - INFO - utils_glue -   Writing example 20000 of 180960\n","08/04/2021 17:27:50 - INFO - utils_glue -   Writing example 30000 of 180960\n","08/04/2021 17:29:19 - INFO - utils_glue -   Writing example 40000 of 180960\n","08/04/2021 17:30:43 - INFO - utils_glue -   Writing example 50000 of 180960\n","08/04/2021 17:32:11 - INFO - utils_glue -   Writing example 60000 of 180960\n","08/04/2021 17:33:43 - INFO - utils_glue -   Writing example 70000 of 180960\n","08/04/2021 17:35:14 - INFO - utils_glue -   Writing example 80000 of 180960\n","08/04/2021 17:37:14 - INFO - utils_glue -   Writing example 90000 of 180960\n","08/04/2021 17:39:24 - INFO - utils_glue -   Writing example 100000 of 180960\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XqdE1h9-daca","executionInfo":{"status":"ok","timestamp":1627817221702,"user_tz":-120,"elapsed":4364,"user":{"displayName":"T. Z.","photoUrl":"","userId":"04670299702794629529"}},"outputId":"d4f1758c-b2d9-4fc3-d878-63a4508ef08f"},"source":["import pandas as pd\n","valid = pd.read_csv(\"drive/MyDrive/transformer_rankers/valid.tsv\", sep=\"\\t\",  error_bad_lines=False)\n","valid.size//3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["180959"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"LX72ICNFI0Wg"},"source":["# tested on a new negative sampling valid, with 9 ns in xiaokang's drive\n","!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/transformer_rankers \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=8   \\\n","    --per_gpu_train_batch_size=8   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_10_bert_test/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 1000 \\"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t2OVyNr50-s-"},"source":["# tested on a new negative sampling valid, which has no responses from the train dataset, but the map is still very high\n","!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/transformer_rankers \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=8   \\\n","    --per_gpu_train_batch_size=8   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_10_bert_8test/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 1000 \\"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2cN92X3PjsOF"},"source":["# because the negative sampling is bert-base-cased, I want to check if any different things can happen??? \n","# But the result is no, almost the same \n","!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-cased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/transformer_rankers \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=8   \\\n","    --per_gpu_train_batch_size=8   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_10_bert_8test_cased/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 1000 \\"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0nLoInBRsC6K"},"source":["# 07-27 batch size = 8, trained epoch = 1, map very high, sentenceBert negative sampling"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GqBKZRPZsC6L","executionInfo":{"status":"ok","timestamp":1627802795306,"user_tz":-120,"elapsed":970098,"user":{"displayName":"Chen Qian","photoUrl":"","userId":"11245437508655380561"}},"outputId":"ba21dcfb-3378-41ad-f345-222e8b443052"},"source":["!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/transformer_rankers \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=8   \\\n","    --per_gpu_train_batch_size=8   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_10_bert_83/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 1000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/01/2021 07:10:26 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/01/2021 07:10:27 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/01/2021 07:10:27 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/01/2021 07:10:27 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/01/2021 07:10:27 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/01/2021 07:10:30 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/01/2021 07:10:30 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/01/2021 07:10:33 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/transformer_rankers', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=1000, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise=0.0, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_10_bert_83/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","08/01/2021 07:10:33 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_train_bert-base-uncased_128_mantis_10\n","08/01/2021 07:10:52 - INFO - __main__ -   ***** Running training *****\n","08/01/2021 07:10:52 - INFO - __main__ -     Num examples = 164544\n","08/01/2021 07:10:52 - INFO - __main__ -     Num Epochs = 1\n","08/01/2021 07:10:52 - INFO - __main__ -     Instantaneous batch size per GPU = 8\n","08/01/2021 07:10:52 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 8\n","08/01/2021 07:10:52 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/01/2021 07:10:52 - INFO - __main__ -     Total optimization steps = 20568\n","08/01/2021 07:10:52 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/01/2021 07:10:52 - INFO - __main__ -     data_loaders = [('all_random_batches', <torch.utils.data.dataloader.DataLoader object at 0x7fb26de20850>)]\n","08/01/2021 07:10:52 - INFO - __main__ -   Starting epoch 1\n","08/01/2021 07:10:52 - INFO - __main__ -   Training with all_random_batches\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/01/2021 07:14:55 - INFO - __main__ -   Iter = 1000\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/01/2021 07:14:55 - INFO - __main__ -   lr = 1.9027615713730068e-05\n","08/01/2021 07:14:55 - INFO - __main__ -   loss = 0.5364379909262061\n","08/01/2021 07:14:55 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/01/2021 07:14:59 - INFO - __main__ -   ***** Running evaluation  *****\n","08/01/2021 07:14:59 - INFO - __main__ -     Num examples = 36192\n","08/01/2021 07:14:59 - INFO - __main__ -     Batch size = 8\n","08/01/2021 07:20:55 - INFO - __main__ -   ***** Eval results  *****\n","08/01/2021 07:20:55 - INFO - __main__ -     map = 0.9179652961980548\n","08/01/2021 07:20:55 - INFO - __main__ -     ndcg = 0.9394468633042701\n","08/01/2021 07:20:58 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-best_run_cl__seed_42\n","08/01/2021 07:25:10 - INFO - __main__ -   Iter = 2000\n","08/01/2021 07:25:10 - INFO - __main__ -   lr = 1.8055231427460135e-05\n","08/01/2021 07:25:10 - INFO - __main__ -   loss = 0.46784578981250524\n","08/01/2021 07:25:10 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","08/01/2021 07:25:13 - INFO - __main__ -   ***** Running evaluation  *****\n","08/01/2021 07:25:13 - INFO - __main__ -     Num examples = 36192\n","08/01/2021 07:25:13 - INFO - __main__ -     Batch size = 8\n","Traceback (most recent call last):\n","  File \"drive/MyDrive/transformers_cl/run_glue.py\", line 695, in <module>\n","    main()\n","  File \"drive/MyDrive/transformers_cl/run_glue.py\", line 642, in main\n","    global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n","  File \"drive/MyDrive/transformers_cl/run_glue.py\", line 244, in train\n","    results = evaluate(args, model, tokenizer)\n","  File \"drive/MyDrive/transformers_cl/run_glue.py\", line 360, in evaluate\n","    all_losses.append(tmp_eval_loss.mean().item())\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"d26PIgsmqH89"},"source":["# 07-27 batch size = 64, trained epoch = 1, map = , sentenceBert negative sampling"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D8Xwk8byqTLl","executionInfo":{"status":"ok","timestamp":1627383602567,"user_tz":-120,"elapsed":15779037,"user":{"displayName":"xiaokang qian","photoUrl":"","userId":"16136989389156139825"}},"outputId":"dd6e73b3-8aa6-4941-c846-b02ae7dfdf65"},"source":["!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/transformer_rankers \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_10_bert_364/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 100 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["07/27/2021 06:37:05 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","07/27/2021 06:37:06 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","07/27/2021 06:37:06 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","07/27/2021 06:37:06 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","07/27/2021 06:37:06 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","07/27/2021 06:37:09 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","07/27/2021 06:37:09 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","07/27/2021 06:37:12 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/transformer_rankers', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise=0.0, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_10_bert_364/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","07/27/2021 06:37:12 - INFO - __main__ -   Creating features from dataset file at drive/MyDrive/transformer_rankers\n","07/27/2021 06:37:12 - INFO - utils_glue -   LOOKING AT drive/MyDrive/transformer_rankers/train.tsv\n","07/27/2021 06:37:25 - INFO - utils_glue -   Writing example 0 of 164544\n","07/27/2021 06:37:25 - INFO - utils_glue -   *** Example ***\n","07/27/2021 06:37:25 - INFO - utils_glue -   guid: train-0\n","07/27/2021 06:37:25 - INFO - utils_glue -   tokens: [CLS] im using windows 8 my system is : intel core ##2 ##du ##o t ##64 ##00 2 . 0 ghz 2 ##mb cache ##6 gb dd ##r ##3 103 ##3 mhz ram ##n ##vid ##ia 960 ##0 ##mg ##s gp ##uan ##d i have 500 gb hd ##d i love to play games so i prefer windows 8 for games but i would [SEP] u ##bu ##nt ##u ' s system requirements are quite modest according to the [ system requirements page ] ( https : / / help . u ##bu ##nt ##u . com / community / installation / system ##re ##qui ##rem ##ents ) . the la ##g that you experienced before might be due to the fact that your video card drivers [SEP]\n","07/27/2021 06:37:25 - INFO - utils_glue -   input_ids: 101 10047 2478 3645 1022 2026 2291 2003 1024 13420 4563 2475 8566 2080 1056 21084 8889 1016 1012 1014 29066 1016 14905 17053 2575 16351 20315 2099 2509 9800 2509 11413 8223 2078 17258 2401 26637 2692 24798 2015 14246 13860 2094 1045 2031 3156 16351 10751 2094 1045 2293 2000 2377 2399 2061 1045 9544 3645 1022 2005 2399 2021 1045 2052 102 1057 8569 3372 2226 1005 1055 2291 5918 2024 3243 10754 2429 2000 1996 1031 2291 5918 3931 1033 1006 16770 1024 1013 1013 2393 1012 1057 8569 3372 2226 1012 4012 1013 2451 1013 8272 1013 2291 2890 15549 28578 11187 1007 1012 1996 2474 2290 2008 2017 5281 2077 2453 2022 2349 2000 1996 2755 2008 2115 2678 4003 6853 102\n","07/27/2021 06:37:25 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/27/2021 06:37:25 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/27/2021 06:37:25 - INFO - utils_glue -   label: 1 (id = 1)\n","07/27/2021 06:37:25 - INFO - utils_glue -   *** Example ***\n","07/27/2021 06:37:25 - INFO - utils_glue -   guid: train-1\n","07/27/2021 06:37:25 - INFO - utils_glue -   tokens: [CLS] im using windows 8 my system is : intel core ##2 ##du ##o t ##64 ##00 2 . 0 ghz 2 ##mb cache ##6 gb dd ##r ##3 103 ##3 mhz ram ##n ##vid ##ia 960 ##0 ##mg ##s gp ##uan ##d i have 500 gb hd ##d i love to play games so i prefer windows 8 for games but i would [SEP] @ peter ##te ##oh - arch / x ##86 has mixed 32 ##bit and 64 ##bit code , i just prefer to go through the it ##ani ##um stack ( ia ##64 ) ' cause it is normally clearer ( no # if ##de ##f con ##if ##g _ x ##86 _ 64 everywhere ) . the fact that my most powerful [SEP]\n","07/27/2021 06:37:25 - INFO - utils_glue -   input_ids: 101 10047 2478 3645 1022 2026 2291 2003 1024 13420 4563 2475 8566 2080 1056 21084 8889 1016 1012 1014 29066 1016 14905 17053 2575 16351 20315 2099 2509 9800 2509 11413 8223 2078 17258 2401 26637 2692 24798 2015 14246 13860 2094 1045 2031 3156 16351 10751 2094 1045 2293 2000 2377 2399 2061 1045 9544 3645 1022 2005 2399 2021 1045 2052 102 1030 2848 2618 11631 1011 7905 1013 1060 20842 2038 3816 3590 16313 1998 4185 16313 3642 1010 1045 2074 9544 2000 2175 2083 1996 2009 7088 2819 9991 1006 24264 21084 1007 1005 3426 2009 2003 5373 24509 1006 2053 1001 2065 3207 2546 9530 10128 2290 1035 1060 20842 1035 4185 7249 1007 1012 1996 2755 2008 2026 2087 3928 102\n","07/27/2021 06:37:25 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/27/2021 06:37:25 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/27/2021 06:37:25 - INFO - utils_glue -   label: 0 (id = 0)\n","07/27/2021 06:37:25 - INFO - utils_glue -   *** Example ***\n","07/27/2021 06:37:25 - INFO - utils_glue -   guid: train-2\n","07/27/2021 06:37:25 - INFO - utils_glue -   tokens: [CLS] im using windows 8 my system is : intel core ##2 ##du ##o t ##64 ##00 2 . 0 ghz 2 ##mb cache ##6 gb dd ##r ##3 103 ##3 mhz ram ##n ##vid ##ia 960 ##0 ##mg ##s gp ##uan ##d i have 500 gb hd ##d i love to play games so i prefer windows 8 for games but i would [SEP] after installation , follow the steps on [ this guide ] ( http : / / www . how ##open ##so ##ur ##ce . com / 2012 / 10 / install - n ##vid ##ia - ge ##force - driver - in - u ##bu ##nt ##u - 12 - 10 - 12 - 04 - using - pp ##a / ) [SEP]\n","07/27/2021 06:37:25 - INFO - utils_glue -   input_ids: 101 10047 2478 3645 1022 2026 2291 2003 1024 13420 4563 2475 8566 2080 1056 21084 8889 1016 1012 1014 29066 1016 14905 17053 2575 16351 20315 2099 2509 9800 2509 11413 8223 2078 17258 2401 26637 2692 24798 2015 14246 13860 2094 1045 2031 3156 16351 10751 2094 1045 2293 2000 2377 2399 2061 1045 9544 3645 1022 2005 2399 2021 1045 2052 102 2044 8272 1010 3582 1996 4084 2006 1031 2023 5009 1033 1006 8299 1024 1013 1013 7479 1012 2129 26915 6499 3126 3401 1012 4012 1013 2262 1013 2184 1013 16500 1011 1050 17258 2401 1011 16216 14821 1011 4062 1011 1999 1011 1057 8569 3372 2226 1011 2260 1011 2184 1011 2260 1011 5840 1011 2478 1011 4903 2050 1013 1007 102\n","07/27/2021 06:37:25 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/27/2021 06:37:25 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/27/2021 06:37:25 - INFO - utils_glue -   label: 1 (id = 1)\n","07/27/2021 06:37:25 - INFO - utils_glue -   *** Example ***\n","07/27/2021 06:37:25 - INFO - utils_glue -   guid: train-3\n","07/27/2021 06:37:25 - INFO - utils_glue -   tokens: [CLS] im using windows 8 my system is : intel core ##2 ##du ##o t ##64 ##00 2 . 0 ghz 2 ##mb cache ##6 gb dd ##r ##3 103 ##3 mhz ram ##n ##vid ##ia 960 ##0 ##mg ##s gp ##uan ##d i have 500 gb hd ##d i love to play games so i prefer windows 8 for games but i would [SEP] @ peter ##te ##oh - arch / x ##86 has mixed 32 ##bit and 64 ##bit code , i just prefer to go through the it ##ani ##um stack ( ia ##64 ) ' cause it is normally clearer ( no # if ##de ##f con ##if ##g _ x ##86 _ 64 everywhere ) . the fact that my most powerful [SEP]\n","07/27/2021 06:37:25 - INFO - utils_glue -   input_ids: 101 10047 2478 3645 1022 2026 2291 2003 1024 13420 4563 2475 8566 2080 1056 21084 8889 1016 1012 1014 29066 1016 14905 17053 2575 16351 20315 2099 2509 9800 2509 11413 8223 2078 17258 2401 26637 2692 24798 2015 14246 13860 2094 1045 2031 3156 16351 10751 2094 1045 2293 2000 2377 2399 2061 1045 9544 3645 1022 2005 2399 2021 1045 2052 102 1030 2848 2618 11631 1011 7905 1013 1060 20842 2038 3816 3590 16313 1998 4185 16313 3642 1010 1045 2074 9544 2000 2175 2083 1996 2009 7088 2819 9991 1006 24264 21084 1007 1005 3426 2009 2003 5373 24509 1006 2053 1001 2065 3207 2546 9530 10128 2290 1035 1060 20842 1035 4185 7249 1007 1012 1996 2755 2008 2026 2087 3928 102\n","07/27/2021 06:37:25 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/27/2021 06:37:25 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/27/2021 06:37:25 - INFO - utils_glue -   label: 0 (id = 0)\n","07/27/2021 06:37:25 - INFO - utils_glue -   *** Example ***\n","07/27/2021 06:37:25 - INFO - utils_glue -   guid: train-4\n","07/27/2021 06:37:25 - INFO - utils_glue -   tokens: [CLS] im using windows 8 my system is : intel core ##2 ##du ##o t ##64 ##00 2 . 0 ghz 2 ##mb cache ##6 gb dd ##r ##3 103 ##3 mhz ram ##n ##vid ##ia 960 ##0 ##mg ##s gp ##uan ##d i have 500 gb hd ##d i love to play games so i prefer windows 8 for games but i would l ##Ä± ##ke to use u ##bu ##nt ##u for my daily use i am [SEP] seems either gr ##ub is not installed or is not working . read on and try the steps [ here ] ( http : / / u ##bu ##nt ##uf ##orum ##s . org / show ##th ##rea ##d . php ? t = 217 ##6 ##27 [SEP]\n","07/27/2021 06:37:25 - INFO - utils_glue -   input_ids: 101 10047 2478 3645 1022 2026 2291 2003 1024 13420 4563 2475 8566 2080 1056 21084 8889 1016 1012 1014 29066 1016 14905 17053 2575 16351 20315 2099 2509 9800 2509 11413 8223 2078 17258 2401 26637 2692 24798 2015 14246 13860 2094 1045 2031 3156 16351 10751 2094 1045 2293 2000 2377 2399 2061 1045 9544 3645 1022 2005 2399 2021 1045 2052 1048 11722 3489 2000 2224 1057 8569 3372 2226 2005 2026 3679 2224 1045 2572 102 3849 2593 24665 12083 2003 2025 5361 2030 2003 2025 2551 1012 3191 2006 1998 3046 1996 4084 1031 2182 1033 1006 8299 1024 1013 1013 1057 8569 3372 16093 20527 2015 1012 8917 1013 2265 2705 16416 2094 1012 25718 1029 1056 1027 20335 2575 22907 102\n","07/27/2021 06:37:25 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/27/2021 06:37:25 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/27/2021 06:37:25 - INFO - utils_glue -   label: 1 (id = 1)\n","07/27/2021 06:38:38 - INFO - utils_glue -   Writing example 10000 of 164544\n","07/27/2021 06:40:06 - INFO - utils_glue -   Writing example 20000 of 164544\n","07/27/2021 06:41:35 - INFO - utils_glue -   Writing example 30000 of 164544\n","07/27/2021 06:43:04 - INFO - utils_glue -   Writing example 40000 of 164544\n","07/27/2021 06:44:28 - INFO - utils_glue -   Writing example 50000 of 164544\n","07/27/2021 06:45:57 - INFO - utils_glue -   Writing example 60000 of 164544\n","07/27/2021 06:47:22 - INFO - utils_glue -   Writing example 70000 of 164544\n","07/27/2021 06:48:49 - INFO - utils_glue -   Writing example 80000 of 164544\n","07/27/2021 06:50:38 - INFO - utils_glue -   Writing example 90000 of 164544\n","07/27/2021 06:52:42 - INFO - utils_glue -   Writing example 100000 of 164544\n","07/27/2021 06:54:36 - INFO - utils_glue -   Writing example 110000 of 164544\n","07/27/2021 06:56:33 - INFO - utils_glue -   Writing example 120000 of 164544\n","07/27/2021 06:58:24 - INFO - utils_glue -   Writing example 130000 of 164544\n","07/27/2021 07:00:21 - INFO - utils_glue -   Writing example 140000 of 164544\n","07/27/2021 07:02:23 - INFO - utils_glue -   Writing example 150000 of 164544\n","07/27/2021 07:04:20 - INFO - utils_glue -   Writing example 160000 of 164544\n","07/27/2021 07:05:08 - INFO - __main__ -   Saving features into cached file drive/MyDrive/transformer_rankers/cached_train_bert-base-uncased_128_mantis_10\n","07/27/2021 07:05:32 - INFO - __main__ -   ***** Running training *****\n","07/27/2021 07:05:32 - INFO - __main__ -     Num examples = 164544\n","07/27/2021 07:05:32 - INFO - __main__ -     Num Epochs = 1\n","07/27/2021 07:05:32 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","07/27/2021 07:05:32 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","07/27/2021 07:05:32 - INFO - __main__ -     Gradient Accumulation steps = 1\n","07/27/2021 07:05:32 - INFO - __main__ -     Total optimization steps = 2571\n","07/27/2021 07:05:32 - INFO - __main__ -     percentage by epoch = 1.000000\n","07/27/2021 07:05:32 - INFO - __main__ -     data_loaders = [('all_random_batches', <torch.utils.data.dataloader.DataLoader object at 0x7fe187f68710>)]\n","07/27/2021 07:05:32 - INFO - __main__ -   Starting epoch 1\n","07/27/2021 07:05:32 - INFO - __main__ -   Training with all_random_batches\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","07/27/2021 07:08:16 - INFO - __main__ -   Iter = 100\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","07/27/2021 07:08:16 - INFO - __main__ -   lr = 1.9222092570984054e-05\n","07/27/2021 07:08:16 - INFO - __main__ -   loss = 0.5580266085267067\n","07/27/2021 07:08:16 - INFO - __main__ -   Creating features from dataset file at drive/MyDrive/transformer_rankers\n","07/27/2021 07:08:20 - INFO - utils_glue -   Writing example 0 of 36192\n","07/27/2021 07:08:20 - INFO - utils_glue -   *** Example ***\n","07/27/2021 07:08:20 - INFO - utils_glue -   guid: dev-0\n","07/27/2021 07:08:20 - INFO - utils_glue -   tokens: [CLS] you are right it didn ##ot , next test will be on pic ##32 , just to prove the concept . in all cases thanks a lot for the well written and improved answer : ) you deserve more than a silly bounty , i am keeping it open just to allow others to contribute ( only 95 views of the question so far ) by the way how did you draw these diagrams of clock ? [ [SEP] @ electrons great news ! ! so my morning guess was good . i was struggling with that to right now . you might put your findings in your question for others that might needed . not the source code but at least some gui ##dan ##c [SEP]\n","07/27/2021 07:08:20 - INFO - utils_glue -   input_ids: 101 2017 2024 2157 2009 2134 4140 1010 2279 3231 2097 2022 2006 27263 16703 1010 2074 2000 6011 1996 4145 1012 1999 2035 3572 4283 1037 2843 2005 1996 2092 2517 1998 5301 3437 1024 1007 2017 10107 2062 2084 1037 10021 17284 1010 1045 2572 4363 2009 2330 2074 2000 3499 2500 2000 9002 1006 2069 5345 5328 1997 1996 3160 2061 2521 1007 2011 1996 2126 2129 2106 2017 4009 2122 26309 1997 5119 1029 1031 102 1030 15057 2307 2739 999 999 2061 2026 2851 3984 2001 2204 1012 1045 2001 8084 2007 2008 2000 2157 2085 1012 2017 2453 2404 2115 9556 1999 2115 3160 2005 2500 2008 2453 2734 1012 2025 1996 3120 3642 2021 2012 2560 2070 26458 7847 2278 102\n","07/27/2021 07:08:20 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/27/2021 07:08:20 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/27/2021 07:08:20 - INFO - utils_glue -   label: 1 (id = 1)\n","07/27/2021 07:08:20 - INFO - utils_glue -   *** Example ***\n","07/27/2021 07:08:20 - INFO - utils_glue -   guid: dev-1\n","07/27/2021 07:08:20 - INFO - utils_glue -   tokens: [CLS] you are right it didn ##ot , next test will be on pic ##32 , just to prove the concept . in all cases thanks a lot for the well written and improved answer : ) you deserve more than a silly bounty , i am keeping it open just to allow others to contribute ( only 95 views of the question so [SEP] @ an ##hn ##ha cool . i ' m glad you did a simulation to confirm my thoughts - i was thinking about sim ##ulating it myself but the math seems so simple that it ' s hard to see how it could be wrong . @ an ##hn ##ha in response to this question and the general lack of clarity on [SEP]\n","07/27/2021 07:08:20 - INFO - utils_glue -   input_ids: 101 2017 2024 2157 2009 2134 4140 1010 2279 3231 2097 2022 2006 27263 16703 1010 2074 2000 6011 1996 4145 1012 1999 2035 3572 4283 1037 2843 2005 1996 2092 2517 1998 5301 3437 1024 1007 2017 10107 2062 2084 1037 10021 17284 1010 1045 2572 4363 2009 2330 2074 2000 3499 2500 2000 9002 1006 2069 5345 5328 1997 1996 3160 2061 102 1030 2019 7295 3270 4658 1012 1045 1005 1049 5580 2017 2106 1037 12504 2000 12210 2026 4301 1011 1045 2001 3241 2055 21934 10924 2009 2870 2021 1996 8785 3849 2061 3722 2008 2009 1005 1055 2524 2000 2156 2129 2009 2071 2022 3308 1012 1030 2019 7295 3270 1999 3433 2000 2023 3160 1998 1996 2236 3768 1997 15563 2006 102\n","07/27/2021 07:08:20 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/27/2021 07:08:20 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/27/2021 07:08:20 - INFO - utils_glue -   label: 0 (id = 0)\n","07/27/2021 07:08:20 - INFO - utils_glue -   *** Example ***\n","07/27/2021 07:08:20 - INFO - utils_glue -   guid: dev-2\n","07/27/2021 07:08:20 - INFO - utils_glue -   tokens: [CLS] ye ##a i can ##t remember the name of the app i was trying to install so i just used lynx to get my point across . anyway ##s . . ran both of your commands . paste ##bin below ##ht ##tp : / / paste ##bin . u ##bu ##nt ##u . com / 237 ##6 ##9 ##51 ##9 / [ utter [SEP] hm ok i think you broke the os and the packet depend ##encies the fastest way to fix this is to backup your data and reins ##tal ##l , an work ##around would take too long . but if you want to work ##around this problem , then read some d ##p ##k ##g documentation ##s , i think that must be [SEP]\n","07/27/2021 07:08:20 - INFO - utils_glue -   input_ids: 101 6300 2050 1045 2064 2102 3342 1996 2171 1997 1996 10439 1045 2001 2667 2000 16500 2061 1045 2074 2109 22636 2000 2131 2026 2391 2408 1012 4312 2015 1012 1012 2743 2119 1997 2115 10954 1012 19351 8428 2917 11039 25856 1024 1013 1013 19351 8428 1012 1057 8569 3372 2226 1012 4012 1013 23297 2575 2683 22203 2683 1013 1031 14395 102 20287 7929 1045 2228 2017 3631 1996 9808 1998 1996 14771 12530 15266 1996 7915 2126 2000 8081 2023 2003 2000 10200 2115 2951 1998 19222 9080 2140 1010 2019 2147 24490 2052 2202 2205 2146 1012 2021 2065 2017 2215 2000 2147 24490 2023 3291 1010 2059 3191 2070 1040 2361 2243 2290 12653 2015 1010 1045 2228 2008 2442 2022 102\n","07/27/2021 07:08:20 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/27/2021 07:08:20 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/27/2021 07:08:20 - INFO - utils_glue -   label: 1 (id = 1)\n","07/27/2021 07:08:20 - INFO - utils_glue -   *** Example ***\n","07/27/2021 07:08:20 - INFO - utils_glue -   guid: dev-3\n","07/27/2021 07:08:20 - INFO - utils_glue -   tokens: [CLS] ye ##a i can ##t remember the name of the app i was trying to install so i just used lynx to get my point across . anyway ##s . . ran both of your commands . paste ##bin below ##ht ##tp : / / paste ##bin . u ##bu ##nt ##u . com / 237 ##6 ##9 ##51 ##9 / [ utter [SEP] @ bc ##rip ##ps it seems that you don ' t want the [ terminal ] ( https : / / help . u ##bu ##nt ##u . com / community / using ##the ##ter ##mina ##l ) . ok . the alternate method is : double click on the found package file d ##km ##s _ 2 . 2 . 0 [SEP]\n","07/27/2021 07:08:20 - INFO - utils_glue -   input_ids: 101 6300 2050 1045 2064 2102 3342 1996 2171 1997 1996 10439 1045 2001 2667 2000 16500 2061 1045 2074 2109 22636 2000 2131 2026 2391 2408 1012 4312 2015 1012 1012 2743 2119 1997 2115 10954 1012 19351 8428 2917 11039 25856 1024 1013 1013 19351 8428 1012 1057 8569 3372 2226 1012 4012 1013 23297 2575 2683 22203 2683 1013 1031 14395 102 1030 4647 29443 4523 2009 3849 2008 2017 2123 1005 1056 2215 1996 1031 5536 1033 1006 16770 1024 1013 1013 2393 1012 1057 8569 3372 2226 1012 4012 1013 2451 1013 2478 10760 3334 22311 2140 1007 1012 7929 1012 1996 6585 4118 2003 1024 3313 11562 2006 1996 2179 7427 5371 1040 22287 2015 1035 1016 1012 1016 1012 1014 102\n","07/27/2021 07:08:20 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/27/2021 07:08:20 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/27/2021 07:08:20 - INFO - utils_glue -   label: 0 (id = 0)\n","07/27/2021 07:08:20 - INFO - utils_glue -   *** Example ***\n","07/27/2021 07:08:20 - INFO - utils_glue -   guid: dev-4\n","07/27/2021 07:08:20 - INFO - utils_glue -   tokens: [CLS] while installing q ##em ##u - kv ##m i ' m getting error like below : < pre > < code > $ sud ##o apt - get install q ##em ##u - kv ##m reading package lists . . . done ##building dependency tree reading state information . . . done ##pack ##age q ##em ##u - kv ##m is not available , but is referred to by another package . this may mean that the package is missing , has been obsolete ##d , or ##is [SEP] @ n ##vn for google chrome , check this question http : / / ask ##ub ##unt ##u . com / questions / 510 ##0 ##56 / how - to - install - google - ch ##ro [SEP]\n","07/27/2021 07:08:20 - INFO - utils_glue -   input_ids: 101 2096 23658 1053 6633 2226 1011 24888 2213 1045 1005 1049 2893 7561 2066 2917 1024 1026 3653 1028 1026 3642 1028 1002 19219 2080 26794 1011 2131 16500 1053 6633 2226 1011 24888 2213 3752 7427 7201 1012 1012 1012 2589 25820 24394 3392 3752 2110 2592 1012 1012 1012 2589 23947 4270 1053 6633 2226 1011 24888 2213 2003 2025 2800 1010 2021 2003 3615 2000 2011 2178 7427 1012 2023 2089 2812 2008 1996 7427 2003 4394 1010 2038 2042 15832 2094 1010 2030 2483 102 1030 1050 16022 2005 8224 18546 1010 4638 2023 3160 8299 1024 1013 1013 3198 12083 16671 2226 1012 4012 1013 3980 1013 23475 2692 26976 1013 2129 1011 2000 1011 16500 1011 8224 1011 10381 3217 102\n","07/27/2021 07:08:20 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/27/2021 07:08:20 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/27/2021 07:08:20 - INFO - utils_glue -   label: 1 (id = 1)\n","07/27/2021 07:09:49 - INFO - utils_glue -   Writing example 10000 of 36192\n","07/27/2021 07:11:37 - INFO - utils_glue -   Writing example 20000 of 36192\n","07/27/2021 07:13:41 - INFO - utils_glue -   Writing example 30000 of 36192\n","07/27/2021 07:14:58 - INFO - __main__ -   Saving features into cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 07:15:02 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 07:15:02 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 07:15:02 - INFO - __main__ -     Batch size = 64\n","07/27/2021 07:20:12 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 07:20:12 - INFO - __main__ -     map = 0.9218888152077808\n","07/27/2021 07:20:12 - INFO - __main__ -     ndcg = 0.9423429715598429\n","07/27/2021 07:20:14 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/27/2021 07:22:57 - INFO - __main__ -   Iter = 200\n","07/27/2021 07:22:57 - INFO - __main__ -   lr = 1.8444185141968107e-05\n","07/27/2021 07:22:57 - INFO - __main__ -   loss = 0.47590845346450805\n","07/27/2021 07:22:57 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 07:23:00 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 07:23:00 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 07:23:00 - INFO - __main__ -     Batch size = 64\n","07/27/2021 07:28:09 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 07:28:09 - INFO - __main__ -     map = 0.9312278956675508\n","07/27/2021 07:28:09 - INFO - __main__ -     ndcg = 0.949236525013245\n","07/27/2021 07:28:11 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/27/2021 07:30:54 - INFO - __main__ -   Iter = 300\n","07/27/2021 07:30:54 - INFO - __main__ -   lr = 1.766627771295216e-05\n","07/27/2021 07:30:54 - INFO - __main__ -   loss = 0.4562908259034157\n","07/27/2021 07:30:54 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 07:30:57 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 07:30:57 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 07:30:57 - INFO - __main__ -     Batch size = 64\n","07/27/2021 07:36:05 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 07:36:05 - INFO - __main__ -     map = 0.937444739168877\n","07/27/2021 07:36:05 - INFO - __main__ -     ndcg = 0.9538254289393262\n","07/27/2021 07:36:06 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/27/2021 07:38:49 - INFO - __main__ -   Iter = 400\n","07/27/2021 07:38:49 - INFO - __main__ -   lr = 1.6888370283936212e-05\n","07/27/2021 07:38:49 - INFO - __main__ -   loss = 0.42606908202171323\n","07/27/2021 07:38:49 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 07:38:52 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 07:38:52 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 07:38:52 - INFO - __main__ -     Batch size = 64\n","07/27/2021 07:43:59 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 07:43:59 - INFO - __main__ -     map = 0.9441589301503095\n","07/27/2021 07:43:59 - INFO - __main__ -     ndcg = 0.9587814451794953\n","07/27/2021 07:44:01 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/27/2021 07:46:43 - INFO - __main__ -   Iter = 500\n","07/27/2021 07:46:43 - INFO - __main__ -   lr = 1.6110462854920264e-05\n","07/27/2021 07:46:43 - INFO - __main__ -   loss = 0.41940021961927415\n","07/27/2021 07:46:43 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 07:46:46 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 07:46:46 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 07:46:46 - INFO - __main__ -     Batch size = 64\n","07/27/2021 07:51:54 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 07:51:54 - INFO - __main__ -     map = 0.9486350574712644\n","07/27/2021 07:51:54 - INFO - __main__ -     ndcg = 0.9620854560062735\n","07/27/2021 07:51:56 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/27/2021 07:54:38 - INFO - __main__ -   Iter = 600\n","07/27/2021 07:54:38 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","07/27/2021 07:54:38 - INFO - __main__ -   loss = 0.3999816271662712\n","07/27/2021 07:54:38 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 07:54:42 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 07:54:42 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 07:54:42 - INFO - __main__ -     Batch size = 64\n","07/27/2021 07:59:50 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 07:59:50 - INFO - __main__ -     map = 0.9517296640141468\n","07/27/2021 07:59:50 - INFO - __main__ -     ndcg = 0.9643493152764735\n","07/27/2021 07:59:52 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/27/2021 08:02:34 - INFO - __main__ -   Iter = 700\n","07/27/2021 08:02:34 - INFO - __main__ -   lr = 1.4554647996888371e-05\n","07/27/2021 08:02:34 - INFO - __main__ -   loss = 0.38221280559897425\n","07/27/2021 08:02:34 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 08:02:38 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 08:02:38 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 08:02:38 - INFO - __main__ -     Batch size = 64\n","07/27/2021 08:07:45 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 08:07:45 - INFO - __main__ -     map = 0.9542992926613616\n","07/27/2021 08:07:45 - INFO - __main__ -     ndcg = 0.9662664573611471\n","07/27/2021 08:07:47 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/27/2021 08:10:29 - INFO - __main__ -   Iter = 800\n","07/27/2021 08:10:29 - INFO - __main__ -   lr = 1.3776740567872424e-05\n","07/27/2021 08:10:29 - INFO - __main__ -   loss = 0.3564403891563416\n","07/27/2021 08:10:29 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 08:10:33 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 08:10:33 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 08:10:33 - INFO - __main__ -     Batch size = 64\n","07/27/2021 08:15:40 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 08:15:40 - INFO - __main__ -     map = 0.956343943412909\n","07/27/2021 08:15:40 - INFO - __main__ -     ndcg = 0.9677756968746148\n","07/27/2021 08:15:42 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/27/2021 08:18:25 - INFO - __main__ -   Iter = 900\n","07/27/2021 08:18:25 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","07/27/2021 08:18:25 - INFO - __main__ -   loss = 0.36231369733810426\n","07/27/2021 08:18:25 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 08:18:28 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 08:18:28 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 08:18:28 - INFO - __main__ -     Batch size = 64\n","07/27/2021 08:23:35 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 08:23:35 - INFO - __main__ -     map = 0.9584438549955792\n","07/27/2021 08:23:35 - INFO - __main__ -     ndcg = 0.9693257266452028\n","07/27/2021 08:23:37 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/27/2021 08:26:19 - INFO - __main__ -   Iter = 1000\n","07/27/2021 08:26:19 - INFO - __main__ -   lr = 1.222092570984053e-05\n","07/27/2021 08:26:19 - INFO - __main__ -   loss = 0.3515385788679123\n","07/27/2021 08:26:19 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 08:26:23 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 08:26:23 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 08:26:23 - INFO - __main__ -     Batch size = 64\n","07/27/2021 08:31:31 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 08:31:31 - INFO - __main__ -     map = 0.9596872236958444\n","07/27/2021 08:31:31 - INFO - __main__ -     ndcg = 0.97024350743042\n","07/27/2021 08:31:33 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/27/2021 08:34:16 - INFO - __main__ -   Iter = 1100\n","07/27/2021 08:34:16 - INFO - __main__ -   lr = 1.1443018280824583e-05\n","07/27/2021 08:34:16 - INFO - __main__ -   loss = 0.34873854741454124\n","07/27/2021 08:34:16 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 08:34:19 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 08:34:19 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 08:34:19 - INFO - __main__ -     Batch size = 64\n","07/27/2021 08:39:26 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 08:39:26 - INFO - __main__ -     map = 0.9599635278514589\n","07/27/2021 08:39:26 - INFO - __main__ -     ndcg = 0.9704474587160228\n","07/27/2021 08:39:28 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/27/2021 08:42:09 - INFO - __main__ -   Iter = 1200\n","07/27/2021 08:42:09 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","07/27/2021 08:42:09 - INFO - __main__ -   loss = 0.33442223697900775\n","07/27/2021 08:42:09 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 08:42:13 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 08:42:13 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 08:42:13 - INFO - __main__ -     Batch size = 64\n","07/27/2021 08:47:19 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 08:47:19 - INFO - __main__ -     map = 0.9613450486295314\n","07/27/2021 08:47:19 - INFO - __main__ -     ndcg = 0.9714672151440413\n","07/27/2021 08:47:20 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/27/2021 08:50:02 - INFO - __main__ -   Iter = 1300\n","07/27/2021 08:50:02 - INFO - __main__ -   lr = 9.887203422792688e-06\n","07/27/2021 08:50:02 - INFO - __main__ -   loss = 0.31437417551875113\n","07/27/2021 08:50:02 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 08:50:05 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 08:50:05 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 08:50:05 - INFO - __main__ -     Batch size = 64\n","07/27/2021 08:55:10 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 08:55:10 - INFO - __main__ -     map = 0.9622292219274978\n","07/27/2021 08:55:10 - INFO - __main__ -     ndcg = 0.9721198592579735\n","07/27/2021 08:55:12 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/27/2021 08:57:54 - INFO - __main__ -   Iter = 1400\n","07/27/2021 08:57:54 - INFO - __main__ -   lr = 9.10929599377674e-06\n","07/27/2021 08:57:54 - INFO - __main__ -   loss = 0.32559410214424134\n","07/27/2021 08:57:54 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 08:57:57 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 08:57:57 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 08:57:57 - INFO - __main__ -     Batch size = 64\n","07/27/2021 09:03:03 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 09:03:03 - INFO - __main__ -     map = 0.9628370910698497\n","07/27/2021 09:03:03 - INFO - __main__ -     ndcg = 0.972568552086301\n","07/27/2021 09:03:04 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/27/2021 09:05:46 - INFO - __main__ -   Iter = 1500\n","07/27/2021 09:05:46 - INFO - __main__ -   lr = 8.331388564760793e-06\n","07/27/2021 09:05:46 - INFO - __main__ -   loss = 0.328714642226696\n","07/27/2021 09:05:46 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 09:05:49 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 09:05:49 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 09:05:49 - INFO - __main__ -     Batch size = 64\n","07/27/2021 09:10:56 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 09:10:56 - INFO - __main__ -     map = 0.963776525198939\n","07/27/2021 09:10:56 - INFO - __main__ -     ndcg = 0.9732619864573534\n","07/27/2021 09:10:57 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/27/2021 09:13:39 - INFO - __main__ -   Iter = 1600\n","07/27/2021 09:13:39 - INFO - __main__ -   lr = 7.5534811357448465e-06\n","07/27/2021 09:13:39 - INFO - __main__ -   loss = 0.3107838360965252\n","07/27/2021 09:13:39 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 09:13:42 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 09:13:42 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 09:13:42 - INFO - __main__ -     Batch size = 64\n","07/27/2021 09:18:49 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 09:18:49 - INFO - __main__ -     map = 0.963527851458886\n","07/27/2021 09:18:49 - INFO - __main__ -     ndcg = 0.97307843030031\n","07/27/2021 09:21:31 - INFO - __main__ -   Iter = 1700\n","07/27/2021 09:21:31 - INFO - __main__ -   lr = 6.7755737067289e-06\n","07/27/2021 09:21:31 - INFO - __main__ -   loss = 0.3130376674234867\n","07/27/2021 09:21:31 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 09:21:34 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 09:21:34 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 09:21:34 - INFO - __main__ -     Batch size = 64\n","07/27/2021 09:26:41 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 09:26:41 - INFO - __main__ -     map = 0.9639699381078691\n","07/27/2021 09:26:41 - INFO - __main__ -     ndcg = 0.9734047523572757\n","07/27/2021 09:26:42 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/27/2021 09:29:24 - INFO - __main__ -   Iter = 1800\n","07/27/2021 09:29:24 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","07/27/2021 09:29:24 - INFO - __main__ -   loss = 0.29247962951660156\n","07/27/2021 09:29:24 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 09:29:27 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 09:29:27 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 09:29:27 - INFO - __main__ -     Batch size = 64\n","07/27/2021 09:34:34 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 09:34:34 - INFO - __main__ -     map = 0.9652685676392573\n","07/27/2021 09:34:34 - INFO - __main__ -     ndcg = 0.9743633233996135\n","07/27/2021 09:34:35 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/27/2021 09:37:18 - INFO - __main__ -   Iter = 1900\n","07/27/2021 09:37:18 - INFO - __main__ -   lr = 5.219758848697005e-06\n","07/27/2021 09:37:18 - INFO - __main__ -   loss = 0.2975452950596809\n","07/27/2021 09:37:18 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 09:37:21 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 09:37:21 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 09:37:21 - INFO - __main__ -     Batch size = 64\n","07/27/2021 09:42:29 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 09:42:29 - INFO - __main__ -     map = 0.9658211759504863\n","07/27/2021 09:42:29 - INFO - __main__ -     ndcg = 0.9747712259708207\n","07/27/2021 09:42:30 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/27/2021 09:45:13 - INFO - __main__ -   Iter = 2000\n","07/27/2021 09:45:13 - INFO - __main__ -   lr = 4.441851419681058e-06\n","07/27/2021 09:45:13 - INFO - __main__ -   loss = 0.28441397041082384\n","07/27/2021 09:45:13 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 09:45:16 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 09:45:16 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 09:45:16 - INFO - __main__ -     Batch size = 64\n","07/27/2021 09:50:24 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 09:50:24 - INFO - __main__ -     map = 0.9663737842617153\n","07/27/2021 09:50:24 - INFO - __main__ -     ndcg = 0.9751791285420283\n","07/27/2021 09:50:26 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/27/2021 09:53:08 - INFO - __main__ -   Iter = 2100\n","07/27/2021 09:53:08 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","07/27/2021 09:53:08 - INFO - __main__ -   loss = 0.28950472868978977\n","07/27/2021 09:53:08 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 09:53:12 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 09:53:12 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 09:53:12 - INFO - __main__ -     Batch size = 64\n","07/27/2021 09:58:19 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 09:58:19 - INFO - __main__ -     map = 0.9660698496905393\n","07/27/2021 09:58:19 - INFO - __main__ -     ndcg = 0.9749547821278648\n","07/27/2021 10:01:03 - INFO - __main__ -   Iter = 2200\n","07/27/2021 10:01:03 - INFO - __main__ -   lr = 2.8860365616491643e-06\n","07/27/2021 10:01:03 - INFO - __main__ -   loss = 0.28620243549346924\n","07/27/2021 10:01:03 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 10:01:06 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 10:01:06 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 10:01:06 - INFO - __main__ -     Batch size = 64\n","07/27/2021 10:06:12 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 10:06:12 - INFO - __main__ -     map = 0.9659593280282935\n","07/27/2021 10:06:12 - INFO - __main__ -     ndcg = 0.9748732016136226\n","07/27/2021 10:08:55 - INFO - __main__ -   Iter = 2300\n","07/27/2021 10:08:55 - INFO - __main__ -   lr = 2.108129132633217e-06\n","07/27/2021 10:08:55 - INFO - __main__ -   loss = 0.2882205404341221\n","07/27/2021 10:08:55 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 10:08:58 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 10:08:58 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 10:08:58 - INFO - __main__ -     Batch size = 64\n","07/27/2021 10:14:05 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 10:14:05 - INFO - __main__ -     map = 0.9664014146772767\n","07/27/2021 10:14:05 - INFO - __main__ -     ndcg = 0.9751995236705887\n","07/27/2021 10:14:07 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/27/2021 10:16:49 - INFO - __main__ -   Iter = 2400\n","07/27/2021 10:16:49 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","07/27/2021 10:16:49 - INFO - __main__ -   loss = 0.2835252697765827\n","07/27/2021 10:16:49 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 10:16:53 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 10:16:53 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 10:16:53 - INFO - __main__ -     Batch size = 64\n","07/27/2021 10:22:01 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 10:22:01 - INFO - __main__ -     map = 0.9665119363395226\n","07/27/2021 10:22:01 - INFO - __main__ -     ndcg = 0.9752811041848305\n","07/27/2021 10:22:02 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/27/2021 10:24:45 - INFO - __main__ -   Iter = 2500\n","07/27/2021 10:24:45 - INFO - __main__ -   lr = 5.523142746013224e-07\n","07/27/2021 10:24:45 - INFO - __main__ -   loss = 0.28495567202568056\n","07/27/2021 10:24:45 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_dev_bert-base-uncased_128_mantis_10\n","07/27/2021 10:24:48 - INFO - __main__ -   ***** Running evaluation  *****\n","07/27/2021 10:24:48 - INFO - __main__ -     Num examples = 36192\n","07/27/2021 10:24:48 - INFO - __main__ -     Batch size = 64\n","07/27/2021 10:29:55 - INFO - __main__ -   ***** Eval results  *****\n","07/27/2021 10:29:55 - INFO - __main__ -     map = 0.9664290450928382\n","07/27/2021 10:29:55 - INFO - __main__ -     ndcg = 0.9752199187991492\n","07/27/2021 10:31:53 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","07/27/2021 10:31:53 - INFO - __main__ -    global_step = 2572, average loss = 0.3484427845120013\n","07/27/2021 10:31:55 - INFO - __main__ -   Loading features from cached file drive/MyDrive/transformer_rankers/cached_train_bert-base-uncased_128_mantis_10\n","07/27/2021 10:32:15 - INFO - __main__ -   ***** Running evaluation best_run_cl__seed_42 *****\n","07/27/2021 10:32:15 - INFO - __main__ -     Num examples = 164544\n","07/27/2021 10:32:15 - INFO - __main__ -     Batch size = 2\n","07/27/2021 11:00:02 - INFO - __main__ -   ***** Eval results best_run_cl__seed_42 *****\n","07/27/2021 11:00:02 - INFO - __main__ -     map = 0.975799786075457\n","07/27/2021 11:00:02 - INFO - __main__ -     ndcg = 0.9821368421665037\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Vnd8MYa3KFS-"},"source":["# 07-19 batch size = 8, trained epoch = 1, map very high, random negative sampling"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sY3gCcBvJMl-","outputId":"a08dba2a-717a-4289-b51b-25a2d41fc0eb"},"source":["# running time 7h15m for 1 epochs random negative sampling\n","!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=8   \\\n","    --per_gpu_train_batch_size=8   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 3 \\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_10_bert_83/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 1000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["07/19/2021 13:39:59 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","07/19/2021 13:40:00 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","07/19/2021 13:40:00 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","07/19/2021 13:40:00 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","07/19/2021 13:40:01 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","07/19/2021 13:40:05 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","07/19/2021 13:40:05 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","07/19/2021 13:40:07 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=1000, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise=0.0, num_train_epochs=3.0, output_dir='drive/MyDrive/transformers_cl/mantis_10_bert_83/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","07/19/2021 13:40:07 - INFO - __main__ -   Creating features from dataset file at drive/MyDrive/Mantis\n","07/19/2021 13:40:07 - INFO - utils_glue -   LOOKING AT drive/MyDrive/Mantis/train.tsv\n","07/19/2021 13:40:18 - INFO - utils_glue -   Writing example 0 of 164544\n","07/19/2021 13:40:18 - INFO - utils_glue -   *** Example ***\n","07/19/2021 13:40:18 - INFO - utils_glue -   guid: train-0\n","07/19/2021 13:40:18 - INFO - utils_glue -   tokens: [CLS] im using windows 8 my system is : intel core ##2 ##du ##o t ##64 ##00 2 . 0 ghz 2 ##mb cache ##6 gb dd ##r ##3 103 ##3 mhz ram ##n ##vid ##ia 960 ##0 ##mg ##s gp ##uan ##d i have 500 gb hd ##d i love to play games so i prefer windows 8 for games but i would [SEP] u ##bu ##nt ##u ' s system requirements are quite modest according to the [ system requirements page ] ( https : / / help . u ##bu ##nt ##u . com / community / installation / system ##re ##qui ##rem ##ents ) . the la ##g that you experienced before might be due to the fact that your video card drivers [SEP]\n","07/19/2021 13:40:18 - INFO - utils_glue -   input_ids: 101 10047 2478 3645 1022 2026 2291 2003 1024 13420 4563 2475 8566 2080 1056 21084 8889 1016 1012 1014 29066 1016 14905 17053 2575 16351 20315 2099 2509 9800 2509 11413 8223 2078 17258 2401 26637 2692 24798 2015 14246 13860 2094 1045 2031 3156 16351 10751 2094 1045 2293 2000 2377 2399 2061 1045 9544 3645 1022 2005 2399 2021 1045 2052 102 1057 8569 3372 2226 1005 1055 2291 5918 2024 3243 10754 2429 2000 1996 1031 2291 5918 3931 1033 1006 16770 1024 1013 1013 2393 1012 1057 8569 3372 2226 1012 4012 1013 2451 1013 8272 1013 2291 2890 15549 28578 11187 1007 1012 1996 2474 2290 2008 2017 5281 2077 2453 2022 2349 2000 1996 2755 2008 2115 2678 4003 6853 102\n","07/19/2021 13:40:18 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/19/2021 13:40:18 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/19/2021 13:40:18 - INFO - utils_glue -   label: 1 (id = 1)\n","07/19/2021 13:40:18 - INFO - utils_glue -   *** Example ***\n","07/19/2021 13:40:18 - INFO - utils_glue -   guid: train-1\n","07/19/2021 13:40:18 - INFO - utils_glue -   tokens: [CLS] im using windows 8 my system is : intel core ##2 ##du ##o t ##64 ##00 2 . 0 ghz 2 ##mb cache ##6 gb dd ##r ##3 103 ##3 mhz ram ##n ##vid ##ia 960 ##0 ##mg ##s gp ##uan ##d i have 500 gb hd ##d i love to play games so i prefer windows 8 for games but i would l ##Ä± ##ke to [SEP] did the apt - get command tell you it was already at the newest version ? if so , it sounds like the package installation may have gotten screwed up . try ` sud ##o apt - get install - - reins ##tal ##l li ##b ##gs ##sa ##pi - k ##rb ##5 - 2 ` ins ##tea [SEP]\n","07/19/2021 13:40:18 - INFO - utils_glue -   input_ids: 101 10047 2478 3645 1022 2026 2291 2003 1024 13420 4563 2475 8566 2080 1056 21084 8889 1016 1012 1014 29066 1016 14905 17053 2575 16351 20315 2099 2509 9800 2509 11413 8223 2078 17258 2401 26637 2692 24798 2015 14246 13860 2094 1045 2031 3156 16351 10751 2094 1045 2293 2000 2377 2399 2061 1045 9544 3645 1022 2005 2399 2021 1045 2052 1048 11722 3489 2000 102 2106 1996 26794 1011 2131 3094 2425 2017 2009 2001 2525 2012 1996 14751 2544 1029 2065 2061 1010 2009 4165 2066 1996 7427 8272 2089 2031 5407 14180 2039 1012 3046 1036 19219 2080 26794 1011 2131 16500 1011 1011 19222 9080 2140 5622 2497 5620 3736 8197 1011 1047 15185 2629 1011 1016 1036 16021 27058 102\n","07/19/2021 13:40:18 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/19/2021 13:40:18 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/19/2021 13:40:18 - INFO - utils_glue -   label: 0 (id = 0)\n","07/19/2021 13:40:18 - INFO - utils_glue -   *** Example ***\n","07/19/2021 13:40:18 - INFO - utils_glue -   guid: train-2\n","07/19/2021 13:40:18 - INFO - utils_glue -   tokens: [CLS] im using windows 8 my system is : intel core ##2 ##du ##o t ##64 ##00 2 . 0 ghz 2 ##mb cache ##6 gb dd ##r ##3 103 ##3 mhz ram ##n ##vid ##ia 960 ##0 ##mg ##s gp ##uan ##d i have 500 gb hd ##d i love to play games so i prefer windows 8 for games but i would [SEP] after installation , follow the steps on [ this guide ] ( http : / / www . how ##open ##so ##ur ##ce . com / 2012 / 10 / install - n ##vid ##ia - ge ##force - driver - in - u ##bu ##nt ##u - 12 - 10 - 12 - 04 - using - pp ##a / ) [SEP]\n","07/19/2021 13:40:18 - INFO - utils_glue -   input_ids: 101 10047 2478 3645 1022 2026 2291 2003 1024 13420 4563 2475 8566 2080 1056 21084 8889 1016 1012 1014 29066 1016 14905 17053 2575 16351 20315 2099 2509 9800 2509 11413 8223 2078 17258 2401 26637 2692 24798 2015 14246 13860 2094 1045 2031 3156 16351 10751 2094 1045 2293 2000 2377 2399 2061 1045 9544 3645 1022 2005 2399 2021 1045 2052 102 2044 8272 1010 3582 1996 4084 2006 1031 2023 5009 1033 1006 8299 1024 1013 1013 7479 1012 2129 26915 6499 3126 3401 1012 4012 1013 2262 1013 2184 1013 16500 1011 1050 17258 2401 1011 16216 14821 1011 4062 1011 1999 1011 1057 8569 3372 2226 1011 2260 1011 2184 1011 2260 1011 5840 1011 2478 1011 4903 2050 1013 1007 102\n","07/19/2021 13:40:18 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/19/2021 13:40:18 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/19/2021 13:40:18 - INFO - utils_glue -   label: 1 (id = 1)\n","07/19/2021 13:40:18 - INFO - utils_glue -   *** Example ***\n","07/19/2021 13:40:18 - INFO - utils_glue -   guid: train-3\n","07/19/2021 13:40:18 - INFO - utils_glue -   tokens: [CLS] im using windows 8 my system is : intel core ##2 ##du ##o t ##64 ##00 2 . 0 ghz 2 ##mb cache ##6 gb dd ##r ##3 103 ##3 mhz ram ##n ##vid ##ia 960 ##0 ##mg ##s gp ##uan ##d i have 500 gb hd ##d i love to play games so i prefer windows 8 for games but i would l ##Ä± ##ke to use u ##bu ##nt ##u for my daily use i am thinking to use it alongside with windows 8 it is possible right ? should i install 12 . 04 or 13 . 04 also i use 64 bit windows so i should use 64 ##bit u ##bu ##nt ##u right ? thank you [SEP] i added that to [SEP]\n","07/19/2021 13:40:18 - INFO - utils_glue -   input_ids: 101 10047 2478 3645 1022 2026 2291 2003 1024 13420 4563 2475 8566 2080 1056 21084 8889 1016 1012 1014 29066 1016 14905 17053 2575 16351 20315 2099 2509 9800 2509 11413 8223 2078 17258 2401 26637 2692 24798 2015 14246 13860 2094 1045 2031 3156 16351 10751 2094 1045 2293 2000 2377 2399 2061 1045 9544 3645 1022 2005 2399 2021 1045 2052 1048 11722 3489 2000 2224 1057 8569 3372 2226 2005 2026 3679 2224 1045 2572 3241 2000 2224 2009 4077 2007 3645 1022 2009 2003 2825 2157 1029 2323 1045 16500 2260 1012 5840 2030 2410 1012 5840 2036 1045 2224 4185 2978 3645 2061 1045 2323 2224 4185 16313 1057 8569 3372 2226 2157 1029 4067 2017 102 1045 2794 2008 2000 102\n","07/19/2021 13:40:18 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/19/2021 13:40:18 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n","07/19/2021 13:40:18 - INFO - utils_glue -   label: 0 (id = 0)\n","07/19/2021 13:40:18 - INFO - utils_glue -   *** Example ***\n","07/19/2021 13:40:18 - INFO - utils_glue -   guid: train-4\n","07/19/2021 13:40:18 - INFO - utils_glue -   tokens: [CLS] im using windows 8 my system is : intel core ##2 ##du ##o t ##64 ##00 2 . 0 ghz 2 ##mb cache ##6 gb dd ##r ##3 103 ##3 mhz ram ##n ##vid ##ia 960 ##0 ##mg ##s gp ##uan ##d i have 500 gb hd ##d i love to play games so i prefer windows 8 for games but i would l ##Ä± ##ke to use u ##bu ##nt ##u for my daily use i am [SEP] seems either gr ##ub is not installed or is not working . read on and try the steps [ here ] ( http : / / u ##bu ##nt ##uf ##orum ##s . org / show ##th ##rea ##d . php ? t = 217 ##6 ##27 [SEP]\n","07/19/2021 13:40:18 - INFO - utils_glue -   input_ids: 101 10047 2478 3645 1022 2026 2291 2003 1024 13420 4563 2475 8566 2080 1056 21084 8889 1016 1012 1014 29066 1016 14905 17053 2575 16351 20315 2099 2509 9800 2509 11413 8223 2078 17258 2401 26637 2692 24798 2015 14246 13860 2094 1045 2031 3156 16351 10751 2094 1045 2293 2000 2377 2399 2061 1045 9544 3645 1022 2005 2399 2021 1045 2052 1048 11722 3489 2000 2224 1057 8569 3372 2226 2005 2026 3679 2224 1045 2572 102 3849 2593 24665 12083 2003 2025 5361 2030 2003 2025 2551 1012 3191 2006 1998 3046 1996 4084 1031 2182 1033 1006 8299 1024 1013 1013 1057 8569 3372 16093 20527 2015 1012 8917 1013 2265 2705 16416 2094 1012 25718 1029 1056 1027 20335 2575 22907 102\n","07/19/2021 13:40:18 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/19/2021 13:40:18 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/19/2021 13:40:18 - INFO - utils_glue -   label: 1 (id = 1)\n","07/19/2021 13:41:39 - INFO - utils_glue -   Writing example 10000 of 164544\n","07/19/2021 13:43:20 - INFO - utils_glue -   Writing example 20000 of 164544\n","07/19/2021 13:45:01 - INFO - utils_glue -   Writing example 30000 of 164544\n","07/19/2021 13:46:44 - INFO - utils_glue -   Writing example 40000 of 164544\n","07/19/2021 13:48:19 - INFO - utils_glue -   Writing example 50000 of 164544\n","07/19/2021 13:50:03 - INFO - utils_glue -   Writing example 60000 of 164544\n","07/19/2021 13:51:41 - INFO - utils_glue -   Writing example 70000 of 164544\n","07/19/2021 13:53:22 - INFO - utils_glue -   Writing example 80000 of 164544\n","07/19/2021 13:55:29 - INFO - utils_glue -   Writing example 90000 of 164544\n","07/19/2021 13:57:54 - INFO - utils_glue -   Writing example 100000 of 164544\n","07/19/2021 14:00:05 - INFO - utils_glue -   Writing example 110000 of 164544\n","07/19/2021 14:02:20 - INFO - utils_glue -   Writing example 120000 of 164544\n","07/19/2021 14:04:31 - INFO - utils_glue -   Writing example 130000 of 164544\n","07/19/2021 14:06:47 - INFO - utils_glue -   Writing example 140000 of 164544\n","07/19/2021 14:09:03 - INFO - utils_glue -   Writing example 150000 of 164544\n","07/19/2021 14:11:18 - INFO - utils_glue -   Writing example 160000 of 164544\n","07/19/2021 14:12:12 - INFO - __main__ -   Saving features into cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","07/19/2021 14:12:41 - INFO - __main__ -   ***** Running training *****\n","07/19/2021 14:12:41 - INFO - __main__ -     Num examples = 164544\n","07/19/2021 14:12:41 - INFO - __main__ -     Num Epochs = 3\n","07/19/2021 14:12:41 - INFO - __main__ -     Instantaneous batch size per GPU = 8\n","07/19/2021 14:12:41 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 8\n","07/19/2021 14:12:41 - INFO - __main__ -     Gradient Accumulation steps = 1\n","07/19/2021 14:12:41 - INFO - __main__ -     Total optimization steps = 61704\n","07/19/2021 14:12:41 - INFO - __main__ -     percentage by epoch = 1.000000\n","07/19/2021 14:12:41 - INFO - __main__ -     data_loaders = [('all_random_batches', <torch.utils.data.dataloader.DataLoader object at 0x7f26c4640d90>)]\n","07/19/2021 14:12:41 - INFO - __main__ -   Starting epoch 1\n","07/19/2021 14:12:41 - INFO - __main__ -   Training with all_random_batches\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","07/19/2021 14:20:05 - INFO - __main__ -   Iter = 1000\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","07/19/2021 14:20:05 - INFO - __main__ -   lr = 1.9675871904576693e-05\n","07/19/2021 14:20:05 - INFO - __main__ -   loss = 0.4415985205434263\n","07/19/2021 14:20:05 - INFO - __main__ -   Creating features from dataset file at drive/MyDrive/Mantis\n","07/19/2021 14:20:10 - INFO - utils_glue -   Writing example 0 of 36192\n","07/19/2021 14:20:10 - INFO - utils_glue -   *** Example ***\n","07/19/2021 14:20:10 - INFO - utils_glue -   guid: dev-0\n","07/19/2021 14:20:10 - INFO - utils_glue -   tokens: [CLS] you are right it didn ##ot , next test will be on pic ##32 , just to prove the concept . in all cases thanks a lot for the well written and improved answer : ) you deserve more than a silly bounty , i am keeping it open just to allow others to contribute ( only 95 views of the question so far ) by the way how did you draw these diagrams of clock ? [ [SEP] @ electrons great news ! ! so my morning guess was good . i was struggling with that to right now . you might put your findings in your question for others that might needed . not the source code but at least some gui ##dan ##c [SEP]\n","07/19/2021 14:20:10 - INFO - utils_glue -   input_ids: 101 2017 2024 2157 2009 2134 4140 1010 2279 3231 2097 2022 2006 27263 16703 1010 2074 2000 6011 1996 4145 1012 1999 2035 3572 4283 1037 2843 2005 1996 2092 2517 1998 5301 3437 1024 1007 2017 10107 2062 2084 1037 10021 17284 1010 1045 2572 4363 2009 2330 2074 2000 3499 2500 2000 9002 1006 2069 5345 5328 1997 1996 3160 2061 2521 1007 2011 1996 2126 2129 2106 2017 4009 2122 26309 1997 5119 1029 1031 102 1030 15057 2307 2739 999 999 2061 2026 2851 3984 2001 2204 1012 1045 2001 8084 2007 2008 2000 2157 2085 1012 2017 2453 2404 2115 9556 1999 2115 3160 2005 2500 2008 2453 2734 1012 2025 1996 3120 3642 2021 2012 2560 2070 26458 7847 2278 102\n","07/19/2021 14:20:10 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/19/2021 14:20:10 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/19/2021 14:20:10 - INFO - utils_glue -   label: 1 (id = 1)\n","07/19/2021 14:20:10 - INFO - utils_glue -   *** Example ***\n","07/19/2021 14:20:10 - INFO - utils_glue -   guid: dev-1\n","07/19/2021 14:20:10 - INFO - utils_glue -   tokens: [CLS] you are right it didn ##ot , next test will be on pic ##32 , just to prove the concept . in all cases thanks a lot for the well written and improved answer : ) you deserve more than a silly bounty , i am keeping it open just to allow others to contribute ( only 95 views of the question so [SEP] @ i ##hs ##an ##hai ##kal you can always write an application which runs in their data centre and does whatever calculations you like on the data there . . . your code , your calculation / operations . ? for azure , i would just write an azure function ( https : / / azure . microsoft . com / en [SEP]\n","07/19/2021 14:20:10 - INFO - utils_glue -   input_ids: 101 2017 2024 2157 2009 2134 4140 1010 2279 3231 2097 2022 2006 27263 16703 1010 2074 2000 6011 1996 4145 1012 1999 2035 3572 4283 1037 2843 2005 1996 2092 2517 1998 5301 3437 1024 1007 2017 10107 2062 2084 1037 10021 17284 1010 1045 2572 4363 2009 2330 2074 2000 3499 2500 2000 9002 1006 2069 5345 5328 1997 1996 3160 2061 102 1030 1045 7898 2319 10932 12902 2017 2064 2467 4339 2019 4646 2029 3216 1999 2037 2951 2803 1998 2515 3649 16268 2017 2066 2006 1996 2951 2045 1012 1012 1012 2115 3642 1010 2115 17208 1013 3136 1012 1029 2005 24296 1010 1045 2052 2074 4339 2019 24296 3853 1006 16770 1024 1013 1013 24296 1012 7513 1012 4012 1013 4372 102\n","07/19/2021 14:20:10 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/19/2021 14:20:10 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/19/2021 14:20:10 - INFO - utils_glue -   label: 0 (id = 0)\n","07/19/2021 14:20:10 - INFO - utils_glue -   *** Example ***\n","07/19/2021 14:20:10 - INFO - utils_glue -   guid: dev-2\n","07/19/2021 14:20:10 - INFO - utils_glue -   tokens: [CLS] ye ##a i can ##t remember the name of the app i was trying to install so i just used lynx to get my point across . anyway ##s . . ran both of your commands . paste ##bin below ##ht ##tp : / / paste ##bin . u ##bu ##nt ##u . com / 237 ##6 ##9 ##51 ##9 / [ utter [SEP] hm ok i think you broke the os and the packet depend ##encies the fastest way to fix this is to backup your data and reins ##tal ##l , an work ##around would take too long . but if you want to work ##around this problem , then read some d ##p ##k ##g documentation ##s , i think that must be [SEP]\n","07/19/2021 14:20:10 - INFO - utils_glue -   input_ids: 101 6300 2050 1045 2064 2102 3342 1996 2171 1997 1996 10439 1045 2001 2667 2000 16500 2061 1045 2074 2109 22636 2000 2131 2026 2391 2408 1012 4312 2015 1012 1012 2743 2119 1997 2115 10954 1012 19351 8428 2917 11039 25856 1024 1013 1013 19351 8428 1012 1057 8569 3372 2226 1012 4012 1013 23297 2575 2683 22203 2683 1013 1031 14395 102 20287 7929 1045 2228 2017 3631 1996 9808 1998 1996 14771 12530 15266 1996 7915 2126 2000 8081 2023 2003 2000 10200 2115 2951 1998 19222 9080 2140 1010 2019 2147 24490 2052 2202 2205 2146 1012 2021 2065 2017 2215 2000 2147 24490 2023 3291 1010 2059 3191 2070 1040 2361 2243 2290 12653 2015 1010 1045 2228 2008 2442 2022 102\n","07/19/2021 14:20:10 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/19/2021 14:20:10 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/19/2021 14:20:10 - INFO - utils_glue -   label: 1 (id = 1)\n","07/19/2021 14:20:10 - INFO - utils_glue -   *** Example ***\n","07/19/2021 14:20:10 - INFO - utils_glue -   guid: dev-3\n","07/19/2021 14:20:10 - INFO - utils_glue -   tokens: [CLS] ye ##a i can ##t remember the name of the app i was trying to install so i just used lynx to get my point across . anyway ##s . . ran both of your commands . paste ##bin below ##ht ##tp : / / paste ##bin . u ##bu ##nt ##u . com / 237 ##6 ##9 ##51 ##9 / [ utter ##ance _ sep ] yeah sr ##y , this was in the documentation from d ##p ##k ##g from u ##bu ##nt ##u ##user ##s . try this one : sud ##o d ##p ##k ##g - p libre ##off ##ice [ [SEP] yes , reins ##tal ##l . sorry we couldn ' t repair it any other way . we tri ##e [SEP]\n","07/19/2021 14:20:10 - INFO - utils_glue -   input_ids: 101 6300 2050 1045 2064 2102 3342 1996 2171 1997 1996 10439 1045 2001 2667 2000 16500 2061 1045 2074 2109 22636 2000 2131 2026 2391 2408 1012 4312 2015 1012 1012 2743 2119 1997 2115 10954 1012 19351 8428 2917 11039 25856 1024 1013 1013 19351 8428 1012 1057 8569 3372 2226 1012 4012 1013 23297 2575 2683 22203 2683 1013 1031 14395 6651 1035 19802 1033 3398 5034 2100 1010 2023 2001 1999 1996 12653 2013 1040 2361 2243 2290 2013 1057 8569 3372 2226 20330 2015 1012 3046 2023 2028 1024 19219 2080 1040 2361 2243 2290 1011 1052 21091 7245 6610 1031 102 2748 1010 19222 9080 2140 1012 3374 2057 2481 1005 1056 7192 2009 2151 2060 2126 1012 2057 13012 2063 102\n","07/19/2021 14:20:10 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/19/2021 14:20:10 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/19/2021 14:20:10 - INFO - utils_glue -   label: 0 (id = 0)\n","07/19/2021 14:20:10 - INFO - utils_glue -   *** Example ***\n","07/19/2021 14:20:10 - INFO - utils_glue -   guid: dev-4\n","07/19/2021 14:20:10 - INFO - utils_glue -   tokens: [CLS] while installing q ##em ##u - kv ##m i ' m getting error like below : < pre > < code > $ sud ##o apt - get install q ##em ##u - kv ##m reading package lists . . . done ##building dependency tree reading state information . . . done ##pack ##age q ##em ##u - kv ##m is not available , but is referred to by another package . this may mean that the package is missing , has been obsolete ##d , or ##is [SEP] @ n ##vn for google chrome , check this question http : / / ask ##ub ##unt ##u . com / questions / 510 ##0 ##56 / how - to - install - google - ch ##ro [SEP]\n","07/19/2021 14:20:10 - INFO - utils_glue -   input_ids: 101 2096 23658 1053 6633 2226 1011 24888 2213 1045 1005 1049 2893 7561 2066 2917 1024 1026 3653 1028 1026 3642 1028 1002 19219 2080 26794 1011 2131 16500 1053 6633 2226 1011 24888 2213 3752 7427 7201 1012 1012 1012 2589 25820 24394 3392 3752 2110 2592 1012 1012 1012 2589 23947 4270 1053 6633 2226 1011 24888 2213 2003 2025 2800 1010 2021 2003 3615 2000 2011 2178 7427 1012 2023 2089 2812 2008 1996 7427 2003 4394 1010 2038 2042 15832 2094 1010 2030 2483 102 1030 1050 16022 2005 8224 18546 1010 4638 2023 3160 8299 1024 1013 1013 3198 12083 16671 2226 1012 4012 1013 3980 1013 23475 2692 26976 1013 2129 1011 2000 1011 16500 1011 8224 1011 10381 3217 102\n","07/19/2021 14:20:10 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/19/2021 14:20:10 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","07/19/2021 14:20:10 - INFO - utils_glue -   label: 1 (id = 1)\n","07/19/2021 14:21:52 - INFO - utils_glue -   Writing example 10000 of 36192\n","07/19/2021 14:23:58 - INFO - utils_glue -   Writing example 20000 of 36192\n","07/19/2021 14:26:23 - INFO - utils_glue -   Writing example 30000 of 36192\n","07/19/2021 14:27:52 - INFO - __main__ -   Saving features into cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 14:27:58 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 14:27:58 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 14:27:58 - INFO - __main__ -     Batch size = 8\n","07/19/2021 14:37:14 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 14:37:14 - INFO - __main__ -     map = 0.9456509725906278\n","07/19/2021 14:37:14 - INFO - __main__ -     ndcg = 0.9598827821217484\n","07/19/2021 14:37:16 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-best_run_cl__seed_42\n","07/19/2021 14:44:42 - INFO - __main__ -   Iter = 2000\n","07/19/2021 14:44:42 - INFO - __main__ -   lr = 1.9351743809153377e-05\n","07/19/2021 14:44:42 - INFO - __main__ -   loss = 0.40548956977855416\n","07/19/2021 14:44:42 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 14:44:46 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 14:44:46 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 14:44:46 - INFO - __main__ -     Batch size = 8\n","07/19/2021 14:54:01 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 14:54:01 - INFO - __main__ -     map = 0.9535809018567639\n","07/19/2021 14:54:01 - INFO - __main__ -     ndcg = 0.9657361840185754\n","07/19/2021 14:54:03 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-best_run_cl__seed_42\n","07/19/2021 15:01:28 - INFO - __main__ -   Iter = 3000\n","07/19/2021 15:01:28 - INFO - __main__ -   lr = 1.9027615713730068e-05\n","07/19/2021 15:01:28 - INFO - __main__ -   loss = 0.3917869931971654\n","07/19/2021 15:01:28 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 15:01:32 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 15:01:32 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 15:01:32 - INFO - __main__ -     Batch size = 8\n","07/19/2021 15:10:46 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 15:10:46 - INFO - __main__ -     map = 0.9549071618037135\n","07/19/2021 15:10:46 - INFO - __main__ -     ndcg = 0.9667151501894736\n","07/19/2021 15:10:48 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-best_run_cl__seed_42\n","07/19/2021 15:18:12 - INFO - __main__ -   Iter = 4000\n","07/19/2021 15:18:12 - INFO - __main__ -   lr = 1.8703487618306756e-05\n","07/19/2021 15:18:12 - INFO - __main__ -   loss = 0.39148518407996746\n","07/19/2021 15:18:12 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 15:18:16 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 15:18:16 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 15:18:16 - INFO - __main__ -     Batch size = 8\n","07/19/2021 15:27:30 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 15:27:30 - INFO - __main__ -     map = 0.9559018567639257\n","07/19/2021 15:27:30 - INFO - __main__ -     ndcg = 0.9674493748176483\n","07/19/2021 15:27:32 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-best_run_cl__seed_42\n","07/19/2021 15:34:55 - INFO - __main__ -   Iter = 5000\n","07/19/2021 15:34:55 - INFO - __main__ -   lr = 1.8379359522883444e-05\n","07/19/2021 15:34:55 - INFO - __main__ -   loss = 0.3685514224478975\n","07/19/2021 15:34:55 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 15:34:59 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 15:34:59 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 15:34:59 - INFO - __main__ -     Batch size = 8\n","07/19/2021 15:44:14 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 15:44:14 - INFO - __main__ -     map = 0.9570899646330681\n","07/19/2021 15:44:14 - INFO - __main__ -     ndcg = 0.968326365345744\n","07/19/2021 15:44:16 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-best_run_cl__seed_42\n","07/19/2021 15:44:18 - INFO - __main__ -   Saving model checkpoint to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-5000\n","07/19/2021 15:51:42 - INFO - __main__ -   Iter = 6000\n","07/19/2021 15:51:42 - INFO - __main__ -   lr = 1.8055231427460135e-05\n","07/19/2021 15:51:42 - INFO - __main__ -   loss = 0.36856873692478986\n","07/19/2021 15:51:42 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 15:51:46 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 15:51:46 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 15:51:46 - INFO - __main__ -     Batch size = 8\n","07/19/2021 16:01:00 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 16:01:00 - INFO - __main__ -     map = 0.9575320512820513\n","07/19/2021 16:01:00 - INFO - __main__ -     ndcg = 0.9686526874027083\n","07/19/2021 16:01:02 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-best_run_cl__seed_42\n","07/19/2021 16:08:25 - INFO - __main__ -   Iter = 7000\n","07/19/2021 16:08:25 - INFO - __main__ -   lr = 1.7731103332036822e-05\n","07/19/2021 16:08:25 - INFO - __main__ -   loss = 0.3626151102883741\n","07/19/2021 16:08:25 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 16:08:29 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 16:08:29 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 16:08:29 - INFO - __main__ -     Batch size = 8\n","07/19/2021 16:17:43 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 16:17:43 - INFO - __main__ -     map = 0.957449160035367\n","07/19/2021 16:17:43 - INFO - __main__ -     ndcg = 0.9685915020170277\n","07/19/2021 16:25:06 - INFO - __main__ -   Iter = 8000\n","07/19/2021 16:25:06 - INFO - __main__ -   lr = 1.740697523661351e-05\n","07/19/2021 16:25:06 - INFO - __main__ -   loss = 0.3481030406742357\n","07/19/2021 16:25:06 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 16:25:10 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 16:25:10 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 16:25:10 - INFO - __main__ -     Batch size = 8\n","07/19/2021 16:34:24 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 16:34:24 - INFO - __main__ -     map = 0.9577254641909815\n","07/19/2021 16:34:24 - INFO - __main__ -     ndcg = 0.9687954533026321\n","07/19/2021 16:34:26 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-best_run_cl__seed_42\n","07/19/2021 16:41:50 - INFO - __main__ -   Iter = 9000\n","07/19/2021 16:41:50 - INFO - __main__ -   lr = 1.70828471411902e-05\n","07/19/2021 16:41:50 - INFO - __main__ -   loss = 0.3467722663441673\n","07/19/2021 16:41:50 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 16:41:54 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 16:41:54 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 16:41:54 - INFO - __main__ -     Batch size = 8\n","07/19/2021 16:51:07 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 16:51:07 - INFO - __main__ -     map = 0.9579741379310345\n","07/19/2021 16:51:07 - INFO - __main__ -     ndcg = 0.9689790094596739\n","07/19/2021 16:51:09 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-best_run_cl__seed_42\n","07/19/2021 16:58:31 - INFO - __main__ -   Iter = 10000\n","07/19/2021 16:58:31 - INFO - __main__ -   lr = 1.675871904576689e-05\n","07/19/2021 16:58:31 - INFO - __main__ -   loss = 0.3521506057535298\n","07/19/2021 16:58:31 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 16:58:35 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 16:58:35 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 16:58:35 - INFO - __main__ -     Batch size = 8\n","07/19/2021 17:07:48 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 17:07:48 - INFO - __main__ -     map = 0.9573386383731212\n","07/19/2021 17:07:48 - INFO - __main__ -     ndcg = 0.9685099215027873\n","07/19/2021 17:07:50 - INFO - __main__ -   Saving model checkpoint to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-10000\n","07/19/2021 17:15:15 - INFO - __main__ -   Iter = 11000\n","07/19/2021 17:15:15 - INFO - __main__ -   lr = 1.6434590950343577e-05\n","07/19/2021 17:15:15 - INFO - __main__ -   loss = 0.3397126476485282\n","07/19/2021 17:15:15 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 17:15:19 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 17:15:19 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 17:15:19 - INFO - __main__ -     Batch size = 8\n","07/19/2021 17:24:32 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 17:24:32 - INFO - __main__ -     map = 0.9582228116710876\n","07/19/2021 17:24:32 - INFO - __main__ -     ndcg = 0.9691625656167175\n","07/19/2021 17:24:34 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-best_run_cl__seed_42\n","07/19/2021 17:31:58 - INFO - __main__ -   Iter = 12000\n","07/19/2021 17:31:58 - INFO - __main__ -   lr = 1.6110462854920264e-05\n","07/19/2021 17:31:58 - INFO - __main__ -   loss = 0.32139030142407865\n","07/19/2021 17:31:58 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 17:32:01 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 17:32:01 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 17:32:01 - INFO - __main__ -     Batch size = 8\n","07/19/2021 17:41:14 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 17:41:14 - INFO - __main__ -     map = 0.9587201591511937\n","07/19/2021 17:41:14 - INFO - __main__ -     ndcg = 0.9695296779308051\n","07/19/2021 17:41:16 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-best_run_cl__seed_42\n","07/19/2021 17:48:39 - INFO - __main__ -   Iter = 13000\n","07/19/2021 17:48:39 - INFO - __main__ -   lr = 1.5786334759496955e-05\n","07/19/2021 17:48:39 - INFO - __main__ -   loss = 0.3241533164791763\n","07/19/2021 17:48:39 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 17:48:43 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 17:48:43 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 17:48:43 - INFO - __main__ -     Batch size = 8\n","07/19/2021 17:57:54 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 17:57:54 - INFO - __main__ -     map = 0.9591346153846154\n","07/19/2021 17:57:54 - INFO - __main__ -     ndcg = 0.9698356048592106\n","07/19/2021 17:57:56 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-best_run_cl__seed_42\n","07/19/2021 18:05:17 - INFO - __main__ -   Iter = 14000\n","07/19/2021 18:05:17 - INFO - __main__ -   lr = 1.5462206664073643e-05\n","07/19/2021 18:05:17 - INFO - __main__ -   loss = 0.33555542559339663\n","07/19/2021 18:05:17 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 18:05:21 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 18:05:21 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 18:05:21 - INFO - __main__ -     Batch size = 8\n","07/19/2021 18:14:31 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 18:14:31 - INFO - __main__ -     map = 0.959355658709107\n","07/19/2021 18:14:31 - INFO - __main__ -     ndcg = 0.9699987658876947\n","07/19/2021 18:14:33 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-best_run_cl__seed_42\n","07/19/2021 18:21:54 - INFO - __main__ -   Iter = 15000\n","07/19/2021 18:21:54 - INFO - __main__ -   lr = 1.5138078568650333e-05\n","07/19/2021 18:21:54 - INFO - __main__ -   loss = 0.31925439141876993\n","07/19/2021 18:21:54 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 18:21:58 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 18:21:58 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 18:21:58 - INFO - __main__ -     Batch size = 8\n","07/19/2021 18:31:08 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 18:31:08 - INFO - __main__ -     map = 0.9609305923961097\n","07/19/2021 18:31:08 - INFO - __main__ -     ndcg = 0.9711612882156346\n","07/19/2021 18:31:11 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-best_run_cl__seed_42\n","07/19/2021 18:31:13 - INFO - __main__ -   Saving model checkpoint to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-15000\n","07/19/2021 18:38:34 - INFO - __main__ -   Iter = 16000\n","07/19/2021 18:38:34 - INFO - __main__ -   lr = 1.4813950473227022e-05\n","07/19/2021 18:38:34 - INFO - __main__ -   loss = 0.32721012314921244\n","07/19/2021 18:38:34 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 18:38:38 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 18:38:38 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 18:38:38 - INFO - __main__ -     Batch size = 8\n","07/19/2021 18:47:48 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 18:47:48 - INFO - __main__ -     map = 0.9600464190981433\n","07/19/2021 18:47:48 - INFO - __main__ -     ndcg = 0.970508644101703\n","07/19/2021 18:55:08 - INFO - __main__ -   Iter = 17000\n","07/19/2021 18:55:08 - INFO - __main__ -   lr = 1.4489822377803708e-05\n","07/19/2021 18:55:08 - INFO - __main__ -   loss = 0.3234105028117774\n","07/19/2021 18:55:08 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 18:55:12 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 18:55:12 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 18:55:12 - INFO - __main__ -     Batch size = 8\n","07/19/2021 19:04:22 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 19:04:22 - INFO - __main__ -     map = 0.9612345269672856\n","07/19/2021 19:04:22 - INFO - __main__ -     ndcg = 0.9713856346297984\n","07/19/2021 19:04:24 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-best_run_cl__seed_42\n","07/19/2021 19:11:45 - INFO - __main__ -   Iter = 18000\n","07/19/2021 19:11:45 - INFO - __main__ -   lr = 1.4165694282380397e-05\n","07/19/2021 19:11:45 - INFO - __main__ -   loss = 0.32182782498234885\n","07/19/2021 19:11:45 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 19:11:48 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 19:11:48 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 19:11:48 - INFO - __main__ -     Batch size = 8\n","07/19/2021 19:20:59 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 19:20:59 - INFO - __main__ -     map = 0.9607648099027409\n","07/19/2021 19:20:59 - INFO - __main__ -     ndcg = 0.9710389174442725\n","07/19/2021 19:28:19 - INFO - __main__ -   Iter = 19000\n","07/19/2021 19:28:19 - INFO - __main__ -   lr = 1.3841566186957087e-05\n","07/19/2021 19:28:19 - INFO - __main__ -   loss = 0.3061748232028913\n","07/19/2021 19:28:19 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 19:28:23 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 19:28:23 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 19:28:23 - INFO - __main__ -     Batch size = 8\n","07/19/2021 19:37:34 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 19:37:34 - INFO - __main__ -     map = 0.960405614500442\n","07/19/2021 19:37:34 - INFO - __main__ -     ndcg = 0.9707737807729884\n","07/19/2021 19:44:54 - INFO - __main__ -   Iter = 20000\n","07/19/2021 19:44:54 - INFO - __main__ -   lr = 1.3517438091533774e-05\n","07/19/2021 19:44:54 - INFO - __main__ -   loss = 0.3242836415930651\n","07/19/2021 19:44:54 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 19:44:58 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 19:44:58 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 19:44:58 - INFO - __main__ -     Batch size = 8\n","07/19/2021 19:54:09 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 19:54:09 - INFO - __main__ -     map = 0.9616489832007074\n","07/19/2021 19:54:09 - INFO - __main__ -     ndcg = 0.9716915615582044\n","07/19/2021 19:54:11 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-best_run_cl__seed_42\n","07/19/2021 19:54:14 - INFO - __main__ -   Saving model checkpoint to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-20000\n","07/19/2021 19:58:25 - INFO - __main__ -   Finished epoch with 20568 iterations.\n","07/19/2021 19:58:25 - INFO - __main__ -   Starting epoch 2\n","07/19/2021 19:58:25 - INFO - __main__ -   Training with all_random_batches\n","07/19/2021 20:01:35 - INFO - __main__ -   Iter = 21000\n","07/19/2021 20:01:35 - INFO - __main__ -   lr = 1.3193309996110464e-05\n","07/19/2021 20:01:35 - INFO - __main__ -   loss = 0.31061217745637987\n","07/19/2021 20:01:35 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 20:01:39 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 20:01:39 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 20:01:39 - INFO - __main__ -     Batch size = 8\n","07/19/2021 20:10:51 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 20:10:51 - INFO - __main__ -     map = 0.9617318744473917\n","07/19/2021 20:10:51 - INFO - __main__ -     ndcg = 0.9717527469438852\n","07/19/2021 20:10:54 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-best_run_cl__seed_42\n","07/19/2021 20:18:17 - INFO - __main__ -   Iter = 22000\n","07/19/2021 20:18:17 - INFO - __main__ -   lr = 1.2869181900687153e-05\n","07/19/2021 20:18:17 - INFO - __main__ -   loss = 0.2967218017099658\n","07/19/2021 20:18:17 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 20:18:20 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 20:18:20 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 20:18:20 - INFO - __main__ -     Batch size = 8\n","07/19/2021 20:27:35 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 20:27:35 - INFO - __main__ -     map = 0.9620910698496905\n","07/19/2021 20:27:35 - INFO - __main__ -     ndcg = 0.9720178836151705\n","07/19/2021 20:27:37 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-best_run_cl__seed_42\n","07/19/2021 20:34:59 - INFO - __main__ -   Iter = 23000\n","07/19/2021 20:34:59 - INFO - __main__ -   lr = 1.2545053805263841e-05\n","07/19/2021 20:34:59 - INFO - __main__ -   loss = 0.31028598749276715\n","07/19/2021 20:34:59 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 20:35:02 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 20:35:02 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 20:35:02 - INFO - __main__ -     Batch size = 8\n","07/19/2021 20:44:17 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 20:44:17 - INFO - __main__ -     map = 0.9611792661361627\n","07/19/2021 20:44:17 - INFO - __main__ -     ndcg = 0.9713448443726788\n","07/19/2021 20:51:39 - INFO - __main__ -   Iter = 24000\n","07/19/2021 20:51:39 - INFO - __main__ -   lr = 1.222092570984053e-05\n","07/19/2021 20:51:39 - INFO - __main__ -   loss = 0.2928118450565962\n","07/19/2021 20:51:39 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 20:51:43 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 20:51:43 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 20:51:43 - INFO - __main__ -     Batch size = 8\n","07/19/2021 21:00:57 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 21:00:57 - INFO - __main__ -     map = 0.9634173297966402\n","07/19/2021 21:00:57 - INFO - __main__ -     ndcg = 0.972996849786068\n","07/19/2021 21:01:00 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_83/checkpoint-best_run_cl__seed_42\n","07/19/2021 21:08:22 - INFO - __main__ -   Iter = 25000\n","07/19/2021 21:08:22 - INFO - __main__ -   lr = 1.189679761441722e-05\n","07/19/2021 21:08:22 - INFO - __main__ -   loss = 0.30717908301914576\n","07/19/2021 21:08:22 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 21:08:25 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 21:08:25 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 21:08:25 - INFO - __main__ -     Batch size = 8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZUsCFkNlA46g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627028312530,"user_tz":-120,"elapsed":1694152,"user":{"displayName":"Chen Qian","photoUrl":"","userId":"11245437508655380561"}},"outputId":"21378ecb-f05b-4818-bfc4-6ef0030553d3"},"source":["# 7ä¸ªå°æ¶ç½è·äº\n","# åæ¥èäºç¹è±æï¼å¶å®ä¹ä¸æ¯å¦ï¼æ¯predsé£è¾¹å¿è®°æ¹äºï¼åªææå1/4çæ°æ®åä¸äºæåä¸ä¸ªcompute_metricçè®¡ç®\n","# æ»ä¹scoring fileæ²¡é®é¢å¦\n","!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=8   \\\n","    --per_gpu_train_batch_size=8   \\\n","    --learning_rate 2e-5 \\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_10_bert_83/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 1000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["07/23/2021 07:50:19 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","07/23/2021 07:50:19 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","07/23/2021 07:50:19 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","07/23/2021 07:50:19 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","07/23/2021 07:50:20 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","07/23/2021 07:50:23 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","07/23/2021 07:50:23 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","07/23/2021 07:50:26 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=False, eval_all_checkpoints=True, eval_difficult=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=1000, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise=0.0, num_train_epochs=3.0, output_dir='drive/MyDrive/transformers_cl/mantis_10_bert_83/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","07/23/2021 07:50:29 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","QC: length of each training dataset partition <class 'torch.utils.data.dataset.TensorDataset'> <class 'torch.utils.data.dataset.Subset'> 41136\n","07/23/2021 07:50:49 - INFO - __main__ -   ***** Running evaluation best_run_cl__seed_42 *****\n","07/23/2021 07:50:49 - INFO - __main__ -     Num examples = 164544\n","07/23/2021 07:50:49 - INFO - __main__ -     Batch size = 2\n","QC: length of each training dataset partition <class 'torch.utils.data.dataset.TensorDataset'> <class 'torch.utils.data.dataset.Subset'> 41136\n","07/23/2021 07:57:42 - INFO - __main__ -   ***** Running evaluation best_run_cl__seed_42 *****\n","07/23/2021 07:57:42 - INFO - __main__ -     Num examples = 164544\n","07/23/2021 07:57:42 - INFO - __main__ -     Batch size = 2\n","QC: length of each training dataset partition <class 'torch.utils.data.dataset.TensorDataset'> <class 'torch.utils.data.dataset.Subset'> 41136\n","07/23/2021 08:04:38 - INFO - __main__ -   ***** Running evaluation best_run_cl__seed_42 *****\n","07/23/2021 08:04:38 - INFO - __main__ -     Num examples = 164544\n","07/23/2021 08:04:38 - INFO - __main__ -     Batch size = 2\n","QC: length of each training dataset partition <class 'torch.utils.data.dataset.TensorDataset'> <class 'torch.utils.data.dataset.Subset'> 41136\n","07/23/2021 08:11:34 - INFO - __main__ -   ***** Running evaluation best_run_cl__seed_42 *****\n","07/23/2021 08:11:34 - INFO - __main__ -     Num examples = 164544\n","07/23/2021 08:11:34 - INFO - __main__ -     Batch size = 2\n","07/23/2021 08:18:30 - INFO - __main__ -   ***** Eval results best_run_cl__seed_42 *****\n","07/23/2021 08:18:30 - INFO - __main__ -     map = 0.979336833916764\n","07/23/2021 08:18:30 - INFO - __main__ -     ndcg = 0.9847476804033267\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tBbFB8l-kXnx","executionInfo":{"status":"ok","timestamp":1626963311853,"user_tz":-120,"elapsed":313,"user":{"displayName":"T. Z.","photoUrl":"","userId":"04670299702794629529"}},"outputId":"aae8e7eb-196c-42ad-d1e1-c4204c826a51"},"source":["a = (1,2)\n","len(a)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"Bk-x-bZboZco"},"source":["# 07-19 batch size = 64, trained epoch = 1, map very high, random negative sampling"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Kx2Y420oiH_","outputId":"a7a7df82-7849-4cc0-c39a-100858617e3d"},"source":["# running timeï¼2h5m  for 3 epochs \n","!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 3 \\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_10_bert_364/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 100 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["07/19/2021 21:19:29 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","07/19/2021 21:19:29 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmp9j85fg5t\n","100% 433/433 [00:00<00:00, 470866.90B/s]\n","07/19/2021 21:19:29 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp9j85fg5t to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","07/19/2021 21:19:29 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","07/19/2021 21:19:29 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp9j85fg5t\n","07/19/2021 21:19:29 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","07/19/2021 21:19:29 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","07/19/2021 21:19:30 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp4g0j_wec\n","100% 231508/231508 [00:00<00:00, 926548.04B/s]\n","07/19/2021 21:19:30 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp4g0j_wec to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","07/19/2021 21:19:30 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","07/19/2021 21:19:30 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp4g0j_wec\n","07/19/2021 21:19:30 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","07/19/2021 21:19:30 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpm9_pdvzn\n","100% 440473133/440473133 [00:12<00:00, 34499122.83B/s]\n","07/19/2021 21:19:44 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpm9_pdvzn to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","07/19/2021 21:19:45 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","07/19/2021 21:19:45 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpm9_pdvzn\n","07/19/2021 21:19:45 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","07/19/2021 21:19:48 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","07/19/2021 21:19:48 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","07/19/2021 21:20:00 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise=0.0, num_train_epochs=3.0, output_dir='drive/MyDrive/transformers_cl/mantis_10_bert_364/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","07/19/2021 21:20:00 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","07/19/2021 21:20:20 - INFO - __main__ -   ***** Running training *****\n","07/19/2021 21:20:20 - INFO - __main__ -     Num examples = 164544\n","07/19/2021 21:20:20 - INFO - __main__ -     Num Epochs = 3\n","07/19/2021 21:20:20 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","07/19/2021 21:20:20 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","07/19/2021 21:20:20 - INFO - __main__ -     Gradient Accumulation steps = 1\n","07/19/2021 21:20:20 - INFO - __main__ -     Total optimization steps = 7713\n","07/19/2021 21:20:20 - INFO - __main__ -     percentage by epoch = 1.000000\n","07/19/2021 21:20:20 - INFO - __main__ -     data_loaders = [('all_random_batches', <torch.utils.data.dataloader.DataLoader object at 0x7f652a921110>)]\n","07/19/2021 21:20:20 - INFO - __main__ -   Starting epoch 1\n","07/19/2021 21:20:20 - INFO - __main__ -   Training with all_random_batches\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","07/19/2021 21:22:57 - INFO - __main__ -   Iter = 100\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","07/19/2021 21:22:57 - INFO - __main__ -   lr = 1.9740697523661352e-05\n","07/19/2021 21:22:57 - INFO - __main__ -   loss = 0.5164027073979378\n","07/19/2021 21:22:57 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 21:23:02 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 21:23:02 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 21:23:02 - INFO - __main__ -     Batch size = 64\n","07/19/2021 21:28:17 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 21:28:17 - INFO - __main__ -     map = 0.9444628647214854\n","07/19/2021 21:28:17 - INFO - __main__ -     ndcg = 0.9590057915936498\n","07/19/2021 21:28:19 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/19/2021 21:31:05 - INFO - __main__ -   Iter = 200\n","07/19/2021 21:31:05 - INFO - __main__ -   lr = 1.9481395047322703e-05\n","07/19/2021 21:31:05 - INFO - __main__ -   loss = 0.39204443246126175\n","07/19/2021 21:31:05 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 21:31:08 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 21:31:08 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 21:31:08 - INFO - __main__ -     Batch size = 64\n","07/19/2021 21:36:25 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 21:36:25 - INFO - __main__ -     map = 0.9518125552608311\n","07/19/2021 21:36:25 - INFO - __main__ -     ndcg = 0.9644308957907128\n","07/19/2021 21:36:27 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/19/2021 21:39:14 - INFO - __main__ -   Iter = 300\n","07/19/2021 21:39:14 - INFO - __main__ -   lr = 1.9222092570984054e-05\n","07/19/2021 21:39:14 - INFO - __main__ -   loss = 0.37872677609324457\n","07/19/2021 21:39:14 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 21:39:17 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 21:39:17 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 21:39:17 - INFO - __main__ -     Batch size = 64\n","07/19/2021 21:44:32 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 21:44:32 - INFO - __main__ -     map = 0.9533598585322723\n","07/19/2021 21:44:32 - INFO - __main__ -     ndcg = 0.9655730229900917\n","07/19/2021 21:44:33 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/19/2021 21:47:20 - INFO - __main__ -   Iter = 400\n","07/19/2021 21:47:20 - INFO - __main__ -   lr = 1.8962790094645405e-05\n","07/19/2021 21:47:20 - INFO - __main__ -   loss = 0.36170305743813513\n","07/19/2021 21:47:20 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 21:47:23 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 21:47:23 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 21:47:23 - INFO - __main__ -     Batch size = 64\n","07/19/2021 21:52:38 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 21:52:38 - INFO - __main__ -     map = 0.9549624226348364\n","07/19/2021 21:52:38 - INFO - __main__ -     ndcg = 0.9667559404465935\n","07/19/2021 21:52:40 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/19/2021 21:55:27 - INFO - __main__ -   Iter = 500\n","07/19/2021 21:55:27 - INFO - __main__ -   lr = 1.8703487618306756e-05\n","07/19/2021 21:55:27 - INFO - __main__ -   loss = 0.35240567415952684\n","07/19/2021 21:55:27 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 21:55:30 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 21:55:30 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 21:55:30 - INFO - __main__ -     Batch size = 64\n","07/19/2021 22:00:47 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 22:00:47 - INFO - __main__ -     map = 0.957393899204244\n","07/19/2021 22:00:47 - INFO - __main__ -     ndcg = 0.968550711759906\n","07/19/2021 22:00:48 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/19/2021 22:03:35 - INFO - __main__ -   Iter = 600\n","07/19/2021 22:03:35 - INFO - __main__ -   lr = 1.8444185141968107e-05\n","07/19/2021 22:03:35 - INFO - __main__ -   loss = 0.33728502586483955\n","07/19/2021 22:03:35 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 22:03:38 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 22:03:38 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 22:03:38 - INFO - __main__ -     Batch size = 64\n","07/19/2021 22:08:53 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 22:08:53 - INFO - __main__ -     map = 0.9578083554376657\n","07/19/2021 22:08:53 - INFO - __main__ -     ndcg = 0.9688566386883115\n","07/19/2021 22:08:55 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/19/2021 22:11:41 - INFO - __main__ -   Iter = 700\n","07/19/2021 22:11:41 - INFO - __main__ -   lr = 1.8184882665629458e-05\n","07/19/2021 22:11:41 - INFO - __main__ -   loss = 0.3301018700003624\n","07/19/2021 22:11:41 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 22:11:44 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 22:11:44 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 22:11:44 - INFO - __main__ -     Batch size = 64\n","07/19/2021 22:16:59 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 22:16:59 - INFO - __main__ -     map = 0.9592175066312998\n","07/19/2021 22:16:59 - INFO - __main__ -     ndcg = 0.9698967902448912\n","07/19/2021 22:17:01 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/19/2021 22:19:48 - INFO - __main__ -   Iter = 800\n","07/19/2021 22:19:48 - INFO - __main__ -   lr = 1.792558018929081e-05\n","07/19/2021 22:19:48 - INFO - __main__ -   loss = 0.34227114081382753\n","07/19/2021 22:19:48 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 22:19:51 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 22:19:51 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 22:19:51 - INFO - __main__ -     Batch size = 64\n","07/19/2021 22:25:06 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 22:25:06 - INFO - __main__ -     map = 0.9601293103448276\n","07/19/2021 22:25:06 - INFO - __main__ -     ndcg = 0.9705698294873831\n","07/19/2021 22:25:08 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/19/2021 22:27:54 - INFO - __main__ -   Iter = 900\n","07/19/2021 22:27:54 - INFO - __main__ -   lr = 1.766627771295216e-05\n","07/19/2021 22:27:54 - INFO - __main__ -   loss = 0.3184237818419933\n","07/19/2021 22:27:54 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 22:27:57 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 22:27:57 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 22:27:57 - INFO - __main__ -     Batch size = 64\n","07/19/2021 22:33:13 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 22:33:13 - INFO - __main__ -     map = 0.9605161361626879\n","07/19/2021 22:33:13 - INFO - __main__ -     ndcg = 0.9708553612872296\n","07/19/2021 22:33:15 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/19/2021 22:36:02 - INFO - __main__ -   Iter = 1000\n","07/19/2021 22:36:02 - INFO - __main__ -   lr = 1.740697523661351e-05\n","07/19/2021 22:36:02 - INFO - __main__ -   loss = 0.3363843895494938\n","07/19/2021 22:36:02 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 22:36:06 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 22:36:06 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 22:36:06 - INFO - __main__ -     Batch size = 64\n","07/19/2021 22:41:21 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 22:41:21 - INFO - __main__ -     map = 0.9612345269672856\n","07/19/2021 22:41:21 - INFO - __main__ -     ndcg = 0.9713856346297991\n","07/19/2021 22:41:23 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/19/2021 22:44:10 - INFO - __main__ -   Iter = 1100\n","07/19/2021 22:44:10 - INFO - __main__ -   lr = 1.7147672760274864e-05\n","07/19/2021 22:44:10 - INFO - __main__ -   loss = 0.29659435883164403\n","07/19/2021 22:44:10 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 22:44:13 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 22:44:13 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 22:44:13 - INFO - __main__ -     Batch size = 64\n","07/19/2021 22:49:29 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 22:49:29 - INFO - __main__ -     map = 0.9610687444739169\n","07/19/2021 22:49:29 - INFO - __main__ -     ndcg = 0.9712632638584353\n","07/19/2021 22:52:15 - INFO - __main__ -   Iter = 1200\n","07/19/2021 22:52:15 - INFO - __main__ -   lr = 1.6888370283936212e-05\n","07/19/2021 22:52:15 - INFO - __main__ -   loss = 0.30680863589048385\n","07/19/2021 22:52:15 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 22:52:19 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 22:52:19 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 22:52:19 - INFO - __main__ -     Batch size = 64\n","07/19/2021 22:57:33 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 22:57:33 - INFO - __main__ -     map = 0.9613726790450928\n","07/19/2021 22:57:33 - INFO - __main__ -     ndcg = 0.9714876102726006\n","07/19/2021 22:57:35 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/19/2021 23:00:21 - INFO - __main__ -   Iter = 1300\n","07/19/2021 23:00:21 - INFO - __main__ -   lr = 1.6629067807597563e-05\n","07/19/2021 23:00:21 - INFO - __main__ -   loss = 0.30279663592576983\n","07/19/2021 23:00:21 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 23:00:24 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 23:00:24 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 23:00:24 - INFO - __main__ -     Batch size = 64\n","07/19/2021 23:05:40 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 23:05:40 - INFO - __main__ -     map = 0.9616489832007074\n","07/19/2021 23:05:40 - INFO - __main__ -     ndcg = 0.9716915615582047\n","07/19/2021 23:05:42 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/19/2021 23:08:28 - INFO - __main__ -   Iter = 1400\n","07/19/2021 23:08:28 - INFO - __main__ -   lr = 1.6369765331258917e-05\n","07/19/2021 23:08:28 - INFO - __main__ -   loss = 0.29421780452132223\n","07/19/2021 23:08:28 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 23:08:31 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 23:08:31 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 23:08:31 - INFO - __main__ -     Batch size = 64\n","07/19/2021 23:13:47 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 23:13:47 - INFO - __main__ -     map = 0.9620910698496905\n","07/19/2021 23:13:47 - INFO - __main__ -     ndcg = 0.9720178836151688\n","07/19/2021 23:13:49 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/19/2021 23:16:35 - INFO - __main__ -   Iter = 1500\n","07/19/2021 23:16:35 - INFO - __main__ -   lr = 1.6110462854920264e-05\n","07/19/2021 23:16:35 - INFO - __main__ -   loss = 0.306300308406353\n","07/19/2021 23:16:35 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 23:16:38 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 23:16:38 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 23:16:38 - INFO - __main__ -     Batch size = 64\n","07/19/2021 23:21:53 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 23:21:53 - INFO - __main__ -     map = 0.9623397435897436\n","07/19/2021 23:21:53 - INFO - __main__ -     ndcg = 0.972201439772213\n","07/19/2021 23:21:55 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/19/2021 23:24:41 - INFO - __main__ -   Iter = 1600\n","07/19/2021 23:24:41 - INFO - __main__ -   lr = 1.5851160378581615e-05\n","07/19/2021 23:24:41 - INFO - __main__ -   loss = 0.290106925368309\n","07/19/2021 23:24:41 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 23:24:44 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 23:24:44 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 23:24:44 - INFO - __main__ -     Batch size = 64\n","07/19/2021 23:30:00 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 23:30:00 - INFO - __main__ -     map = 0.9623121131741822\n","07/19/2021 23:30:00 - INFO - __main__ -     ndcg = 0.9721810446436535\n","07/19/2021 23:32:46 - INFO - __main__ -   Iter = 1700\n","07/19/2021 23:32:46 - INFO - __main__ -   lr = 1.559185790224297e-05\n","07/19/2021 23:32:46 - INFO - __main__ -   loss = 0.28587049975991247\n","07/19/2021 23:32:46 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 23:32:50 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 23:32:50 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 23:32:50 - INFO - __main__ -     Batch size = 64\n","07/19/2021 23:38:04 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 23:38:04 - INFO - __main__ -     map = 0.9633344385499558\n","07/19/2021 23:38:04 - INFO - __main__ -     ndcg = 0.9729356644003865\n","07/19/2021 23:38:06 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/19/2021 23:40:52 - INFO - __main__ -   Iter = 1800\n","07/19/2021 23:40:52 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","07/19/2021 23:40:52 - INFO - __main__ -   loss = 0.2817360891401768\n","07/19/2021 23:40:52 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 23:40:56 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 23:40:56 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 23:40:56 - INFO - __main__ -     Batch size = 64\n","07/19/2021 23:46:11 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 23:46:11 - INFO - __main__ -     map = 0.9625607869142352\n","07/19/2021 23:46:11 - INFO - __main__ -     ndcg = 0.9723646008006962\n","07/19/2021 23:48:57 - INFO - __main__ -   Iter = 1900\n","07/19/2021 23:48:57 - INFO - __main__ -   lr = 1.507325294956567e-05\n","07/19/2021 23:48:57 - INFO - __main__ -   loss = 0.2896208041906357\n","07/19/2021 23:48:57 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 23:49:01 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 23:49:01 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 23:49:01 - INFO - __main__ -     Batch size = 64\n","07/19/2021 23:54:16 - INFO - __main__ -   ***** Eval results  *****\n","07/19/2021 23:54:16 - INFO - __main__ -     map = 0.9634173297966402\n","07/19/2021 23:54:16 - INFO - __main__ -     ndcg = 0.972996849786068\n","07/19/2021 23:54:18 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/19/2021 23:57:04 - INFO - __main__ -   Iter = 2000\n","07/19/2021 23:57:04 - INFO - __main__ -   lr = 1.4813950473227022e-05\n","07/19/2021 23:57:04 - INFO - __main__ -   loss = 0.2644683811068535\n","07/19/2021 23:57:04 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/19/2021 23:57:07 - INFO - __main__ -   ***** Running evaluation  *****\n","07/19/2021 23:57:07 - INFO - __main__ -     Num examples = 36192\n","07/19/2021 23:57:07 - INFO - __main__ -     Batch size = 64\n","07/20/2021 00:02:23 - INFO - __main__ -   ***** Eval results  *****\n","07/20/2021 00:02:23 - INFO - __main__ -     map = 0.9620358090185677\n","07/20/2021 00:02:23 - INFO - __main__ -     ndcg = 0.9719770933580485\n","07/20/2021 00:05:09 - INFO - __main__ -   Iter = 2100\n","07/20/2021 00:05:09 - INFO - __main__ -   lr = 1.4554647996888371e-05\n","07/20/2021 00:05:09 - INFO - __main__ -   loss = 0.2826935204863548\n","07/20/2021 00:05:09 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/20/2021 00:05:13 - INFO - __main__ -   ***** Running evaluation  *****\n","07/20/2021 00:05:13 - INFO - __main__ -     Num examples = 36192\n","07/20/2021 00:05:13 - INFO - __main__ -     Batch size = 64\n","07/20/2021 00:10:27 - INFO - __main__ -   ***** Eval results  *****\n","07/20/2021 00:10:27 - INFO - __main__ -     map = 0.9632791777188329\n","07/20/2021 00:10:27 - INFO - __main__ -     ndcg = 0.9728948741432656\n","07/20/2021 00:13:13 - INFO - __main__ -   Iter = 2200\n","07/20/2021 00:13:13 - INFO - __main__ -   lr = 1.4295345520549722e-05\n","07/20/2021 00:13:13 - INFO - __main__ -   loss = 0.2771580076217651\n","07/20/2021 00:13:13 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/20/2021 00:13:16 - INFO - __main__ -   ***** Running evaluation  *****\n","07/20/2021 00:13:16 - INFO - __main__ -     Num examples = 36192\n","07/20/2021 00:13:16 - INFO - __main__ -     Batch size = 64\n","07/20/2021 00:18:31 - INFO - __main__ -   ***** Eval results  *****\n","07/20/2021 00:18:31 - INFO - __main__ -     map = 0.9633620689655172\n","07/20/2021 00:18:31 - INFO - __main__ -     ndcg = 0.9729560595289459\n","07/20/2021 00:21:18 - INFO - __main__ -   Iter = 2300\n","07/20/2021 00:21:18 - INFO - __main__ -   lr = 1.4036043044211074e-05\n","07/20/2021 00:21:18 - INFO - __main__ -   loss = 0.2735061113536358\n","07/20/2021 00:21:18 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/20/2021 00:21:22 - INFO - __main__ -   ***** Running evaluation  *****\n","07/20/2021 00:21:22 - INFO - __main__ -     Num examples = 36192\n","07/20/2021 00:21:22 - INFO - __main__ -     Batch size = 64\n","07/20/2021 00:26:37 - INFO - __main__ -   ***** Eval results  *****\n","07/20/2021 00:26:37 - INFO - __main__ -     map = 0.9643567639257294\n","07/20/2021 00:26:37 - INFO - __main__ -     ndcg = 0.9736902841571196\n","07/20/2021 00:26:39 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_bert_364/checkpoint-best_run_cl__seed_42\n","07/20/2021 00:29:25 - INFO - __main__ -   Iter = 2400\n","07/20/2021 00:29:25 - INFO - __main__ -   lr = 1.3776740567872424e-05\n","07/20/2021 00:29:25 - INFO - __main__ -   loss = 0.26313208281993866\n","07/20/2021 00:29:25 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/20/2021 00:29:29 - INFO - __main__ -   ***** Running evaluation  *****\n","07/20/2021 00:29:29 - INFO - __main__ -     Num examples = 36192\n","07/20/2021 00:29:29 - INFO - __main__ -     Batch size = 64\n","07/20/2021 00:34:44 - INFO - __main__ -   ***** Eval results  *****\n","07/20/2021 00:34:44 - INFO - __main__ -     map = 0.9639423076923077\n","07/20/2021 00:34:44 - INFO - __main__ -     ndcg = 0.9733843572287143\n","07/20/2021 00:37:30 - INFO - __main__ -   Iter = 2500\n","07/20/2021 00:37:30 - INFO - __main__ -   lr = 1.3517438091533774e-05\n","07/20/2021 00:37:30 - INFO - __main__ -   loss = 0.26065801829099655\n","07/20/2021 00:37:30 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/20/2021 00:37:33 - INFO - __main__ -   ***** Running evaluation  *****\n","07/20/2021 00:37:33 - INFO - __main__ -     Num examples = 36192\n","07/20/2021 00:37:33 - INFO - __main__ -     Batch size = 64\n","07/20/2021 00:42:47 - INFO - __main__ -   ***** Eval results  *****\n","07/20/2021 00:42:47 - INFO - __main__ -     map = 0.9638870468611848\n","07/20/2021 00:42:47 - INFO - __main__ -     ndcg = 0.9733435669715939\n","07/20/2021 00:44:47 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","07/20/2021 00:44:47 - INFO - __main__ -   Starting epoch 2\n","07/20/2021 00:44:47 - INFO - __main__ -   Training with all_random_batches\n","07/20/2021 00:45:34 - INFO - __main__ -   Iter = 2600\n","07/20/2021 00:45:34 - INFO - __main__ -   lr = 1.3258135615195127e-05\n","07/20/2021 00:45:34 - INFO - __main__ -   loss = 0.2611388024687767\n","07/20/2021 00:45:34 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","07/20/2021 00:45:37 - INFO - __main__ -   ***** Running evaluation  *****\n","07/20/2021 00:45:37 - INFO - __main__ -     Num examples = 36192\n","07/20/2021 00:45:37 - INFO - __main__ -     Batch size = 64\n","07/20/2021 00:50:53 - INFO - __main__ -   ***** Eval results  *****\n","07/20/2021 00:50:53 - INFO - __main__ -     map = 0.9643015030946065\n","07/20/2021 00:50:53 - INFO - __main__ -     ndcg = 0.9736494938999991\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"URLbgRYfBxnN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627028462065,"user_tz":-120,"elapsed":1720582,"user":{"displayName":"T. Z.","photoUrl":"","userId":"04670299702794629529"}},"outputId":"c8affb54-17c0-4295-afa5-e0e1a1377ac6"},"source":["!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=8   \\\n","    --per_gpu_train_batch_size=8   \\\n","    --learning_rate 2e-5 \\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_10_bert_364/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 1000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["07/23/2021 07:52:27 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","07/23/2021 07:52:27 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpiel50oi9\n","100% 433/433 [00:00<00:00, 474434.07B/s]\n","07/23/2021 07:52:27 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpiel50oi9 to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","07/23/2021 07:52:27 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","07/23/2021 07:52:27 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpiel50oi9\n","07/23/2021 07:52:27 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","07/23/2021 07:52:27 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","07/23/2021 07:52:28 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp2fhgc0nb\n","100% 231508/231508 [00:00<00:00, 860463.45B/s]\n","07/23/2021 07:52:28 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp2fhgc0nb to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","07/23/2021 07:52:28 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","07/23/2021 07:52:28 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp2fhgc0nb\n","07/23/2021 07:52:28 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","07/23/2021 07:52:28 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpm2_t72_0\n","100% 440473133/440473133 [00:12<00:00, 34621026.26B/s]\n","07/23/2021 07:52:41 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpm2_t72_0 to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","07/23/2021 07:52:43 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","07/23/2021 07:52:43 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpm2_t72_0\n","07/23/2021 07:52:43 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","07/23/2021 07:52:46 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","07/23/2021 07:52:46 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","07/23/2021 07:52:58 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=False, eval_all_checkpoints=True, eval_difficult=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=1000, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise=0.0, num_train_epochs=3.0, output_dir='drive/MyDrive/transformers_cl/mantis_10_bert_364/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","07/23/2021 07:53:04 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","QC: length of each training dataset partition <class 'torch.utils.data.dataset.TensorDataset'> <class 'torch.utils.data.dataset.Subset'> 41136\n","07/23/2021 07:53:25 - INFO - __main__ -   ***** Running evaluation best_run_cl__seed_42 *****\n","07/23/2021 07:53:25 - INFO - __main__ -     Num examples = 164544\n","07/23/2021 07:53:25 - INFO - __main__ -     Batch size = 2\n","QC: length of each training dataset partition <class 'torch.utils.data.dataset.TensorDataset'> <class 'torch.utils.data.dataset.Subset'> 41136\n","07/23/2021 08:00:12 - INFO - __main__ -   ***** Running evaluation best_run_cl__seed_42 *****\n","07/23/2021 08:00:12 - INFO - __main__ -     Num examples = 164544\n","07/23/2021 08:00:12 - INFO - __main__ -     Batch size = 2\n","QC: length of each training dataset partition <class 'torch.utils.data.dataset.TensorDataset'> <class 'torch.utils.data.dataset.Subset'> 41136\n","07/23/2021 08:07:07 - INFO - __main__ -   ***** Running evaluation best_run_cl__seed_42 *****\n","07/23/2021 08:07:07 - INFO - __main__ -     Num examples = 164544\n","07/23/2021 08:07:07 - INFO - __main__ -     Batch size = 2\n","QC: length of each training dataset partition <class 'torch.utils.data.dataset.TensorDataset'> <class 'torch.utils.data.dataset.Subset'> 41136\n","07/23/2021 08:14:03 - INFO - __main__ -   ***** Running evaluation best_run_cl__seed_42 *****\n","07/23/2021 08:14:03 - INFO - __main__ -     Num examples = 164544\n","07/23/2021 08:14:03 - INFO - __main__ -     Batch size = 2\n","07/23/2021 08:21:00 - INFO - __main__ -   ***** Eval results best_run_cl__seed_42 *****\n","07/23/2021 08:21:00 - INFO - __main__ -     map = 0.9764439906651109\n","07/23/2021 08:21:00 - INFO - __main__ -     ndcg = 0.982612355659791\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DiQFK54cIlmT"},"source":["# ------------------------------------------------------------MSDialog----------------------------------------------"]},{"cell_type":"markdown","metadata":{"id":"g4eCULHGti5K"},"source":["# 09-07 batch size = 8, max_seq_length = 256"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jSYreUo5uZCT","executionInfo":{"status":"ok","timestamp":1631023302938,"user_tz":-120,"elapsed":9211352,"user":{"displayName":"T. Z.","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04670299702794629529"}},"outputId":"9ba86161-9aa7-4935-9a76-7dcbaa280c9f"},"source":["# running time 2h30m for 1 epochs \n","!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  ms_v2 \\\n","    --do_train \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/MSDialog \\\n","    --max_seq_length 256 \\\n","    --per_gpu_eval_batch_size=8   \\\n","    --per_gpu_train_batch_size=8   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 3 \\\n","    --output_dir drive/MyDrive/transformers_cl/ms_v2_bert_6/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 1000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["09/07/2021 11:28:12 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","09/07/2021 11:28:12 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","09/07/2021 11:28:12 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"ms_v2\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","09/07/2021 11:28:12 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","09/07/2021 11:28:13 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","09/07/2021 11:28:16 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","09/07/2021 11:28:16 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","09/07/2021 11:28:18 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', cached_features_file_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/MSDialog', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=-1, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=1000, max_grad_norm=1.0, max_seq_length=256, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise=0.0, num_train_epochs=3.0, output_dir='drive/MyDrive/transformers_cl/ms_v2_bert_6/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, percentage_data_by_epoch=1.0, reset_clf_weights=False, resume_epoch=1.0, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='ms_v2', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","09/07/2021 11:28:18 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_train_bert-base-uncased_256_ms_v2\n","09/07/2021 11:28:28 - INFO - __main__ -   ***** Running training *****\n","09/07/2021 11:28:28 - INFO - __main__ -     Num examples = 34736\n","09/07/2021 11:28:28 - INFO - __main__ -     Num Epochs = 3\n","09/07/2021 11:28:28 - INFO - __main__ -     Instantaneous batch size per GPU = 8\n","09/07/2021 11:28:28 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 8\n","09/07/2021 11:28:28 - INFO - __main__ -     Gradient Accumulation steps = 1\n","09/07/2021 11:28:28 - INFO - __main__ -     Total optimization steps = 13026\n","09/07/2021 11:28:28 - INFO - __main__ -     percentage by epoch = 1.000000\n","09/07/2021 11:28:28 - INFO - __main__ -     data_loaders = [('all_random_batches', <torch.utils.data.dataloader.DataLoader object at 0x7fb7ca495e50>)]\n","09/07/2021 11:28:28 - INFO - __main__ -   Starting epoch 1\n","09/07/2021 11:28:28 - INFO - __main__ -   Training with all_random_batches\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","09/07/2021 11:42:37 - INFO - __main__ -   Iter = 1000.0\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","09/07/2021 11:42:37 - INFO - __main__ -   lr = 1.8464609243052358e-05\n","09/07/2021 11:42:37 - INFO - __main__ -   loss = 0.5294321017414332\n","09/07/2021 11:42:37 - INFO - __main__ -   Creating features from dataset file at drive/MyDrive/MSDialog\n","09/07/2021 11:42:41 - INFO - utils_glue -   Writing example 0 of 37210\n","09/07/2021 11:42:41 - INFO - utils_glue -   *** Example ***\n","09/07/2021 11:42:41 - INFO - utils_glue -   guid: dev-0\n","09/07/2021 11:42:41 - INFO - utils_glue -   tokens: [CLS] two system in our office with dual monitor configuration , windows 10 pro x ##64 1703 . after install kb ##40 ##38 ##7 ##8 ##8 update , on boot after shut ##down ( not after restart ) the second monitor remains in stand by . on both system , i see the win logo and on log ##in the right monitor go in stand by mode . one system is con ##fi ##gur ##ated with primary monitor on left and secondary on right , second with primary on right and secondary on left . in both system the right monitor start in stand - by . the only mode to react ##ivate it is on screen settings and dea ##ct ##ivating / react ##ivating the second monitor [SEP] < < < agent > > > : assuming ( a ) both computers were running windows 7 , and ( b ) the upgrade from win ##7 to win ##10 was offered and installed via windows update ( i . e . , you did not upgrade manually ) , and ( c ) creators update / win ##10 1703 was also offered and installed via windows update , and ( d ) kb ##40 ##38 ##7 ##8 ##8 was also offered and installed via windows update . . . , possibilities include : note : all of the above are not unusual with win ##10 installed on aging - in - place , custom built systems . important ! = > neither computer should [SEP]\n","09/07/2021 11:42:41 - INFO - utils_glue -   input_ids: 101 2048 2291 1999 2256 2436 2007 7037 8080 9563 1010 3645 2184 4013 1060 21084 28366 1012 2044 16500 21677 12740 22025 2581 2620 2620 10651 1010 2006 9573 2044 3844 7698 1006 2025 2044 23818 1007 1996 2117 8080 3464 1999 3233 2011 1012 2006 2119 2291 1010 1045 2156 1996 2663 8154 1998 2006 8833 2378 1996 2157 8080 2175 1999 3233 2011 5549 1012 2028 2291 2003 9530 8873 27390 4383 2007 3078 8080 2006 2187 1998 3905 2006 2157 1010 2117 2007 3078 2006 2157 1998 3905 2006 2187 1012 1999 2119 2291 1996 2157 8080 2707 1999 3233 1011 2011 1012 1996 2069 5549 2000 10509 21466 2009 2003 2006 3898 10906 1998 26709 6593 17441 1013 10509 17441 1996 2117 8080 102 1026 1026 1026 4005 1028 1028 1028 1024 10262 1006 1037 1007 2119 7588 2020 2770 3645 1021 1010 1998 1006 1038 1007 1996 12200 2013 2663 2581 2000 2663 10790 2001 3253 1998 5361 3081 3645 10651 1006 1045 1012 1041 1012 1010 2017 2106 2025 12200 21118 1007 1010 1998 1006 1039 1007 17277 10651 1013 2663 10790 28366 2001 2036 3253 1998 5361 3081 3645 10651 1010 1998 1006 1040 1007 21677 12740 22025 2581 2620 2620 2001 2036 3253 1998 5361 3081 3645 10651 1012 1012 1012 1010 12020 2421 1024 3602 1024 2035 1997 1996 2682 2024 2025 5866 2007 2663 10790 5361 2006 12520 1011 1999 1011 2173 1010 7661 2328 3001 1012 2590 999 1027 1028 4445 3274 2323 102\n","09/07/2021 11:42:41 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","09/07/2021 11:42:41 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","09/07/2021 11:42:41 - INFO - utils_glue -   label: 1 (id = 1)\n","09/07/2021 11:42:41 - INFO - utils_glue -   *** Example ***\n","09/07/2021 11:42:41 - INFO - utils_glue -   guid: dev-1\n","09/07/2021 11:42:41 - INFO - utils_glue -   tokens: [CLS] two system in our office with dual monitor configuration , windows 10 pro x ##64 1703 . after install kb ##40 ##38 ##7 ##8 ##8 update , on boot after shut ##down ( not after restart ) the second monitor remains in stand by . on both system , i see the win logo and on log ##in the right monitor go in stand by mode . one system is con ##fi ##gur ##ated with primary monitor on left and secondary on right , second with primary on right and secondary on left . in both system the right monitor start in stand - by . the only mode to react ##ivate it is on screen settings and dea ##ct ##ivating / react ##ivating the second monitor [SEP] < < < agent > > > : 1 . is the computer still under warrant ##y ? 2 . what os build of windows 10 1703 [ aka creators update ] is currently installed ? 3 . are protection update definitions up - to - date according to windows defender security center ' s virus & threat protection tab ? 4 . what happens when you click on the update button on that tab ? 5 . have you done a reset and / or a ref ##resh since you purchased the computer ? 6 ##a . what country or region is currently selected in settings | time & language | region & language < = this window / tab ? 6 ##b . are [SEP]\n","09/07/2021 11:42:41 - INFO - utils_glue -   input_ids: 101 2048 2291 1999 2256 2436 2007 7037 8080 9563 1010 3645 2184 4013 1060 21084 28366 1012 2044 16500 21677 12740 22025 2581 2620 2620 10651 1010 2006 9573 2044 3844 7698 1006 2025 2044 23818 1007 1996 2117 8080 3464 1999 3233 2011 1012 2006 2119 2291 1010 1045 2156 1996 2663 8154 1998 2006 8833 2378 1996 2157 8080 2175 1999 3233 2011 5549 1012 2028 2291 2003 9530 8873 27390 4383 2007 3078 8080 2006 2187 1998 3905 2006 2157 1010 2117 2007 3078 2006 2157 1998 3905 2006 2187 1012 1999 2119 2291 1996 2157 8080 2707 1999 3233 1011 2011 1012 1996 2069 5549 2000 10509 21466 2009 2003 2006 3898 10906 1998 26709 6593 17441 1013 10509 17441 1996 2117 8080 102 1026 1026 1026 4005 1028 1028 1028 1024 1015 1012 2003 1996 3274 2145 2104 10943 2100 1029 1016 1012 2054 9808 3857 1997 3645 2184 28366 1031 9875 17277 10651 1033 2003 2747 5361 1029 1017 1012 2024 3860 10651 15182 2039 1011 2000 1011 3058 2429 2000 3645 8291 3036 2415 1005 1055 7865 1004 5081 3860 21628 1029 1018 1012 2054 6433 2043 2017 11562 2006 1996 10651 6462 2006 2008 21628 1029 1019 1012 2031 2017 2589 1037 25141 1998 1013 2030 1037 25416 21898 2144 2017 4156 1996 3274 1029 1020 2050 1012 2054 2406 2030 2555 2003 2747 3479 1999 10906 1064 2051 1004 2653 1064 2555 1004 2653 1026 1027 2023 3332 1013 21628 1029 1020 2497 1012 2024 102\n","09/07/2021 11:42:41 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","09/07/2021 11:42:41 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","09/07/2021 11:42:41 - INFO - utils_glue -   label: 0 (id = 0)\n","09/07/2021 11:42:41 - INFO - utils_glue -   *** Example ***\n","09/07/2021 11:42:41 - INFO - utils_glue -   guid: dev-2\n","09/07/2021 11:42:41 - INFO - utils_glue -   tokens: [CLS] two system in our office with dual monitor configuration , windows 10 pro x ##64 1703 . after install kb ##40 ##38 ##7 ##8 ##8 update , on boot after shut ##down ( not after restart ) the second monitor remains in stand by . on both system , i see the win logo and on log ##in the right monitor go in stand by mode . one system is con ##fi ##gur ##ated with primary monitor on left and secondary on right , second with primary on right and secondary on left . in both system the right monitor start in stand - by . the only mode to react ##ivate it is on screen settings and dea ##ct ##ivating / react ##ivating the second monitor [SEP] < < < agent > > > : assuming windows 10 . . . answer - by - number : 1 . when ( approx . date ) did you purchase the computer ? 2 . did the computer come with win ##10 pre ##ins ##tal ##led , did you do a clean install of win ##10 , or did you upgrade a win ##7 computer or a win ##8 . 1 computer [ < = pick one ! ] to win ##10 ? 3 . who manufactured the computer ( e . g . , dell ; hp ; ace ##r ; len ##ovo ; as ##us ) ? 4 . has a norton application or a mca ##fe ##e application ever been installed on [SEP]\n","09/07/2021 11:42:41 - INFO - utils_glue -   input_ids: 101 2048 2291 1999 2256 2436 2007 7037 8080 9563 1010 3645 2184 4013 1060 21084 28366 1012 2044 16500 21677 12740 22025 2581 2620 2620 10651 1010 2006 9573 2044 3844 7698 1006 2025 2044 23818 1007 1996 2117 8080 3464 1999 3233 2011 1012 2006 2119 2291 1010 1045 2156 1996 2663 8154 1998 2006 8833 2378 1996 2157 8080 2175 1999 3233 2011 5549 1012 2028 2291 2003 9530 8873 27390 4383 2007 3078 8080 2006 2187 1998 3905 2006 2157 1010 2117 2007 3078 2006 2157 1998 3905 2006 2187 1012 1999 2119 2291 1996 2157 8080 2707 1999 3233 1011 2011 1012 1996 2069 5549 2000 10509 21466 2009 2003 2006 3898 10906 1998 26709 6593 17441 1013 10509 17441 1996 2117 8080 102 1026 1026 1026 4005 1028 1028 1028 1024 10262 3645 2184 1012 1012 1012 3437 1011 2011 1011 2193 1024 1015 1012 2043 1006 22480 1012 3058 1007 2106 2017 5309 1996 3274 1029 1016 1012 2106 1996 3274 2272 2007 2663 10790 3653 7076 9080 3709 1010 2106 2017 2079 1037 4550 16500 1997 2663 10790 1010 2030 2106 2017 12200 1037 2663 2581 3274 2030 1037 2663 2620 1012 1015 3274 1031 1026 1027 4060 2028 999 1033 2000 2663 10790 1029 1017 1012 2040 7609 1996 3274 1006 1041 1012 1043 1012 1010 12418 1025 6522 1025 9078 2099 1025 18798 16059 1025 2004 2271 1007 1029 1018 1012 2038 1037 10770 4646 2030 1037 22432 7959 2063 4646 2412 2042 5361 2006 102\n","09/07/2021 11:42:41 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","09/07/2021 11:42:41 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","09/07/2021 11:42:41 - INFO - utils_glue -   label: 0 (id = 0)\n","09/07/2021 11:42:41 - INFO - utils_glue -   *** Example ***\n","09/07/2021 11:42:41 - INFO - utils_glue -   guid: dev-3\n","09/07/2021 11:42:41 - INFO - utils_glue -   tokens: [CLS] two system in our office with dual monitor configuration , windows 10 pro x ##64 1703 . after install kb ##40 ##38 ##7 ##8 ##8 update , on boot after shut ##down ( not after restart ) the second monitor remains in stand by . on both system , i see the win logo and on log ##in the right monitor go in stand by mode . one system is con ##fi ##gur ##ated with primary monitor on left and secondary on right , second with primary on right and secondary on left . in both system the right monitor start in stand - by . the only mode to react ##ivate it is on screen settings and dea ##ct ##ivating / react ##ivating the second monitor [SEP] < < < agent > > > : f ##yi , my ms ##e ' s update tab says that def ##s v ##1 . 251 . 232 . 0 were installed at 7 : 05 pm last ni ##te yet windows update tells me that v ##1 . 249 . 211 . 0 ( released on 25 july 2017 ) is available again ! ps : yes , i ' ve tested installing v ##1 . 249 . 211 . 0 as offered via windows update multiple times . each and every time , it successfully \" \" install ##s \" \" in mill ##ise ##con ##ds yet the def ##s version in ms ##e ' s update tab has changed and dates from within [SEP]\n","09/07/2021 11:42:41 - INFO - utils_glue -   input_ids: 101 2048 2291 1999 2256 2436 2007 7037 8080 9563 1010 3645 2184 4013 1060 21084 28366 1012 2044 16500 21677 12740 22025 2581 2620 2620 10651 1010 2006 9573 2044 3844 7698 1006 2025 2044 23818 1007 1996 2117 8080 3464 1999 3233 2011 1012 2006 2119 2291 1010 1045 2156 1996 2663 8154 1998 2006 8833 2378 1996 2157 8080 2175 1999 3233 2011 5549 1012 2028 2291 2003 9530 8873 27390 4383 2007 3078 8080 2006 2187 1998 3905 2006 2157 1010 2117 2007 3078 2006 2157 1998 3905 2006 2187 1012 1999 2119 2291 1996 2157 8080 2707 1999 3233 1011 2011 1012 1996 2069 5549 2000 10509 21466 2009 2003 2006 3898 10906 1998 26709 6593 17441 1013 10509 17441 1996 2117 8080 102 1026 1026 1026 4005 1028 1028 1028 1024 1042 10139 1010 2026 5796 2063 1005 1055 10651 21628 2758 2008 13366 2015 1058 2487 1012 22582 1012 20666 1012 1014 2020 5361 2012 1021 1024 5709 7610 2197 9152 2618 2664 3645 10651 4136 2033 2008 1058 2487 1012 23628 1012 19235 1012 1014 1006 2207 2006 2423 2251 2418 1007 2003 2800 2153 999 8827 1024 2748 1010 1045 1005 2310 7718 23658 1058 2487 1012 23628 1012 19235 1012 1014 2004 3253 3081 3645 10651 3674 2335 1012 2169 1998 2296 2051 1010 2009 5147 1000 1000 16500 2015 1000 1000 1999 4971 5562 8663 5104 2664 1996 13366 2015 2544 1999 5796 2063 1005 1055 10651 21628 2038 2904 1998 5246 2013 2306 102\n","09/07/2021 11:42:41 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","09/07/2021 11:42:41 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","09/07/2021 11:42:41 - INFO - utils_glue -   label: 0 (id = 0)\n","09/07/2021 11:42:41 - INFO - utils_glue -   *** Example ***\n","09/07/2021 11:42:41 - INFO - utils_glue -   guid: dev-4\n","09/07/2021 11:42:41 - INFO - utils_glue -   tokens: [CLS] two system in our office with dual monitor configuration , windows 10 pro x ##64 1703 . after install kb ##40 ##38 ##7 ##8 ##8 update , on boot after shut ##down ( not after restart ) the second monitor remains in stand by . on both system , i see the win logo and on log ##in the right monitor go in stand by mode . one system is con ##fi ##gur ##ated with primary monitor on left and secondary on right , second with primary on right and secondary on left . in both system the right monitor start in stand - by . the only mode to react ##ivate it is on screen settings and dea ##ct ##ivating / react ##ivating the second monitor [SEP] < < < agent > > > : hello shit ##aki ##bu ##ile ##s and philip ##ger ##ber ##ich , thank you for posting your concern in microsoft community . we understand that you are unable to access your emails via outlook . com . person _ place ##holder , you have mentioned that even you try access ##ing your emails via different browser you still get the same result . for further steps to rec ##tify your case , we also suggest that you reset your browser settings , di ##sable fire ##wall or any anti - filtering program installed on your computer and update your browser version . to do this , kindly perform the steps on the link below : is internet explorer [SEP]\n","09/07/2021 11:42:41 - INFO - utils_glue -   input_ids: 101 2048 2291 1999 2256 2436 2007 7037 8080 9563 1010 3645 2184 4013 1060 21084 28366 1012 2044 16500 21677 12740 22025 2581 2620 2620 10651 1010 2006 9573 2044 3844 7698 1006 2025 2044 23818 1007 1996 2117 8080 3464 1999 3233 2011 1012 2006 2119 2291 1010 1045 2156 1996 2663 8154 1998 2006 8833 2378 1996 2157 8080 2175 1999 3233 2011 5549 1012 2028 2291 2003 9530 8873 27390 4383 2007 3078 8080 2006 2187 1998 3905 2006 2157 1010 2117 2007 3078 2006 2157 1998 3905 2006 2187 1012 1999 2119 2291 1996 2157 8080 2707 1999 3233 1011 2011 1012 1996 2069 5549 2000 10509 21466 2009 2003 2006 3898 10906 1998 26709 6593 17441 1013 10509 17441 1996 2117 8080 102 1026 1026 1026 4005 1028 1028 1028 1024 7592 4485 8978 8569 9463 2015 1998 5170 4590 5677 7033 1010 4067 2017 2005 14739 2115 5142 1999 7513 2451 1012 2057 3305 2008 2017 2024 4039 2000 3229 2115 22028 3081 17680 1012 4012 1012 2711 1035 2173 14528 1010 2017 2031 3855 2008 2130 2017 3046 3229 2075 2115 22028 3081 2367 16602 2017 2145 2131 1996 2168 2765 1012 2005 2582 4084 2000 28667 27351 2115 2553 1010 2057 2036 6592 2008 2017 25141 2115 16602 10906 1010 4487 19150 2543 9628 2030 2151 3424 1011 22910 2565 5361 2006 2115 3274 1998 10651 2115 16602 2544 1012 2000 2079 2023 1010 19045 4685 1996 4084 2006 1996 4957 2917 1024 2003 4274 10566 102\n","09/07/2021 11:42:41 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","09/07/2021 11:42:41 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","09/07/2021 11:42:41 - INFO - utils_glue -   label: 0 (id = 0)\n","09/07/2021 11:44:19 - INFO - utils_glue -   Writing example 10000 of 37210\n","09/07/2021 11:45:41 - INFO - utils_glue -   Writing example 20000 of 37210\n","09/07/2021 11:47:16 - INFO - utils_glue -   Writing example 30000 of 37210\n","09/07/2021 11:48:23 - INFO - __main__ -   Saving features into cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_256_ms_v2\n","09/07/2021 11:48:35 - INFO - __main__ -   ***** Running evaluation  *****\n","09/07/2021 11:48:35 - INFO - __main__ -     Num examples = 37210\n","09/07/2021 11:48:35 - INFO - __main__ -     Batch size = 8\n","09/07/2021 12:09:39 - INFO - __main__ -   ***** Eval results  *****\n","09/07/2021 12:09:39 - INFO - __main__ -     map = 0.7267057839887724\n","09/07/2021 12:10:45 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_6/checkpoint-best_run_cl__seed_42\n","09/07/2021 12:24:43 - INFO - __main__ -   Iter = 2000.0\n","09/07/2021 12:24:43 - INFO - __main__ -   lr = 1.6929218486104714e-05\n","09/07/2021 12:24:43 - INFO - __main__ -   loss = 0.45672454622387887\n","09/07/2021 12:24:43 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_256_ms_v2\n","09/07/2021 12:24:51 - INFO - __main__ -   ***** Running evaluation  *****\n","09/07/2021 12:24:51 - INFO - __main__ -     Num examples = 37210\n","09/07/2021 12:24:51 - INFO - __main__ -     Batch size = 8\n","09/07/2021 12:45:47 - INFO - __main__ -   ***** Eval results  *****\n","09/07/2021 12:45:47 - INFO - __main__ -     map = 0.7471553559164423\n","09/07/2021 12:45:49 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_6/checkpoint-best_run_cl__seed_42\n","09/07/2021 12:59:51 - INFO - __main__ -   Iter = 3000.0\n","09/07/2021 12:59:51 - INFO - __main__ -   lr = 1.5393827729157073e-05\n","09/07/2021 12:59:51 - INFO - __main__ -   loss = 0.4187464979942888\n","09/07/2021 12:59:51 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_256_ms_v2\n","09/07/2021 12:59:59 - INFO - __main__ -   ***** Running evaluation  *****\n","09/07/2021 12:59:59 - INFO - __main__ -     Num examples = 37210\n","09/07/2021 12:59:59 - INFO - __main__ -     Batch size = 8\n","09/07/2021 13:20:55 - INFO - __main__ -   ***** Eval results  *****\n","09/07/2021 13:20:55 - INFO - __main__ -     map = 0.7543291400587837\n","09/07/2021 13:20:57 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_6/checkpoint-best_run_cl__seed_42\n","09/07/2021 13:34:59 - INFO - __main__ -   Iter = 4000.0\n","09/07/2021 13:34:59 - INFO - __main__ -   lr = 1.3858436972209429e-05\n","09/07/2021 13:34:59 - INFO - __main__ -   loss = 0.3751625438556075\n","09/07/2021 13:34:59 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_256_ms_v2\n","09/07/2021 13:35:07 - INFO - __main__ -   ***** Running evaluation  *****\n","09/07/2021 13:35:07 - INFO - __main__ -     Num examples = 37210\n","09/07/2021 13:35:07 - INFO - __main__ -     Batch size = 8\n","09/07/2021 13:56:03 - INFO - __main__ -   ***** Eval results  *****\n","09/07/2021 13:56:03 - INFO - __main__ -     map = 0.7641212679643204\n","09/07/2021 13:56:05 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_6/checkpoint-best_run_cl__seed_42\n","09/07/2021 14:00:53 - INFO - __main__ -   Finished epoch with 4342 iterations.\n","09/07/2021 14:00:53 - INFO - __main__ -   Starting epoch 2\n","09/07/2021 14:00:53 - INFO - __main__ -   Training with all_random_batches\n","Traceback (most recent call last):\n","  File \"drive/MyDrive/transformers_cl/run_glue.py\", line 712, in <module>\n","  File \"drive/MyDrive/transformers_cl/run_glue.py\", line 659, in main\n","    global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n","  File \"drive/MyDrive/transformers_cl/run_glue.py\", line 233, in train\n","    optimizer.step()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n","    return wrapped(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py\", line 176, in step\n","    p.data.addcdiv_(-step_size, exp_avg, denom)\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","metadata":{"id":"0QXXO_wOkKc-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631024592455,"user_tz":-120,"elapsed":1267878,"user":{"displayName":"T. Z.","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04670299702794629529"}},"outputId":"be3e5cda-7163-4889-b146-0a6144337d58"},"source":["!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  ms_v2 \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/MSDialog \\\n","    --max_seq_length 256 \\\n","    --per_gpu_eval_batch_size=8   \\\n","    --per_gpu_train_batch_size=8   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 3 \\\n","    --output_dir drive/MyDrive/transformers_cl/ms_v2_bert_6/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 1000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["09/07/2021 14:02:05 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","09/07/2021 14:02:05 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","09/07/2021 14:02:05 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"ms_v2\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","09/07/2021 14:02:05 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","09/07/2021 14:02:06 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","09/07/2021 14:02:09 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","09/07/2021 14:02:09 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","09/07/2021 14:02:11 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', cached_features_file_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/MSDialog', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=False, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=-1, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=1000, max_grad_norm=1.0, max_seq_length=256, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise=0.0, num_train_epochs=3.0, output_dir='drive/MyDrive/transformers_cl/ms_v2_bert_6/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, percentage_data_by_epoch=1.0, reset_clf_weights=False, resume_epoch=1.0, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='ms_v2', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","09/07/2021 14:02:15 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_train_bert-base-uncased_256_ms_v2\n","09/07/2021 14:02:22 - INFO - __main__ -   ***** Running evaluation best_run_cl__seed_42 *****\n","09/07/2021 14:02:22 - INFO - __main__ -     Num examples = 34736\n","09/07/2021 14:02:22 - INFO - __main__ -     Batch size = 2\n","09/07/2021 14:23:10 - INFO - __main__ -   ***** Eval results best_run_cl__seed_42 *****\n","09/07/2021 14:23:10 - INFO - __main__ -     map = 0.9719023491478581\n"]}]},{"cell_type":"markdown","metadata":{"id":"GpDelKWbZpXK"},"source":["# 09-07 batch_size = 8, max_seq_length = 512"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pl8kDapFA8UC","outputId":"d71ef77a-eabd-4ab5-d1e1-cb464c374188"},"source":["# running time 4h30m for less than 1 epoch \n","!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  ms_v2 \\\n","    --do_train \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/MSDialog \\\n","    --max_seq_length 512 \\\n","    --per_gpu_eval_batch_size=8   \\\n","    --per_gpu_train_batch_size=8   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 3 \\\n","    --output_dir drive/MyDrive/transformers_cl/ms_v2_bert_6/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 1000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["09/07/2021 07:16:21 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","09/07/2021 07:16:22 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","09/07/2021 07:16:22 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"ms_v2\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","09/07/2021 07:16:23 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","09/07/2021 07:16:24 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","09/07/2021 07:16:27 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","09/07/2021 07:16:27 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","09/07/2021 07:16:29 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', cached_features_file_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/MSDialog', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=-1, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=1000, max_grad_norm=1.0, max_seq_length=512, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise=0.0, num_train_epochs=3.0, output_dir='drive/MyDrive/transformers_cl/ms_v2_bert_6/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, percentage_data_by_epoch=1.0, reset_clf_weights=False, resume_epoch=1.0, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='ms_v2', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","09/07/2021 07:16:29 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_train_bert-base-uncased_512_ms_v2\n","09/07/2021 07:16:43 - INFO - __main__ -   ***** Running training *****\n","09/07/2021 07:16:43 - INFO - __main__ -     Num examples = 34736\n","09/07/2021 07:16:43 - INFO - __main__ -     Num Epochs = 3\n","09/07/2021 07:16:43 - INFO - __main__ -     Instantaneous batch size per GPU = 8\n","09/07/2021 07:16:43 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 8\n","09/07/2021 07:16:43 - INFO - __main__ -     Gradient Accumulation steps = 1\n","09/07/2021 07:16:43 - INFO - __main__ -     Total optimization steps = 13026\n","09/07/2021 07:16:43 - INFO - __main__ -     percentage by epoch = 1.000000\n","09/07/2021 07:16:43 - INFO - __main__ -     data_loaders = [('all_random_batches', <torch.utils.data.dataloader.DataLoader object at 0x7fc1ab0906d0>)]\n","09/07/2021 07:16:43 - INFO - __main__ -   Starting epoch 1\n","09/07/2021 07:16:43 - INFO - __main__ -   Training with all_random_batches\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","09/07/2021 07:42:03 - INFO - __main__ -   Iter = 1000.0\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","09/07/2021 07:42:03 - INFO - __main__ -   lr = 1.8464609243052358e-05\n","09/07/2021 07:42:03 - INFO - __main__ -   loss = 0.5123689046166837\n","09/07/2021 07:42:03 - INFO - __main__ -   Creating features from dataset file at drive/MyDrive/MSDialog\n","09/07/2021 07:42:08 - INFO - utils_glue -   Writing example 0 of 37210\n","09/07/2021 07:42:08 - INFO - utils_glue -   *** Example ***\n","09/07/2021 07:42:08 - INFO - utils_glue -   guid: dev-0\n","09/07/2021 07:42:08 - INFO - utils_glue -   tokens: [CLS] two system in our office with dual monitor configuration , windows 10 pro x ##64 1703 . after install kb ##40 ##38 ##7 ##8 ##8 update , on boot after shut ##down ( not after restart ) the second monitor remains in stand by . on both system , i see the win logo and on log ##in the right monitor go in stand by mode . one system is con ##fi ##gur ##ated with primary monitor on left and secondary on right , second with primary on right and secondary on left . in both system the right monitor start in stand - by . the only mode to react ##ivate it is on screen settings and dea ##ct ##ivating / react ##ivating the second monitor . in one system i have un ##ins ##tal ##l the update and it has returned normal , but in the other the un ##ins ##tal ##l procedure has not been successful . both graphic board are ra ##de ##on hd with default microsoft driver . any idea or suggestion to solve the problem ? thank ' s in advance moved from : ( windows / windows 10 / windows update , recovery , & backup / pc ) do the computers - in - question belong to you or to your employer ? ps : you ' re certainly not alone ! = > https : / / goo . g ##l / cp ##gy ##f ##j hi person _ place ##holder , thank you for your [SEP] < < < agent > > > : assuming ( a ) both computers were running windows 7 , and ( b ) the upgrade from win ##7 to win ##10 was offered and installed via windows update ( i . e . , you did not upgrade manually ) , and ( c ) creators update / win ##10 1703 was also offered and installed via windows update , and ( d ) kb ##40 ##38 ##7 ##8 ##8 was also offered and installed via windows update . . . , possibilities include : note : all of the above are not unusual with win ##10 installed on aging - in - place , custom built systems . important ! = > neither computer should be connected to the internet or a local network if kb ##40 ##38 ##7 ##8 ##8 has been un ##ins ##tal ##led & hidden . the above notwithstanding , this is a consumer - specific forum . you may be better off posting in the it pro - specific forums for appropriate assistance : https : / / social . tech ##net . microsoft . com / forums / en - us / home ? category = windows ##10 ##it ##pro you may obtain third - party , microsoft - sponsored - but not necessarily free - support via windows support / answer desk - direct chat assistance = > https : / / support . microsoft . com / en - us / contact / chat / [SEP]\n","09/07/2021 07:42:08 - INFO - utils_glue -   input_ids: 101 2048 2291 1999 2256 2436 2007 7037 8080 9563 1010 3645 2184 4013 1060 21084 28366 1012 2044 16500 21677 12740 22025 2581 2620 2620 10651 1010 2006 9573 2044 3844 7698 1006 2025 2044 23818 1007 1996 2117 8080 3464 1999 3233 2011 1012 2006 2119 2291 1010 1045 2156 1996 2663 8154 1998 2006 8833 2378 1996 2157 8080 2175 1999 3233 2011 5549 1012 2028 2291 2003 9530 8873 27390 4383 2007 3078 8080 2006 2187 1998 3905 2006 2157 1010 2117 2007 3078 2006 2157 1998 3905 2006 2187 1012 1999 2119 2291 1996 2157 8080 2707 1999 3233 1011 2011 1012 1996 2069 5549 2000 10509 21466 2009 2003 2006 3898 10906 1998 26709 6593 17441 1013 10509 17441 1996 2117 8080 1012 1999 2028 2291 1045 2031 4895 7076 9080 2140 1996 10651 1998 2009 2038 2513 3671 1010 2021 1999 1996 2060 1996 4895 7076 9080 2140 7709 2038 2025 2042 3144 1012 2119 8425 2604 2024 10958 3207 2239 10751 2007 12398 7513 4062 1012 2151 2801 2030 10293 2000 9611 1996 3291 1029 4067 1005 1055 1999 5083 2333 2013 1024 1006 3645 1013 3645 2184 1013 3645 10651 1010 7233 1010 1004 10200 1013 7473 1007 2079 1996 7588 1011 1999 1011 3160 7141 2000 2017 2030 2000 2115 11194 1029 8827 1024 2017 1005 2128 5121 2025 2894 999 1027 1028 16770 1024 1013 1013 27571 1012 1043 2140 1013 18133 6292 2546 3501 7632 2711 1035 2173 14528 1010 4067 2017 2005 2115 102 1026 1026 1026 4005 1028 1028 1028 1024 10262 1006 1037 1007 2119 7588 2020 2770 3645 1021 1010 1998 1006 1038 1007 1996 12200 2013 2663 2581 2000 2663 10790 2001 3253 1998 5361 3081 3645 10651 1006 1045 1012 1041 1012 1010 2017 2106 2025 12200 21118 1007 1010 1998 1006 1039 1007 17277 10651 1013 2663 10790 28366 2001 2036 3253 1998 5361 3081 3645 10651 1010 1998 1006 1040 1007 21677 12740 22025 2581 2620 2620 2001 2036 3253 1998 5361 3081 3645 10651 1012 1012 1012 1010 12020 2421 1024 3602 1024 2035 1997 1996 2682 2024 2025 5866 2007 2663 10790 5361 2006 12520 1011 1999 1011 2173 1010 7661 2328 3001 1012 2590 999 1027 1028 4445 3274 2323 2022 4198 2000 1996 4274 2030 1037 2334 2897 2065 21677 12740 22025 2581 2620 2620 2038 2042 4895 7076 9080 3709 1004 5023 1012 1996 2682 26206 1010 2023 2003 1037 7325 1011 3563 7057 1012 2017 2089 2022 2488 2125 14739 1999 1996 2009 4013 1011 3563 21415 2005 6413 5375 1024 16770 1024 1013 1013 2591 1012 6627 7159 1012 7513 1012 4012 1013 21415 1013 4372 1011 2149 1013 2188 1029 4696 1027 3645 10790 4183 21572 2017 2089 6855 2353 1011 2283 1010 7513 1011 6485 1011 2021 2025 9352 2489 1011 2490 3081 3645 2490 1013 3437 4624 1011 3622 11834 5375 1027 1028 16770 1024 1013 1013 2490 1012 7513 1012 4012 1013 4372 1011 2149 1013 3967 1013 11834 1013 102\n","09/07/2021 07:42:08 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","09/07/2021 07:42:08 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","09/07/2021 07:42:08 - INFO - utils_glue -   label: 1 (id = 1)\n","09/07/2021 07:42:08 - INFO - utils_glue -   *** Example ***\n","09/07/2021 07:42:08 - INFO - utils_glue -   guid: dev-1\n","09/07/2021 07:42:08 - INFO - utils_glue -   tokens: [CLS] two system in our office with dual monitor configuration , windows 10 pro x ##64 1703 . after install kb ##40 ##38 ##7 ##8 ##8 update , on boot after shut ##down ( not after restart ) the second monitor remains in stand by . on both system , i see the win logo and on log ##in the right monitor go in stand by mode . one system is con ##fi ##gur ##ated with primary monitor on left and secondary on right , second with primary on right and secondary on left . in both system the right monitor start in stand - by . the only mode to react ##ivate it is on screen settings and dea ##ct ##ivating / react ##ivating the second monitor . in one system i have un ##ins ##tal ##l the update and it has returned normal , but in the other the un ##ins ##tal ##l procedure has not been successful . both graphic board are ra ##de ##on hd with default microsoft driver . any idea or suggestion to solve the problem ? thank ' s in advance moved from : ( windows / windows 10 / windows update , recovery , & backup / pc ) do the computers - in - question belong to you or to your employer ? ps : you ' re certainly not alone ! = > https : / / goo . g ##l / cp ##gy ##f ##j hi person _ place ##holder , thank you for your [SEP] < < < agent > > > : 1 . is the computer still under warrant ##y ? 2 . what os build of windows 10 1703 [ aka creators update ] is currently installed ? 3 . are protection update definitions up - to - date according to windows defender security center ' s virus & threat protection tab ? 4 . what happens when you click on the update button on that tab ? 5 . have you done a reset and / or a ref ##resh since you purchased the computer ? 6 ##a . what country or region is currently selected in settings | time & language | region & language < = this window / tab ? 6 ##b . are you currently physically located in that country or region ? ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ comment : the time format disc ##re ##pan ##cy may be a yet - to - be - fixed \" \" bug \" \" in win 10 version 1703 . see https : / / answers . microsoft . com / en - us / windows / forum / windows _ vista - desktop / windows - defender - scan - status - displays - wrong - date / 510 ##a ##9 ##28 ##1 - [SEP]\n","09/07/2021 07:42:08 - INFO - utils_glue -   input_ids: 101 2048 2291 1999 2256 2436 2007 7037 8080 9563 1010 3645 2184 4013 1060 21084 28366 1012 2044 16500 21677 12740 22025 2581 2620 2620 10651 1010 2006 9573 2044 3844 7698 1006 2025 2044 23818 1007 1996 2117 8080 3464 1999 3233 2011 1012 2006 2119 2291 1010 1045 2156 1996 2663 8154 1998 2006 8833 2378 1996 2157 8080 2175 1999 3233 2011 5549 1012 2028 2291 2003 9530 8873 27390 4383 2007 3078 8080 2006 2187 1998 3905 2006 2157 1010 2117 2007 3078 2006 2157 1998 3905 2006 2187 1012 1999 2119 2291 1996 2157 8080 2707 1999 3233 1011 2011 1012 1996 2069 5549 2000 10509 21466 2009 2003 2006 3898 10906 1998 26709 6593 17441 1013 10509 17441 1996 2117 8080 1012 1999 2028 2291 1045 2031 4895 7076 9080 2140 1996 10651 1998 2009 2038 2513 3671 1010 2021 1999 1996 2060 1996 4895 7076 9080 2140 7709 2038 2025 2042 3144 1012 2119 8425 2604 2024 10958 3207 2239 10751 2007 12398 7513 4062 1012 2151 2801 2030 10293 2000 9611 1996 3291 1029 4067 1005 1055 1999 5083 2333 2013 1024 1006 3645 1013 3645 2184 1013 3645 10651 1010 7233 1010 1004 10200 1013 7473 1007 2079 1996 7588 1011 1999 1011 3160 7141 2000 2017 2030 2000 2115 11194 1029 8827 1024 2017 1005 2128 5121 2025 2894 999 1027 1028 16770 1024 1013 1013 27571 1012 1043 2140 1013 18133 6292 2546 3501 7632 2711 1035 2173 14528 1010 4067 2017 2005 2115 102 1026 1026 1026 4005 1028 1028 1028 1024 1015 1012 2003 1996 3274 2145 2104 10943 2100 1029 1016 1012 2054 9808 3857 1997 3645 2184 28366 1031 9875 17277 10651 1033 2003 2747 5361 1029 1017 1012 2024 3860 10651 15182 2039 1011 2000 1011 3058 2429 2000 3645 8291 3036 2415 1005 1055 7865 1004 5081 3860 21628 1029 1018 1012 2054 6433 2043 2017 11562 2006 1996 10651 6462 2006 2008 21628 1029 1019 1012 2031 2017 2589 1037 25141 1998 1013 2030 1037 25416 21898 2144 2017 4156 1996 3274 1029 1020 2050 1012 2054 2406 2030 2555 2003 2747 3479 1999 10906 1064 2051 1004 2653 1064 2555 1004 2653 1026 1027 2023 3332 1013 21628 1029 1020 2497 1012 2024 2017 2747 8186 2284 1999 2008 2406 2030 2555 1029 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 1066 7615 1024 1996 2051 4289 5860 2890 9739 5666 2089 2022 1037 2664 1011 2000 1011 2022 1011 4964 1000 1000 11829 1000 1000 1999 2663 2184 2544 28366 1012 2156 16770 1024 1013 1013 6998 1012 7513 1012 4012 1013 4372 1011 2149 1013 3645 1013 7057 1013 3645 1035 13005 1011 15363 1013 3645 1011 8291 1011 13594 1011 3570 1011 8834 1011 3308 1011 3058 1013 23475 2050 2683 22407 2487 1011 102\n","09/07/2021 07:42:08 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","09/07/2021 07:42:08 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","09/07/2021 07:42:08 - INFO - utils_glue -   label: 0 (id = 0)\n","09/07/2021 07:42:08 - INFO - utils_glue -   *** Example ***\n","09/07/2021 07:42:08 - INFO - utils_glue -   guid: dev-2\n","09/07/2021 07:42:08 - INFO - utils_glue -   tokens: [CLS] two system in our office with dual monitor configuration , windows 10 pro x ##64 1703 . after install kb ##40 ##38 ##7 ##8 ##8 update , on boot after shut ##down ( not after restart ) the second monitor remains in stand by . on both system , i see the win logo and on log ##in the right monitor go in stand by mode . one system is con ##fi ##gur ##ated with primary monitor on left and secondary on right , second with primary on right and secondary on left . in both system the right monitor start in stand - by . the only mode to react ##ivate it is on screen settings and dea ##ct ##ivating / react ##ivating the second monitor . in one system i have un ##ins ##tal ##l the update and it has returned normal , but in the other the un ##ins ##tal ##l procedure has not been successful . both graphic board are ra ##de ##on hd with default microsoft driver . any idea or suggestion to solve the problem ? thank ' s in advance moved from : ( windows / windows 10 / windows update , recovery , & backup / pc ) do the computers - in - question belong to you or to your employer ? ps : you ' re certainly not alone ! = > https : / / goo . g ##l / cp ##gy ##f ##j hi person _ place ##holder , thank you for your interest i ' m my employer . . . : ) the computers are self - made - assembled about 5 - 7 years ago mb socket 77 ##5 , cpu core ##2 840 ##0 , ram 8 ##gb , sk video ra ##de ##on hd 450 ##0 series . operating systems from xp to seven to windows 10 always in dual monitor configuration without any special problems . as mentioned earlier , the problem started after the kb ##40 ##38 ##7 ##8 ##8 update [SEP] < < < agent > > > : assuming windows 10 . . . answer - by - number : 1 . when ( approx . date ) did you purchase the computer ? 2 . did the computer come with win ##10 pre ##ins ##tal ##led , did you do a clean install of win ##10 , or did you upgrade a win ##7 computer or a win ##8 . 1 computer [ < = pick one ! ] to win ##10 ? 3 . who manufactured the computer ( e . g . , dell ; hp ; ace ##r ; len ##ovo ; as ##us ) ? 4 . has a norton application or a mca ##fe ##e application ever been installed on the computer since you bought it ? 5 . have you ever run the norton removal tool and / or the mca ##fe ##e consumer products removal tool ? 6 . what version & os build of windows 10 is currently installed ? [SEP]\n","09/07/2021 07:42:08 - INFO - utils_glue -   input_ids: 101 2048 2291 1999 2256 2436 2007 7037 8080 9563 1010 3645 2184 4013 1060 21084 28366 1012 2044 16500 21677 12740 22025 2581 2620 2620 10651 1010 2006 9573 2044 3844 7698 1006 2025 2044 23818 1007 1996 2117 8080 3464 1999 3233 2011 1012 2006 2119 2291 1010 1045 2156 1996 2663 8154 1998 2006 8833 2378 1996 2157 8080 2175 1999 3233 2011 5549 1012 2028 2291 2003 9530 8873 27390 4383 2007 3078 8080 2006 2187 1998 3905 2006 2157 1010 2117 2007 3078 2006 2157 1998 3905 2006 2187 1012 1999 2119 2291 1996 2157 8080 2707 1999 3233 1011 2011 1012 1996 2069 5549 2000 10509 21466 2009 2003 2006 3898 10906 1998 26709 6593 17441 1013 10509 17441 1996 2117 8080 1012 1999 2028 2291 1045 2031 4895 7076 9080 2140 1996 10651 1998 2009 2038 2513 3671 1010 2021 1999 1996 2060 1996 4895 7076 9080 2140 7709 2038 2025 2042 3144 1012 2119 8425 2604 2024 10958 3207 2239 10751 2007 12398 7513 4062 1012 2151 2801 2030 10293 2000 9611 1996 3291 1029 4067 1005 1055 1999 5083 2333 2013 1024 1006 3645 1013 3645 2184 1013 3645 10651 1010 7233 1010 1004 10200 1013 7473 1007 2079 1996 7588 1011 1999 1011 3160 7141 2000 2017 2030 2000 2115 11194 1029 8827 1024 2017 1005 2128 5121 2025 2894 999 1027 1028 16770 1024 1013 1013 27571 1012 1043 2140 1013 18133 6292 2546 3501 7632 2711 1035 2173 14528 1010 4067 2017 2005 2115 3037 1045 1005 1049 2026 11194 1012 1012 1012 1024 1007 1996 7588 2024 2969 1011 2081 1011 9240 2055 1019 1011 1021 2086 3283 16914 22278 6255 2629 1010 17368 4563 2475 28122 2692 1010 8223 1022 18259 1010 15315 2678 10958 3207 2239 10751 10332 2692 2186 1012 4082 3001 2013 26726 2000 2698 2000 3645 2184 2467 1999 7037 8080 9563 2302 2151 2569 3471 1012 2004 3855 3041 1010 1996 3291 2318 2044 1996 21677 12740 22025 2581 2620 2620 10651 102 1026 1026 1026 4005 1028 1028 1028 1024 10262 3645 2184 1012 1012 1012 3437 1011 2011 1011 2193 1024 1015 1012 2043 1006 22480 1012 3058 1007 2106 2017 5309 1996 3274 1029 1016 1012 2106 1996 3274 2272 2007 2663 10790 3653 7076 9080 3709 1010 2106 2017 2079 1037 4550 16500 1997 2663 10790 1010 2030 2106 2017 12200 1037 2663 2581 3274 2030 1037 2663 2620 1012 1015 3274 1031 1026 1027 4060 2028 999 1033 2000 2663 10790 1029 1017 1012 2040 7609 1996 3274 1006 1041 1012 1043 1012 1010 12418 1025 6522 1025 9078 2099 1025 18798 16059 1025 2004 2271 1007 1029 1018 1012 2038 1037 10770 4646 2030 1037 22432 7959 2063 4646 2412 2042 5361 2006 1996 3274 2144 2017 4149 2009 1029 1019 1012 2031 2017 2412 2448 1996 10770 8208 6994 1998 1013 2030 1996 22432 7959 2063 7325 3688 8208 6994 1029 1020 1012 2054 2544 1004 9808 3857 1997 3645 2184 2003 2747 5361 1029 102\n","09/07/2021 07:42:08 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","09/07/2021 07:42:08 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","09/07/2021 07:42:08 - INFO - utils_glue -   label: 0 (id = 0)\n","09/07/2021 07:42:08 - INFO - utils_glue -   *** Example ***\n","09/07/2021 07:42:08 - INFO - utils_glue -   guid: dev-3\n","09/07/2021 07:42:08 - INFO - utils_glue -   tokens: [CLS] two system in our office with dual monitor configuration , windows 10 pro x ##64 1703 . after install kb ##40 ##38 ##7 ##8 ##8 update , on boot after shut ##down ( not after restart ) the second monitor remains in stand by . on both system , i see the win logo and on log ##in the right monitor go in stand by mode . one system is con ##fi ##gur ##ated with primary monitor on left and secondary on right , second with primary on right and secondary on left . in both system the right monitor start in stand - by . the only mode to react ##ivate it is on screen settings and dea ##ct ##ivating / react ##ivating the second monitor . in one system i have un ##ins ##tal ##l the update and it has returned normal , but in the other the un ##ins ##tal ##l procedure has not been successful . both graphic board are ra ##de ##on hd with default microsoft driver . any idea or suggestion to solve the problem ? thank ' s in advance moved from : ( windows / windows 10 / windows update , recovery , & backup / pc ) do the computers - in - question belong to you or to your employer ? ps : you ' re certainly not alone ! = > https : / / goo . g ##l / cp ##gy ##f ##j hi person _ place ##holder , thank you for your interest i ' m my employer . . . : ) the computers are self - made - assembled about 5 - 7 years ago mb socket 77 ##5 , cpu core ##2 840 ##0 , ram 8 ##gb , sk video ra ##de ##on hd 450 ##0 series . operating systems from xp to seven to windows 10 always in dual monitor configuration without any special problems . as mentioned earlier , the problem started after the kb ##40 ##38 ##7 ##8 ##8 update , when i start the computer , the right monitor stays in stand ##by mode . now that i think , in both systems , monitors that are in stand ##by are connected to d ##vi . [SEP] < < < agent > > > : f ##yi , my ms ##e ' s update tab says that def ##s v ##1 . 251 . 232 . 0 were installed at 7 : 05 pm last ni ##te yet windows update tells me that v ##1 . 249 . 211 . 0 ( released on 25 july 2017 ) is available again ! ps : yes , i ' ve tested installing v ##1 . 249 . 211 . 0 as offered via windows update multiple times . each and every time , it successfully \" \" install ##s \" \" in mill ##ise ##con ##ds yet the def ##s version in ms ##e ' s update tab has changed and dates from within the past 24 hours or s [SEP]\n","09/07/2021 07:42:08 - INFO - utils_glue -   input_ids: 101 2048 2291 1999 2256 2436 2007 7037 8080 9563 1010 3645 2184 4013 1060 21084 28366 1012 2044 16500 21677 12740 22025 2581 2620 2620 10651 1010 2006 9573 2044 3844 7698 1006 2025 2044 23818 1007 1996 2117 8080 3464 1999 3233 2011 1012 2006 2119 2291 1010 1045 2156 1996 2663 8154 1998 2006 8833 2378 1996 2157 8080 2175 1999 3233 2011 5549 1012 2028 2291 2003 9530 8873 27390 4383 2007 3078 8080 2006 2187 1998 3905 2006 2157 1010 2117 2007 3078 2006 2157 1998 3905 2006 2187 1012 1999 2119 2291 1996 2157 8080 2707 1999 3233 1011 2011 1012 1996 2069 5549 2000 10509 21466 2009 2003 2006 3898 10906 1998 26709 6593 17441 1013 10509 17441 1996 2117 8080 1012 1999 2028 2291 1045 2031 4895 7076 9080 2140 1996 10651 1998 2009 2038 2513 3671 1010 2021 1999 1996 2060 1996 4895 7076 9080 2140 7709 2038 2025 2042 3144 1012 2119 8425 2604 2024 10958 3207 2239 10751 2007 12398 7513 4062 1012 2151 2801 2030 10293 2000 9611 1996 3291 1029 4067 1005 1055 1999 5083 2333 2013 1024 1006 3645 1013 3645 2184 1013 3645 10651 1010 7233 1010 1004 10200 1013 7473 1007 2079 1996 7588 1011 1999 1011 3160 7141 2000 2017 2030 2000 2115 11194 1029 8827 1024 2017 1005 2128 5121 2025 2894 999 1027 1028 16770 1024 1013 1013 27571 1012 1043 2140 1013 18133 6292 2546 3501 7632 2711 1035 2173 14528 1010 4067 2017 2005 2115 3037 1045 1005 1049 2026 11194 1012 1012 1012 1024 1007 1996 7588 2024 2969 1011 2081 1011 9240 2055 1019 1011 1021 2086 3283 16914 22278 6255 2629 1010 17368 4563 2475 28122 2692 1010 8223 1022 18259 1010 15315 2678 10958 3207 2239 10751 10332 2692 2186 1012 4082 3001 2013 26726 2000 2698 2000 3645 2184 2467 1999 7037 8080 9563 2302 2151 2569 3471 1012 2004 3855 3041 1010 1996 3291 2318 2044 1996 21677 12740 22025 2581 2620 2620 10651 1010 2043 1045 2707 1996 3274 1010 1996 2157 8080 12237 1999 3233 3762 5549 1012 2085 2008 1045 2228 1010 1999 2119 3001 1010 15410 2008 2024 1999 3233 3762 2024 4198 2000 1040 5737 1012 102 1026 1026 1026 4005 1028 1028 1028 1024 1042 10139 1010 2026 5796 2063 1005 1055 10651 21628 2758 2008 13366 2015 1058 2487 1012 22582 1012 20666 1012 1014 2020 5361 2012 1021 1024 5709 7610 2197 9152 2618 2664 3645 10651 4136 2033 2008 1058 2487 1012 23628 1012 19235 1012 1014 1006 2207 2006 2423 2251 2418 1007 2003 2800 2153 999 8827 1024 2748 1010 1045 1005 2310 7718 23658 1058 2487 1012 23628 1012 19235 1012 1014 2004 3253 3081 3645 10651 3674 2335 1012 2169 1998 2296 2051 1010 2009 5147 1000 1000 16500 2015 1000 1000 1999 4971 5562 8663 5104 2664 1996 13366 2015 2544 1999 5796 2063 1005 1055 10651 21628 2038 2904 1998 5246 2013 2306 1996 2627 2484 2847 2030 1055 102\n","09/07/2021 07:42:08 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","09/07/2021 07:42:08 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","09/07/2021 07:42:08 - INFO - utils_glue -   label: 0 (id = 0)\n","09/07/2021 07:42:08 - INFO - utils_glue -   *** Example ***\n","09/07/2021 07:42:08 - INFO - utils_glue -   guid: dev-4\n","09/07/2021 07:42:08 - INFO - utils_glue -   tokens: [CLS] two system in our office with dual monitor configuration , windows 10 pro x ##64 1703 . after install kb ##40 ##38 ##7 ##8 ##8 update , on boot after shut ##down ( not after restart ) the second monitor remains in stand by . on both system , i see the win logo and on log ##in the right monitor go in stand by mode . one system is con ##fi ##gur ##ated with primary monitor on left and secondary on right , second with primary on right and secondary on left . in both system the right monitor start in stand - by . the only mode to react ##ivate it is on screen settings and dea ##ct ##ivating / react ##ivating the second monitor . in one system i have un ##ins ##tal ##l the update and it has returned normal , but in the other the un ##ins ##tal ##l procedure has not been successful . both graphic board are ra ##de ##on hd with default microsoft driver . any idea or suggestion to solve the problem ? thank ' s in advance moved from : ( windows / windows 10 / windows update , recovery , & backup / pc ) do the computers - in - question belong to you or to your employer ? ps : you ' re certainly not alone ! = > https : / / goo . g ##l / cp ##gy ##f ##j hi person _ place ##holder , thank you for your interest i ' m my employer . . . : ) the computers are self - made - assembled about 5 - 7 years ago mb socket 77 ##5 , cpu core ##2 840 ##0 , ram 8 ##gb , sk video ra ##de ##on hd 450 ##0 series . operating systems from xp to seven to windows 10 always in dual monitor configuration without any special problems . as mentioned earlier , the problem started after the kb ##40 ##38 ##7 ##8 ##8 [SEP] < < < agent > > > : hello shit ##aki ##bu ##ile ##s and philip ##ger ##ber ##ich , thank you for posting your concern in microsoft community . we understand that you are unable to access your emails via outlook . com . person _ place ##holder , you have mentioned that even you try access ##ing your emails via different browser you still get the same result . for further steps to rec ##tify your case , we also suggest that you reset your browser settings , di ##sable fire ##wall or any anti - filtering program installed on your computer and update your browser version . to do this , kindly perform the steps on the link below : is internet explorer slow ? 5 things to try which browser ##s are supported by sky ##drive , people and outlook . com ? manage add - on ##s in internet explorer person _ place ##holder let us know the result for further assistance . thanks . [SEP]\n","09/07/2021 07:42:08 - INFO - utils_glue -   input_ids: 101 2048 2291 1999 2256 2436 2007 7037 8080 9563 1010 3645 2184 4013 1060 21084 28366 1012 2044 16500 21677 12740 22025 2581 2620 2620 10651 1010 2006 9573 2044 3844 7698 1006 2025 2044 23818 1007 1996 2117 8080 3464 1999 3233 2011 1012 2006 2119 2291 1010 1045 2156 1996 2663 8154 1998 2006 8833 2378 1996 2157 8080 2175 1999 3233 2011 5549 1012 2028 2291 2003 9530 8873 27390 4383 2007 3078 8080 2006 2187 1998 3905 2006 2157 1010 2117 2007 3078 2006 2157 1998 3905 2006 2187 1012 1999 2119 2291 1996 2157 8080 2707 1999 3233 1011 2011 1012 1996 2069 5549 2000 10509 21466 2009 2003 2006 3898 10906 1998 26709 6593 17441 1013 10509 17441 1996 2117 8080 1012 1999 2028 2291 1045 2031 4895 7076 9080 2140 1996 10651 1998 2009 2038 2513 3671 1010 2021 1999 1996 2060 1996 4895 7076 9080 2140 7709 2038 2025 2042 3144 1012 2119 8425 2604 2024 10958 3207 2239 10751 2007 12398 7513 4062 1012 2151 2801 2030 10293 2000 9611 1996 3291 1029 4067 1005 1055 1999 5083 2333 2013 1024 1006 3645 1013 3645 2184 1013 3645 10651 1010 7233 1010 1004 10200 1013 7473 1007 2079 1996 7588 1011 1999 1011 3160 7141 2000 2017 2030 2000 2115 11194 1029 8827 1024 2017 1005 2128 5121 2025 2894 999 1027 1028 16770 1024 1013 1013 27571 1012 1043 2140 1013 18133 6292 2546 3501 7632 2711 1035 2173 14528 1010 4067 2017 2005 2115 3037 1045 1005 1049 2026 11194 1012 1012 1012 1024 1007 1996 7588 2024 2969 1011 2081 1011 9240 2055 1019 1011 1021 2086 3283 16914 22278 6255 2629 1010 17368 4563 2475 28122 2692 1010 8223 1022 18259 1010 15315 2678 10958 3207 2239 10751 10332 2692 2186 1012 4082 3001 2013 26726 2000 2698 2000 3645 2184 2467 1999 7037 8080 9563 2302 2151 2569 3471 1012 2004 3855 3041 1010 1996 3291 2318 2044 1996 21677 12740 22025 2581 2620 2620 102 1026 1026 1026 4005 1028 1028 1028 1024 7592 4485 8978 8569 9463 2015 1998 5170 4590 5677 7033 1010 4067 2017 2005 14739 2115 5142 1999 7513 2451 1012 2057 3305 2008 2017 2024 4039 2000 3229 2115 22028 3081 17680 1012 4012 1012 2711 1035 2173 14528 1010 2017 2031 3855 2008 2130 2017 3046 3229 2075 2115 22028 3081 2367 16602 2017 2145 2131 1996 2168 2765 1012 2005 2582 4084 2000 28667 27351 2115 2553 1010 2057 2036 6592 2008 2017 25141 2115 16602 10906 1010 4487 19150 2543 9628 2030 2151 3424 1011 22910 2565 5361 2006 2115 3274 1998 10651 2115 16602 2544 1012 2000 2079 2023 1010 19045 4685 1996 4084 2006 1996 4957 2917 1024 2003 4274 10566 4030 1029 1019 2477 2000 3046 2029 16602 2015 2024 3569 2011 3712 23663 1010 2111 1998 17680 1012 4012 1029 6133 5587 1011 2006 2015 1999 4274 10566 2711 1035 2173 14528 2292 2149 2113 1996 2765 2005 2582 5375 1012 4283 1012 102\n","09/07/2021 07:42:08 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","09/07/2021 07:42:08 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","09/07/2021 07:42:08 - INFO - utils_glue -   label: 0 (id = 0)\n","09/07/2021 07:43:49 - INFO - utils_glue -   Writing example 10000 of 37210\n","09/07/2021 07:45:14 - INFO - utils_glue -   Writing example 20000 of 37210\n","09/07/2021 07:46:52 - INFO - utils_glue -   Writing example 30000 of 37210\n","09/07/2021 07:48:02 - INFO - __main__ -   Saving features into cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_512_ms_v2\n","09/07/2021 07:48:24 - INFO - __main__ -   ***** Running evaluation  *****\n","09/07/2021 07:48:24 - INFO - __main__ -     Num examples = 37210\n","09/07/2021 07:48:24 - INFO - __main__ -     Batch size = 8\n","09/07/2021 08:28:51 - INFO - __main__ -   ***** Eval results  *****\n","09/07/2021 08:28:51 - INFO - __main__ -     map = 0.785386886099062\n","09/07/2021 08:28:53 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_6/checkpoint-best_run_cl__seed_42\n","09/07/2021 08:54:10 - INFO - __main__ -   Iter = 2000.0\n","09/07/2021 08:54:10 - INFO - __main__ -   lr = 1.6929218486104714e-05\n","09/07/2021 08:54:10 - INFO - __main__ -   loss = 0.4366315500475466\n","09/07/2021 08:54:10 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_512_ms_v2\n","09/07/2021 08:54:25 - INFO - __main__ -   ***** Running evaluation  *****\n","09/07/2021 08:54:25 - INFO - __main__ -     Num examples = 37210\n","09/07/2021 08:54:25 - INFO - __main__ -     Batch size = 8\n","09/07/2021 09:34:53 - INFO - __main__ -   ***** Eval results  *****\n","09/07/2021 09:34:53 - INFO - __main__ -     map = 0.7960033785080823\n","09/07/2021 09:34:55 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_6/checkpoint-best_run_cl__seed_42\n","09/07/2021 10:00:14 - INFO - __main__ -   Iter = 3000.0\n","09/07/2021 10:00:14 - INFO - __main__ -   lr = 1.5393827729157073e-05\n","09/07/2021 10:00:14 - INFO - __main__ -   loss = 0.3993615642059594\n","09/07/2021 10:00:14 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_512_ms_v2\n","09/07/2021 10:00:29 - INFO - __main__ -   ***** Running evaluation  *****\n","09/07/2021 10:00:29 - INFO - __main__ -     Num examples = 37210\n","09/07/2021 10:00:29 - INFO - __main__ -     Batch size = 8\n","09/07/2021 10:40:55 - INFO - __main__ -   ***** Eval results  *****\n","09/07/2021 10:40:55 - INFO - __main__ -     map = 0.7988069643337048\n","09/07/2021 10:40:56 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_6/checkpoint-best_run_cl__seed_42\n","09/07/2021 11:06:19 - INFO - __main__ -   Iter = 4000.0\n","09/07/2021 11:06:19 - INFO - __main__ -   lr = 1.3858436972209429e-05\n","09/07/2021 11:06:19 - INFO - __main__ -   loss = 0.3624473292240873\n","09/07/2021 11:06:19 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_512_ms_v2\n","09/07/2021 11:06:34 - INFO - __main__ -   ***** Running evaluation  *****\n","09/07/2021 11:06:34 - INFO - __main__ -     Num examples = 37210\n","09/07/2021 11:06:34 - INFO - __main__ -     Batch size = 8\n","09/07/2021 11:47:04 - INFO - __main__ -   ***** Eval results  *****\n","09/07/2021 11:47:04 - INFO - __main__ -     map = 0.8034897386348622\n","09/07/2021 11:47:06 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_6/checkpoint-best_run_cl__seed_42\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TiZh8fXDIgXl","executionInfo":{"status":"ok","timestamp":1631018673116,"user_tz":-120,"elapsed":2524406,"user":{"displayName":"Chen Qian","photoUrl":"","userId":"11245437508655380561"}},"outputId":"8e9c8a0a-e95b-4a0a-dd21-d5a737feee92"},"source":["!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  ms_v2 \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/MSDialog \\\n","    --max_seq_length 512 \\\n","    --per_gpu_eval_batch_size=8   \\\n","    --per_gpu_train_batch_size=8   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 3 \\\n","    --output_dir drive/MyDrive/transformers_cl/ms_v2_bert_6/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["09/07/2021 12:02:33 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","09/07/2021 12:02:33 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpqmwxadmh\n","100% 433/433 [00:00<00:00, 316565.04B/s]\n","09/07/2021 12:02:34 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpqmwxadmh to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","09/07/2021 12:02:34 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","09/07/2021 12:02:34 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpqmwxadmh\n","09/07/2021 12:02:34 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","09/07/2021 12:02:34 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"ms_v2\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","09/07/2021 12:02:34 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp0insidmq\n","100% 231508/231508 [00:00<00:00, 2588724.24B/s]\n","09/07/2021 12:02:34 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp0insidmq to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","09/07/2021 12:02:34 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","09/07/2021 12:02:34 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp0insidmq\n","09/07/2021 12:02:34 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","09/07/2021 12:02:34 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpmlclf1by\n","100% 440473133/440473133 [00:11<00:00, 39846118.27B/s]\n","09/07/2021 12:02:45 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpmlclf1by to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","09/07/2021 12:02:47 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","09/07/2021 12:02:47 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpmlclf1by\n","09/07/2021 12:02:47 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","09/07/2021 12:02:51 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","09/07/2021 12:02:51 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","09/07/2021 12:03:01 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', cached_features_file_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/MSDialog', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=False, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=-1, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=512, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise=0.0, num_train_epochs=3.0, output_dir='drive/MyDrive/transformers_cl/ms_v2_bert_6/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, percentage_data_by_epoch=1.0, reset_clf_weights=False, resume_epoch=1.0, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='ms_v2', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","09/07/2021 12:03:11 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_train_bert-base-uncased_512_ms_v2\n","09/07/2021 12:03:27 - INFO - __main__ -   ***** Running evaluation best_run_cl__seed_42 *****\n","09/07/2021 12:03:27 - INFO - __main__ -     Num examples = 34736\n","09/07/2021 12:03:27 - INFO - __main__ -     Batch size = 2\n","09/07/2021 12:44:30 - INFO - __main__ -   ***** Eval results best_run_cl__seed_42 *****\n","09/07/2021 12:44:30 - INFO - __main__ -     map = 0.9757312298479963\n"]}]},{"cell_type":"markdown","metadata":{"id":"Gbe71Qz0JAMS"},"source":["# 05-18 batch size = 8, trained epoch = 3, map = 0.95"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nDI1DoVGiCMS","executionInfo":{"elapsed":15314581,"status":"ok","timestamp":1621339811832,"user":{"displayName":"Chen Qian","photoUrl":"","userId":"11245437508655380561"},"user_tz":-120},"outputId":"493590b5-84ee-4cfb-bb65-cf5da9bd06b9"},"source":["# running time 4h15m for 3 epochs \n","!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  ms_v2 \\\n","    --do_train \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/MSDialog \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=8   \\\n","    --per_gpu_train_batch_size=8   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 3 \\\n","    --output_dir drive/MyDrive/transformers_cl/ms_v2_bert_5/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 1000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["05/18/2021 07:54:58 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","05/18/2021 07:54:58 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","05/18/2021 07:54:58 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"ms_v2\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","05/18/2021 07:54:59 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","05/18/2021 07:55:00 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","05/18/2021 07:55:05 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","05/18/2021 07:55:05 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","05/18/2021 07:55:07 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/MSDialog', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=1000, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=3.0, output_dir='drive/MyDrive/transformers_cl/ms_v2_bert_5/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='ms_v2', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","QC: do_train is True do_eval is True save_aps is True\n","QC: local rank is -1 eval_during_training is True\n","05/18/2021 07:55:07 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_train_bert-base-uncased_128_ms_v2\n","QC:training\n","05/18/2021 07:55:10 - INFO - __main__ -   ***** Running training *****\n","05/18/2021 07:55:10 - INFO - __main__ -     Num examples = 34736\n","05/18/2021 07:55:10 - INFO - __main__ -     Num Epochs = 3\n","05/18/2021 07:55:10 - INFO - __main__ -     Instantaneous batch size per GPU = 8\n","05/18/2021 07:55:10 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 8\n","05/18/2021 07:55:10 - INFO - __main__ -     Gradient Accumulation steps = 1\n","05/18/2021 07:55:10 - INFO - __main__ -     Total optimization steps = 13026\n","05/18/2021 07:55:10 - INFO - __main__ -     percentage by epoch = 1.000000\n","05/18/2021 07:55:10 - INFO - __main__ -     data_loaders = [('all_random_batches', <torch.utils.data.dataloader.DataLoader object at 0x7f866eb04a50>)]\n","05/18/2021 07:55:10 - INFO - __main__ -     QC len(data_loaders) = 1\n","05/18/2021 07:55:10 - INFO - __main__ -   Starting epoch 1\n","05/18/2021 07:55:10 - INFO - __main__ -   Training with all_random_batches\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","05/18/2021 08:02:39 - INFO - __main__ -   Iter = 1000\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","05/18/2021 08:02:39 - INFO - __main__ -   lr = 1.8464609243052358e-05\n","05/18/2021 08:02:39 - INFO - __main__ -   loss = 0.5895296258628369\n","QC:evaluate and save_aps is False\n","05/18/2021 08:02:39 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","05/18/2021 08:02:43 - INFO - __main__ -   ***** Running evaluation  *****\n","05/18/2021 08:02:43 - INFO - __main__ -     Num examples = 37210\n","05/18/2021 08:02:43 - INFO - __main__ -     Batch size = 8\n","05/18/2021 08:12:48 - INFO - __main__ -   ***** Eval results  *****\n","05/18/2021 08:12:48 - INFO - __main__ -     map = 0.6450941247232577\n","05/18/2021 08:12:50 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_5/checkpoint-best_run_cl__seed_42\n","05/18/2021 08:20:18 - INFO - __main__ -   Iter = 2000\n","05/18/2021 08:20:18 - INFO - __main__ -   lr = 1.6929218486104714e-05\n","05/18/2021 08:20:18 - INFO - __main__ -   loss = 0.5024988539367914\n","QC:evaluate and save_aps is False\n","05/18/2021 08:20:18 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","05/18/2021 08:20:22 - INFO - __main__ -   ***** Running evaluation  *****\n","05/18/2021 08:20:22 - INFO - __main__ -     Num examples = 37210\n","05/18/2021 08:20:22 - INFO - __main__ -     Batch size = 8\n","05/18/2021 08:30:26 - INFO - __main__ -   ***** Eval results  *****\n","05/18/2021 08:30:26 - INFO - __main__ -     map = 0.657295252598933\n","05/18/2021 08:30:28 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_5/checkpoint-best_run_cl__seed_42\n","05/18/2021 08:37:57 - INFO - __main__ -   Iter = 3000\n","05/18/2021 08:37:57 - INFO - __main__ -   lr = 1.5393827729157073e-05\n","05/18/2021 08:37:57 - INFO - __main__ -   loss = 0.4623306016176939\n","QC:evaluate and save_aps is False\n","05/18/2021 08:37:57 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","05/18/2021 08:38:01 - INFO - __main__ -   ***** Running evaluation  *****\n","05/18/2021 08:38:01 - INFO - __main__ -     Num examples = 37210\n","05/18/2021 08:38:01 - INFO - __main__ -     Batch size = 8\n","05/18/2021 08:48:08 - INFO - __main__ -   ***** Eval results  *****\n","05/18/2021 08:48:08 - INFO - __main__ -     map = 0.6917896281508221\n","05/18/2021 08:48:09 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_5/checkpoint-best_run_cl__seed_42\n","05/18/2021 08:55:38 - INFO - __main__ -   Iter = 4000\n","05/18/2021 08:55:38 - INFO - __main__ -   lr = 1.3858436972209429e-05\n","05/18/2021 08:55:38 - INFO - __main__ -   loss = 0.4365435366891324\n","QC:evaluate and save_aps is False\n","05/18/2021 08:55:38 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","05/18/2021 08:55:42 - INFO - __main__ -   ***** Running evaluation  *****\n","05/18/2021 08:55:42 - INFO - __main__ -     Num examples = 37210\n","05/18/2021 08:55:42 - INFO - __main__ -     Batch size = 8\n","05/18/2021 09:05:49 - INFO - __main__ -   ***** Eval results  *****\n","05/18/2021 09:05:49 - INFO - __main__ -     map = 0.6843974354052293\n","05/18/2021 09:08:23 - INFO - __main__ -   Finished epoch with 4342 iterations.\n","05/18/2021 09:08:23 - INFO - __main__ -   Starting epoch 2\n","05/18/2021 09:08:23 - INFO - __main__ -   Training with all_random_batches\n","05/18/2021 09:13:19 - INFO - __main__ -   Iter = 5000\n","05/18/2021 09:13:19 - INFO - __main__ -   lr = 1.2323046215261785e-05\n","05/18/2021 09:13:19 - INFO - __main__ -   loss = 0.4036350416019559\n","QC:evaluate and save_aps is False\n","05/18/2021 09:13:19 - INFO - __main__ -   Creating features from dataset file at drive/MyDrive/MSDialog\n","05/18/2021 09:13:23 - INFO - utils_glue -   Writing example 0 of 37210\n","05/18/2021 09:13:23 - INFO - utils_glue -   *** Example ***\n","05/18/2021 09:13:23 - INFO - utils_glue -   guid: dev-0\n","05/18/2021 09:13:23 - INFO - utils_glue -   tokens: [CLS] two system in our office with dual monitor configuration , windows 10 pro x ##64 1703 . after install kb ##40 ##38 ##7 ##8 ##8 update , on boot after shut ##down ( not after restart ) the second monitor remains in stand by . on both system , i see the win logo and on log ##in the right monitor go in [SEP] < < < agent > > > : assuming ( a ) both computers were running windows 7 , and ( b ) the upgrade from win ##7 to win ##10 was offered and installed via windows update ( i . e . , you did not upgrade manually ) , and ( c ) creators update / win ##10 1703 was [SEP]\n","05/18/2021 09:13:23 - INFO - utils_glue -   input_ids: 101 2048 2291 1999 2256 2436 2007 7037 8080 9563 1010 3645 2184 4013 1060 21084 28366 1012 2044 16500 21677 12740 22025 2581 2620 2620 10651 1010 2006 9573 2044 3844 7698 1006 2025 2044 23818 1007 1996 2117 8080 3464 1999 3233 2011 1012 2006 2119 2291 1010 1045 2156 1996 2663 8154 1998 2006 8833 2378 1996 2157 8080 2175 1999 102 1026 1026 1026 4005 1028 1028 1028 1024 10262 1006 1037 1007 2119 7588 2020 2770 3645 1021 1010 1998 1006 1038 1007 1996 12200 2013 2663 2581 2000 2663 10790 2001 3253 1998 5361 3081 3645 10651 1006 1045 1012 1041 1012 1010 2017 2106 2025 12200 21118 1007 1010 1998 1006 1039 1007 17277 10651 1013 2663 10790 28366 2001 102\n","05/18/2021 09:13:23 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/18/2021 09:13:23 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/18/2021 09:13:23 - INFO - utils_glue -   label: 1 (id = 1)\n","05/18/2021 09:13:23 - INFO - utils_glue -   *** Example ***\n","05/18/2021 09:13:23 - INFO - utils_glue -   guid: dev-1\n","05/18/2021 09:13:23 - INFO - utils_glue -   tokens: [CLS] two system in our office with dual monitor configuration , windows 10 pro x ##64 1703 . after install kb ##40 ##38 ##7 ##8 ##8 update , on boot after shut ##down ( not after restart ) the second monitor remains in stand by . on both system , i see the win logo and on log ##in the right monitor go in [SEP] < < < agent > > > : 1 . is the computer still under warrant ##y ? 2 . what os build of windows 10 1703 [ aka creators update ] is currently installed ? 3 . are protection update definitions up - to - date according to windows defender security center ' s virus & threat protection tab ? 4 [SEP]\n","05/18/2021 09:13:23 - INFO - utils_glue -   input_ids: 101 2048 2291 1999 2256 2436 2007 7037 8080 9563 1010 3645 2184 4013 1060 21084 28366 1012 2044 16500 21677 12740 22025 2581 2620 2620 10651 1010 2006 9573 2044 3844 7698 1006 2025 2044 23818 1007 1996 2117 8080 3464 1999 3233 2011 1012 2006 2119 2291 1010 1045 2156 1996 2663 8154 1998 2006 8833 2378 1996 2157 8080 2175 1999 102 1026 1026 1026 4005 1028 1028 1028 1024 1015 1012 2003 1996 3274 2145 2104 10943 2100 1029 1016 1012 2054 9808 3857 1997 3645 2184 28366 1031 9875 17277 10651 1033 2003 2747 5361 1029 1017 1012 2024 3860 10651 15182 2039 1011 2000 1011 3058 2429 2000 3645 8291 3036 2415 1005 1055 7865 1004 5081 3860 21628 1029 1018 102\n","05/18/2021 09:13:23 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/18/2021 09:13:23 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/18/2021 09:13:23 - INFO - utils_glue -   label: 0 (id = 0)\n","05/18/2021 09:13:23 - INFO - utils_glue -   *** Example ***\n","05/18/2021 09:13:23 - INFO - utils_glue -   guid: dev-2\n","05/18/2021 09:13:23 - INFO - utils_glue -   tokens: [CLS] two system in our office with dual monitor configuration , windows 10 pro x ##64 1703 . after install kb ##40 ##38 ##7 ##8 ##8 update , on boot after shut ##down ( not after restart ) the second monitor remains in stand by . on both system , i see the win logo and on log ##in the right monitor go in [SEP] < < < agent > > > : assuming windows 10 . . . answer - by - number : 1 . when ( approx . date ) did you purchase the computer ? 2 . did the computer come with win ##10 pre ##ins ##tal ##led , did you do a clean install of win ##10 , or did you upgrade [SEP]\n","05/18/2021 09:13:23 - INFO - utils_glue -   input_ids: 101 2048 2291 1999 2256 2436 2007 7037 8080 9563 1010 3645 2184 4013 1060 21084 28366 1012 2044 16500 21677 12740 22025 2581 2620 2620 10651 1010 2006 9573 2044 3844 7698 1006 2025 2044 23818 1007 1996 2117 8080 3464 1999 3233 2011 1012 2006 2119 2291 1010 1045 2156 1996 2663 8154 1998 2006 8833 2378 1996 2157 8080 2175 1999 102 1026 1026 1026 4005 1028 1028 1028 1024 10262 3645 2184 1012 1012 1012 3437 1011 2011 1011 2193 1024 1015 1012 2043 1006 22480 1012 3058 1007 2106 2017 5309 1996 3274 1029 1016 1012 2106 1996 3274 2272 2007 2663 10790 3653 7076 9080 3709 1010 2106 2017 2079 1037 4550 16500 1997 2663 10790 1010 2030 2106 2017 12200 102\n","05/18/2021 09:13:23 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/18/2021 09:13:23 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/18/2021 09:13:23 - INFO - utils_glue -   label: 0 (id = 0)\n","05/18/2021 09:13:23 - INFO - utils_glue -   *** Example ***\n","05/18/2021 09:13:23 - INFO - utils_glue -   guid: dev-3\n","05/18/2021 09:13:23 - INFO - utils_glue -   tokens: [CLS] two system in our office with dual monitor configuration , windows 10 pro x ##64 1703 . after install kb ##40 ##38 ##7 ##8 ##8 update , on boot after shut ##down ( not after restart ) the second monitor remains in stand by . on both system , i see the win logo and on log ##in the right monitor go in [SEP] < < < agent > > > : f ##yi , my ms ##e ' s update tab says that def ##s v ##1 . 251 . 232 . 0 were installed at 7 : 05 pm last ni ##te yet windows update tells me that v ##1 . 249 . 211 . 0 ( released on 25 july 2017 ) is [SEP]\n","05/18/2021 09:13:23 - INFO - utils_glue -   input_ids: 101 2048 2291 1999 2256 2436 2007 7037 8080 9563 1010 3645 2184 4013 1060 21084 28366 1012 2044 16500 21677 12740 22025 2581 2620 2620 10651 1010 2006 9573 2044 3844 7698 1006 2025 2044 23818 1007 1996 2117 8080 3464 1999 3233 2011 1012 2006 2119 2291 1010 1045 2156 1996 2663 8154 1998 2006 8833 2378 1996 2157 8080 2175 1999 102 1026 1026 1026 4005 1028 1028 1028 1024 1042 10139 1010 2026 5796 2063 1005 1055 10651 21628 2758 2008 13366 2015 1058 2487 1012 22582 1012 20666 1012 1014 2020 5361 2012 1021 1024 5709 7610 2197 9152 2618 2664 3645 10651 4136 2033 2008 1058 2487 1012 23628 1012 19235 1012 1014 1006 2207 2006 2423 2251 2418 1007 2003 102\n","05/18/2021 09:13:23 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/18/2021 09:13:23 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/18/2021 09:13:23 - INFO - utils_glue -   label: 0 (id = 0)\n","05/18/2021 09:13:23 - INFO - utils_glue -   *** Example ***\n","05/18/2021 09:13:23 - INFO - utils_glue -   guid: dev-4\n","05/18/2021 09:13:23 - INFO - utils_glue -   tokens: [CLS] two system in our office with dual monitor configuration , windows 10 pro x ##64 1703 . after install kb ##40 ##38 ##7 ##8 ##8 update , on boot after shut ##down ( not after restart ) the second monitor remains in stand by . on both system , i see the win logo and on log ##in the right monitor go in [SEP] < < < agent > > > : hello shit ##aki ##bu ##ile ##s and philip ##ger ##ber ##ich , thank you for posting your concern in microsoft community . we understand that you are unable to access your emails via outlook . com . person _ place ##holder , you have mentioned that even you try access ##ing your emails via [SEP]\n","05/18/2021 09:13:23 - INFO - utils_glue -   input_ids: 101 2048 2291 1999 2256 2436 2007 7037 8080 9563 1010 3645 2184 4013 1060 21084 28366 1012 2044 16500 21677 12740 22025 2581 2620 2620 10651 1010 2006 9573 2044 3844 7698 1006 2025 2044 23818 1007 1996 2117 8080 3464 1999 3233 2011 1012 2006 2119 2291 1010 1045 2156 1996 2663 8154 1998 2006 8833 2378 1996 2157 8080 2175 1999 102 1026 1026 1026 4005 1028 1028 1028 1024 7592 4485 8978 8569 9463 2015 1998 5170 4590 5677 7033 1010 4067 2017 2005 14739 2115 5142 1999 7513 2451 1012 2057 3305 2008 2017 2024 4039 2000 3229 2115 22028 3081 17680 1012 4012 1012 2711 1035 2173 14528 1010 2017 2031 3855 2008 2130 2017 3046 3229 2075 2115 22028 3081 102\n","05/18/2021 09:13:23 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/18/2021 09:13:23 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/18/2021 09:13:23 - INFO - utils_glue -   label: 0 (id = 0)\n","05/18/2021 09:15:03 - INFO - utils_glue -   Writing example 10000 of 37210\n","05/18/2021 09:16:27 - INFO - utils_glue -   Writing example 20000 of 37210\n","05/18/2021 09:18:04 - INFO - utils_glue -   Writing example 30000 of 37210\n","05/18/2021 09:19:12 - INFO - __main__ -   Saving features into cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","05/18/2021 09:19:18 - INFO - __main__ -   ***** Running evaluation  *****\n","05/18/2021 09:19:18 - INFO - __main__ -     Num examples = 37210\n","05/18/2021 09:19:18 - INFO - __main__ -     Batch size = 8\n","05/18/2021 09:29:26 - INFO - __main__ -   ***** Eval results  *****\n","05/18/2021 09:29:26 - INFO - __main__ -     map = 0.679971248554963\n","05/18/2021 09:29:28 - INFO - __main__ -   Saving model checkpoint to drive/MyDrive/transformers_cl/ms_v2_bert_5/checkpoint-5000\n","05/18/2021 09:36:58 - INFO - __main__ -   Iter = 6000\n","05/18/2021 09:36:58 - INFO - __main__ -   lr = 1.0787655458314141e-05\n","05/18/2021 09:36:58 - INFO - __main__ -   loss = 0.3889350394960493\n","QC:evaluate and save_aps is False\n","05/18/2021 09:36:58 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","05/18/2021 09:37:02 - INFO - __main__ -   ***** Running evaluation  *****\n","05/18/2021 09:37:02 - INFO - __main__ -     Num examples = 37210\n","05/18/2021 09:37:02 - INFO - __main__ -     Batch size = 8\n","05/18/2021 09:47:08 - INFO - __main__ -   ***** Eval results  *****\n","05/18/2021 09:47:08 - INFO - __main__ -     map = 0.6849687317370744\n","05/18/2021 09:54:37 - INFO - __main__ -   Iter = 7000\n","05/18/2021 09:54:37 - INFO - __main__ -   lr = 9.252264701366499e-06\n","05/18/2021 09:54:37 - INFO - __main__ -   loss = 0.36341526307351885\n","QC:evaluate and save_aps is False\n","05/18/2021 09:54:37 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","05/18/2021 09:54:41 - INFO - __main__ -   ***** Running evaluation  *****\n","05/18/2021 09:54:41 - INFO - __main__ -     Num examples = 37210\n","05/18/2021 09:54:41 - INFO - __main__ -     Batch size = 8\n","05/18/2021 10:04:49 - INFO - __main__ -   ***** Eval results  *****\n","05/18/2021 10:04:49 - INFO - __main__ -     map = 0.6893244263574827\n","05/18/2021 10:12:18 - INFO - __main__ -   Iter = 8000\n","05/18/2021 10:12:18 - INFO - __main__ -   lr = 7.716873944418856e-06\n","05/18/2021 10:12:18 - INFO - __main__ -   loss = 0.3500119254728779\n","QC:evaluate and save_aps is False\n","05/18/2021 10:12:18 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","05/18/2021 10:12:22 - INFO - __main__ -   ***** Running evaluation  *****\n","05/18/2021 10:12:22 - INFO - __main__ -     Num examples = 37210\n","05/18/2021 10:12:22 - INFO - __main__ -     Batch size = 8\n","05/18/2021 10:22:29 - INFO - __main__ -   ***** Eval results  *****\n","05/18/2021 10:22:29 - INFO - __main__ -     map = 0.6781852676571842\n","05/18/2021 10:27:37 - INFO - __main__ -   Finished epoch with 4342 iterations.\n","05/18/2021 10:27:37 - INFO - __main__ -   Starting epoch 3\n","05/18/2021 10:27:37 - INFO - __main__ -   Training with all_random_batches\n","05/18/2021 10:29:58 - INFO - __main__ -   Iter = 9000\n","05/18/2021 10:29:58 - INFO - __main__ -   lr = 6.181483187471212e-06\n","05/18/2021 10:29:58 - INFO - __main__ -   loss = 0.35393402985390277\n","QC:evaluate and save_aps is False\n","05/18/2021 10:29:58 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","05/18/2021 10:30:02 - INFO - __main__ -   ***** Running evaluation  *****\n","05/18/2021 10:30:02 - INFO - __main__ -     Num examples = 37210\n","05/18/2021 10:30:02 - INFO - __main__ -     Batch size = 8\n","05/18/2021 10:40:09 - INFO - __main__ -   ***** Eval results  *****\n","05/18/2021 10:40:09 - INFO - __main__ -     map = 0.6861431045588533\n","05/18/2021 10:47:36 - INFO - __main__ -   Iter = 10000\n","05/18/2021 10:47:36 - INFO - __main__ -   lr = 4.646092430523569e-06\n","05/18/2021 10:47:36 - INFO - __main__ -   loss = 0.3263300891546532\n","QC:evaluate and save_aps is False\n","05/18/2021 10:47:36 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","05/18/2021 10:47:40 - INFO - __main__ -   ***** Running evaluation  *****\n","05/18/2021 10:47:40 - INFO - __main__ -     Num examples = 37210\n","05/18/2021 10:47:40 - INFO - __main__ -     Batch size = 8\n","05/18/2021 10:57:46 - INFO - __main__ -   ***** Eval results  *****\n","05/18/2021 10:57:46 - INFO - __main__ -     map = 0.6838780751035525\n","05/18/2021 10:57:48 - INFO - __main__ -   Saving model checkpoint to drive/MyDrive/transformers_cl/ms_v2_bert_5/checkpoint-10000\n","05/18/2021 11:05:15 - INFO - __main__ -   Iter = 11000\n","05/18/2021 11:05:15 - INFO - __main__ -   lr = 3.1107016735759254e-06\n","05/18/2021 11:05:15 - INFO - __main__ -   loss = 0.32824394494248554\n","QC:evaluate and save_aps is False\n","05/18/2021 11:05:15 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","05/18/2021 11:05:19 - INFO - __main__ -   ***** Running evaluation  *****\n","05/18/2021 11:05:19 - INFO - __main__ -     Num examples = 37210\n","05/18/2021 11:05:19 - INFO - __main__ -     Batch size = 8\n","05/18/2021 11:15:25 - INFO - __main__ -   ***** Eval results  *****\n","05/18/2021 11:15:25 - INFO - __main__ -     map = 0.6821833821766639\n","05/18/2021 11:22:51 - INFO - __main__ -   Iter = 12000\n","05/18/2021 11:22:51 - INFO - __main__ -   lr = 1.575310916628282e-06\n","05/18/2021 11:22:51 - INFO - __main__ -   loss = 0.30763058058544995\n","QC:evaluate and save_aps is False\n","05/18/2021 11:22:51 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","05/18/2021 11:22:55 - INFO - __main__ -   ***** Running evaluation  *****\n","05/18/2021 11:22:55 - INFO - __main__ -     Num examples = 37210\n","05/18/2021 11:22:55 - INFO - __main__ -     Batch size = 8\n","05/18/2021 11:33:01 - INFO - __main__ -   ***** Eval results  *****\n","05/18/2021 11:33:01 - INFO - __main__ -     map = 0.6852023905504159\n","05/18/2021 11:40:27 - INFO - __main__ -   Iter = 13000\n","05/18/2021 11:40:27 - INFO - __main__ -   lr = 3.992015968063872e-08\n","05/18/2021 11:40:27 - INFO - __main__ -   loss = 0.3023192723877728\n","QC:evaluate and save_aps is False\n","05/18/2021 11:40:27 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","05/18/2021 11:40:31 - INFO - __main__ -   ***** Running evaluation  *****\n","05/18/2021 11:40:31 - INFO - __main__ -     Num examples = 37210\n","05/18/2021 11:40:31 - INFO - __main__ -     Batch size = 8\n","05/18/2021 11:50:37 - INFO - __main__ -   ***** Eval results  *****\n","05/18/2021 11:50:37 - INFO - __main__ -     map = 0.6842519718628297\n","05/18/2021 11:50:50 - INFO - __main__ -   Finished epoch with 4342 iterations.\n","05/18/2021 11:50:50 - INFO - __main__ -    global_step = 13029, average loss = 0.39322805495750995\n","QC: checkpoint.split('-') ['drive/MyDrive/transformers_cl/ms_v2_bert_5/checkpoint', '10000']\n","QC: global_step: 10000 best_run_name best_run_cl__seed_42\n","QC: checkpoint.split('-') ['drive/MyDrive/transformers_cl/ms_v2_bert_5/checkpoint', '5000']\n","QC: global_step: 5000 best_run_name best_run_cl__seed_42\n","QC: checkpoint.split('-') ['drive/MyDrive/transformers_cl/ms_v2_bert_5/checkpoint', 'best_run_cl__seed_42']\n","QC: global_step: best_run_cl__seed_42 best_run_name best_run_cl__seed_42\n","QC: entered evaluation\n","QC:evaluate and save_aps is True\n","05/18/2021 11:50:54 - INFO - __main__ -   Creating features from dataset file at drive/MyDrive/MSDialog\n","05/18/2021 11:50:54 - INFO - utils_glue -   LOOKING AT drive/MyDrive/MSDialog/train.tsv\n","05/18/2021 11:51:06 - INFO - utils_glue -   Writing example 0 of 34736\n","05/18/2021 11:51:06 - INFO - utils_glue -   *** Example ***\n","05/18/2021 11:51:06 - INFO - utils_glue -   guid: train-0\n","05/18/2021 11:51:06 - INFO - utils_glue -   tokens: [CLS] i upgraded last week with no apparent problems and used sticky notes as recently as two nights ago . tonight i went to open them to check up on something , and not only is the short ##cut missing , sticky notes doesn ' t even appear in the list of programs on this machine . ar ##gh ! help ! ! ! ! i have information on those notes i need . hello , thank you for contact ##ing microsoft [SEP] < < < agent > > > : why are we being given references on how to do a clean boot with every os but windows 10 ? how will an sf ##c scan or a clean boot help to recover the missing data [SEP]\n","05/18/2021 11:51:06 - INFO - utils_glue -   input_ids: 101 1045 9725 2197 2733 2007 2053 6835 3471 1998 2109 15875 3964 2004 3728 2004 2048 6385 3283 1012 3892 1045 2253 2000 2330 2068 2000 4638 2039 2006 2242 1010 1998 2025 2069 2003 1996 2460 12690 4394 1010 15875 3964 2987 1005 1056 2130 3711 1999 1996 2862 1997 3454 2006 2023 3698 1012 12098 5603 999 2393 999 999 999 999 1045 2031 2592 2006 2216 3964 1045 2342 1012 7592 1010 4067 2017 2005 3967 2075 7513 102 1026 1026 1026 4005 1028 1028 1028 1024 2339 2024 2057 2108 2445 7604 2006 2129 2000 2079 1037 4550 9573 2007 2296 9808 2021 3645 2184 1029 2129 2097 2019 16420 2278 13594 2030 1037 4550 9573 2393 2000 8980 1996 4394 2951 102\n","05/18/2021 11:51:06 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/18/2021 11:51:06 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/18/2021 11:51:06 - INFO - utils_glue -   label: 1 (id = 1)\n","05/18/2021 11:51:06 - INFO - utils_glue -   *** Example ***\n","05/18/2021 11:51:06 - INFO - utils_glue -   guid: train-1\n","05/18/2021 11:51:06 - INFO - utils_glue -   tokens: [CLS] i upgraded last week with no apparent problems and used sticky notes as recently as two nights ago . tonight i went to open them to check up on something , and not only is the short ##cut missing , sticky notes doesn ' t even appear in the list of programs on this machine . ar ##gh ! help ! ! ! [SEP] < < < agent > > > : i don ' t see your problem . right from the beginning we were told that there could / would be problems with insider builds and that we shouldn ' t rely on them as our main os . on a number of occasions i ' ve had to do a clean install of [SEP]\n","05/18/2021 11:51:06 - INFO - utils_glue -   input_ids: 101 1045 9725 2197 2733 2007 2053 6835 3471 1998 2109 15875 3964 2004 3728 2004 2048 6385 3283 1012 3892 1045 2253 2000 2330 2068 2000 4638 2039 2006 2242 1010 1998 2025 2069 2003 1996 2460 12690 4394 1010 15875 3964 2987 1005 1056 2130 3711 1999 1996 2862 1997 3454 2006 2023 3698 1012 12098 5603 999 2393 999 999 999 102 1026 1026 1026 4005 1028 1028 1028 1024 1045 2123 1005 1056 2156 2115 3291 1012 2157 2013 1996 2927 2057 2020 2409 2008 2045 2071 1013 2052 2022 3471 2007 25297 16473 1998 2008 2057 5807 1005 1056 11160 2006 2068 2004 2256 2364 9808 1012 2006 1037 2193 1997 6642 1045 1005 2310 2018 2000 2079 1037 4550 16500 1997 102\n","05/18/2021 11:51:06 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/18/2021 11:51:06 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/18/2021 11:51:06 - INFO - utils_glue -   label: 0 (id = 0)\n","05/18/2021 11:51:06 - INFO - utils_glue -   *** Example ***\n","05/18/2021 11:51:06 - INFO - utils_glue -   guid: train-10\n","05/18/2021 11:51:06 - INFO - utils_glue -   tokens: [CLS] i upgraded last week with no apparent problems and used sticky notes as recently as two nights ago . tonight i went to open them to check up on something , and not only is the short ##cut missing , sticky notes doesn ' t even appear in the list of programs on this machine . ar ##gh ! help ! ! ! ! i have information on those notes i need . hello , thank you for contact ##ing microsoft community . i can understand the inc ##on ##ven ##ience caused , be assured that we are here to help you [SEP] < < < agent > > > : sticky notes can be found under windows accessories under all apps in the start men [SEP]\n","05/18/2021 11:51:06 - INFO - utils_glue -   input_ids: 101 1045 9725 2197 2733 2007 2053 6835 3471 1998 2109 15875 3964 2004 3728 2004 2048 6385 3283 1012 3892 1045 2253 2000 2330 2068 2000 4638 2039 2006 2242 1010 1998 2025 2069 2003 1996 2460 12690 4394 1010 15875 3964 2987 1005 1056 2130 3711 1999 1996 2862 1997 3454 2006 2023 3698 1012 12098 5603 999 2393 999 999 999 999 1045 2031 2592 2006 2216 3964 1045 2342 1012 7592 1010 4067 2017 2005 3967 2075 7513 2451 1012 1045 2064 3305 1996 4297 2239 8159 13684 3303 1010 2022 8916 2008 2057 2024 2182 2000 2393 2017 102 1026 1026 1026 4005 1028 1028 1028 1024 15875 3964 2064 2022 2179 2104 3645 16611 2104 2035 18726 1999 1996 2707 2273 102\n","05/18/2021 11:51:06 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/18/2021 11:51:06 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/18/2021 11:51:06 - INFO - utils_glue -   label: 1 (id = 1)\n","05/18/2021 11:51:06 - INFO - utils_glue -   *** Example ***\n","05/18/2021 11:51:06 - INFO - utils_glue -   guid: train-11\n","05/18/2021 11:51:06 - INFO - utils_glue -   tokens: [CLS] i upgraded last week with no apparent problems and used sticky notes as recently as two nights ago . tonight i went to open them to check up on something , and not only is the short ##cut missing , sticky notes doesn ' t even appear in the list of programs on this machine . ar ##gh ! help ! ! ! [SEP] < < < agent > > > : answer , something modified the registry setting hk ##cu \\ software \\ microsoft \\ windows \\ current ##version \\ internet settings \\ 5 . 0 \\ user agent \\ added key version , set to \" \" ms ##ie 9 . 0 \" \" for others with weird agent strings , look at this [SEP]\n","05/18/2021 11:51:06 - INFO - utils_glue -   input_ids: 101 1045 9725 2197 2733 2007 2053 6835 3471 1998 2109 15875 3964 2004 3728 2004 2048 6385 3283 1012 3892 1045 2253 2000 2330 2068 2000 4638 2039 2006 2242 1010 1998 2025 2069 2003 1996 2460 12690 4394 1010 15875 3964 2987 1005 1056 2130 3711 1999 1996 2862 1997 3454 2006 2023 3698 1012 12098 5603 999 2393 999 999 999 102 1026 1026 1026 4005 1028 1028 1028 1024 3437 1010 2242 6310 1996 15584 4292 22563 10841 1032 4007 1032 7513 1032 3645 1032 2783 27774 1032 4274 10906 1032 1019 1012 1014 1032 5310 4005 1032 2794 3145 2544 1010 2275 2000 1000 1000 5796 2666 1023 1012 1014 1000 1000 2005 2500 2007 6881 4005 7817 1010 2298 2012 2023 102\n","05/18/2021 11:51:06 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/18/2021 11:51:06 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/18/2021 11:51:06 - INFO - utils_glue -   label: 0 (id = 0)\n","05/18/2021 11:51:06 - INFO - utils_glue -   *** Example ***\n","05/18/2021 11:51:06 - INFO - utils_glue -   guid: train-20\n","05/18/2021 11:51:06 - INFO - utils_glue -   tokens: [CLS] i upgraded last week with no apparent problems and used sticky notes as recently as two nights ago . tonight i went to open them to check up on something , and not only is the short ##cut missing , sticky notes doesn ' t even appear in the list of programs on this machine . ar ##gh ! help ! ! ! ! [SEP] < < < agent > > > : sticky ##notes can ' t be found there and microsoft even erased c : \\ users \\ your user name \\ app ##da ##ta \\ roaming \\ microsoft \\ sticky notes where they used to be . i had info i need on them . horrible for microsoft to do this to us [SEP]\n","05/18/2021 11:51:06 - INFO - utils_glue -   input_ids: 101 1045 9725 2197 2733 2007 2053 6835 3471 1998 2109 15875 3964 2004 3728 2004 2048 6385 3283 1012 3892 1045 2253 2000 2330 2068 2000 4638 2039 2006 2242 1010 1998 2025 2069 2003 1996 2460 12690 4394 1010 15875 3964 2987 1005 1056 2130 3711 1999 1996 2862 1997 3454 2006 2023 3698 1012 12098 5603 999 2393 999 999 999 999 102 1026 1026 1026 4005 1028 1028 1028 1024 15875 20564 2064 1005 1056 2022 2179 2045 1998 7513 2130 23516 1039 1024 1032 5198 1032 2115 5310 2171 1032 10439 2850 2696 1032 24430 1032 7513 1032 15875 3964 2073 2027 2109 2000 2022 1012 1045 2018 18558 1045 2342 2006 2068 1012 9202 2005 7513 2000 2079 2023 2000 2149 102\n","05/18/2021 11:51:06 - INFO - utils_glue -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/18/2021 11:51:06 - INFO - utils_glue -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/18/2021 11:51:06 - INFO - utils_glue -   label: 1 (id = 1)\n","05/18/2021 11:52:37 - INFO - utils_glue -   Writing example 10000 of 34736\n","05/18/2021 11:54:16 - INFO - utils_glue -   Writing example 20000 of 34736\n","05/18/2021 11:55:52 - INFO - utils_glue -   Writing example 30000 of 34736\n","05/18/2021 11:56:38 - INFO - __main__ -   Saving features into cached file drive/MyDrive/MSDialog/cached_train_bert-base-uncased_128_ms_v2\n","05/18/2021 11:56:43 - INFO - __main__ -   ***** Running evaluation best_run_cl__seed_42 *****\n","05/18/2021 11:56:43 - INFO - __main__ -     Num examples = 34736\n","05/18/2021 11:56:43 - INFO - __main__ -     Batch size = 2\n","drive/MyDrive/transformers_cl/ms_v2_bert_5/  and aps_ saved\n","drive/MyDrive/transformers_cl/ms_v2_bert_5/  and losses_ saved\n","drive/MyDrive/transformers_cl/ms_v2_bert_5/  and preds_ saved\n","05/18/2021 12:10:09 - INFO - __main__ -   ***** Eval results best_run_cl__seed_42 *****\n","05/18/2021 12:10:09 - INFO - __main__ -     map = 0.9548883003224321\n","QC results:  {} , save_aps is True , eval_all_checkpoints True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FFGzPlVXI1lf"},"source":["# 06-11 batch size = 64, trained epoch = 3, map = 0.97"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LIavHAvpY9gm","executionInfo":{"elapsed":7523908,"status":"ok","timestamp":1623416479979,"user":{"displayName":"Chen Qian","photoUrl":"","userId":"11245437508655380561"},"user_tz":-120},"outputId":"2f7eb90c-35ab-4ff8-d060-d37392964d1e"},"source":["# running timeï¼2h5m  for 3 epochs \n","!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  ms_v2 \\\n","    --do_train \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/MSDialog \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 3 \\\n","    --output_dir drive/MyDrive/transformers_cl/ms_v2_bert_3/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 100 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["06/11/2021 10:56:02 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","06/11/2021 10:56:02 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmp_h22ae7k\n","100% 433/433 [00:00<00:00, 439741.80B/s]\n","06/11/2021 10:56:02 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp_h22ae7k to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","06/11/2021 10:56:02 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","06/11/2021 10:56:02 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp_h22ae7k\n","06/11/2021 10:56:02 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","06/11/2021 10:56:02 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"ms_v2\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","06/11/2021 10:56:02 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpmjwwe0n3\n","100% 231508/231508 [00:00<00:00, 869530.31B/s]\n","06/11/2021 10:56:03 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpmjwwe0n3 to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","06/11/2021 10:56:03 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","06/11/2021 10:56:03 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpmjwwe0n3\n","06/11/2021 10:56:03 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","06/11/2021 10:56:03 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpm6u2bqav\n","100% 440473133/440473133 [00:11<00:00, 38763860.44B/s]\n","06/11/2021 10:56:15 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpm6u2bqav to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","06/11/2021 10:56:16 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","06/11/2021 10:56:16 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpm6u2bqav\n","06/11/2021 10:56:16 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","06/11/2021 10:56:20 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","06/11/2021 10:56:20 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","06/11/2021 10:56:31 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/MSDialog', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=3.0, output_dir='drive/MyDrive/transformers_cl/ms_v2_bert_5/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='ms_v2', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","QC: do_train is True do_eval is True save_aps is True\n","QC: local rank is -1 eval_during_training is True\n","06/11/2021 10:56:31 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_train_bert-base-uncased_128_ms_v2\n","QC:training\n","06/11/2021 10:56:34 - INFO - __main__ -   ***** Running training *****\n","06/11/2021 10:56:34 - INFO - __main__ -     Num examples = 34736\n","06/11/2021 10:56:34 - INFO - __main__ -     Num Epochs = 3\n","06/11/2021 10:56:34 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","06/11/2021 10:56:34 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","06/11/2021 10:56:34 - INFO - __main__ -     Gradient Accumulation steps = 1\n","06/11/2021 10:56:34 - INFO - __main__ -     Total optimization steps = 1629\n","06/11/2021 10:56:34 - INFO - __main__ -     percentage by epoch = 1.000000\n","06/11/2021 10:56:34 - INFO - __main__ -     data_loaders = [('all_random_batches', <torch.utils.data.dataloader.DataLoader object at 0x7feb06fb9e50>)]\n","06/11/2021 10:56:34 - INFO - __main__ -     QC len(data_loaders) = 1\n","06/11/2021 10:56:34 - INFO - __main__ -   Starting epoch 1\n","06/11/2021 10:56:34 - INFO - __main__ -   Training with all_random_batches\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","06/11/2021 10:59:01 - INFO - __main__ -   Iter = 100\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","06/11/2021 10:59:01 - INFO - __main__ -   lr = 1.8772252915899326e-05\n","06/11/2021 10:59:01 - INFO - __main__ -   loss = 0.6109435057640076\n","QC:evaluate and save_aps is False\n","06/11/2021 10:59:01 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/11/2021 10:59:06 - INFO - __main__ -   ***** Running evaluation  *****\n","06/11/2021 10:59:06 - INFO - __main__ -     Num examples = 37210\n","06/11/2021 10:59:06 - INFO - __main__ -     Batch size = 64\n","06/11/2021 11:03:57 - INFO - __main__ -   ***** Eval results  *****\n","06/11/2021 11:03:57 - INFO - __main__ -     map = 0.6179879960584068\n","06/11/2021 11:03:59 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_5/checkpoint-best_run_cl__seed_42\n","06/11/2021 11:06:28 - INFO - __main__ -   Iter = 200\n","06/11/2021 11:06:28 - INFO - __main__ -   lr = 1.754450583179865e-05\n","06/11/2021 11:06:28 - INFO - __main__ -   loss = 0.5388327240943909\n","QC:evaluate and save_aps is False\n","06/11/2021 11:06:28 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/11/2021 11:06:31 - INFO - __main__ -   ***** Running evaluation  *****\n","06/11/2021 11:06:31 - INFO - __main__ -     Num examples = 37210\n","06/11/2021 11:06:31 - INFO - __main__ -     Batch size = 64\n","06/11/2021 11:11:23 - INFO - __main__ -   ***** Eval results  *****\n","06/11/2021 11:11:23 - INFO - __main__ -     map = 0.6722435511873841\n","06/11/2021 11:11:25 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_5/checkpoint-best_run_cl__seed_42\n","06/11/2021 11:13:54 - INFO - __main__ -   Iter = 300\n","06/11/2021 11:13:54 - INFO - __main__ -   lr = 1.6316758747697976e-05\n","06/11/2021 11:13:54 - INFO - __main__ -   loss = 0.49348120093345643\n","QC:evaluate and save_aps is False\n","06/11/2021 11:13:54 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/11/2021 11:13:57 - INFO - __main__ -   ***** Running evaluation  *****\n","06/11/2021 11:13:57 - INFO - __main__ -     Num examples = 37210\n","06/11/2021 11:13:57 - INFO - __main__ -     Batch size = 64\n","06/11/2021 11:18:48 - INFO - __main__ -   ***** Eval results  *****\n","06/11/2021 11:18:48 - INFO - __main__ -     map = 0.6875494298767614\n","06/11/2021 11:18:51 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_5/checkpoint-best_run_cl__seed_42\n","06/11/2021 11:21:20 - INFO - __main__ -   Iter = 400\n","06/11/2021 11:21:20 - INFO - __main__ -   lr = 1.50890116635973e-05\n","06/11/2021 11:21:20 - INFO - __main__ -   loss = 0.47837371468544004\n","QC:evaluate and save_aps is False\n","06/11/2021 11:21:20 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/11/2021 11:21:23 - INFO - __main__ -   ***** Running evaluation  *****\n","06/11/2021 11:21:23 - INFO - __main__ -     Num examples = 37210\n","06/11/2021 11:21:23 - INFO - __main__ -     Batch size = 64\n","06/11/2021 11:26:14 - INFO - __main__ -   ***** Eval results  *****\n","06/11/2021 11:26:14 - INFO - __main__ -     map = 0.6893995043148511\n","06/11/2021 11:26:15 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_5/checkpoint-best_run_cl__seed_42\n","06/11/2021 11:28:45 - INFO - __main__ -   Iter = 500\n","06/11/2021 11:28:45 - INFO - __main__ -   lr = 1.3861264579496626e-05\n","06/11/2021 11:28:45 - INFO - __main__ -   loss = 0.44438026010990145\n","QC:evaluate and save_aps is False\n","06/11/2021 11:28:45 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/11/2021 11:28:48 - INFO - __main__ -   ***** Running evaluation  *****\n","06/11/2021 11:28:48 - INFO - __main__ -     Num examples = 37210\n","06/11/2021 11:28:48 - INFO - __main__ -     Batch size = 64\n","06/11/2021 11:33:38 - INFO - __main__ -   ***** Eval results  *****\n","06/11/2021 11:33:38 - INFO - __main__ -     map = 0.6919814821924478\n","06/11/2021 11:33:40 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_5/checkpoint-best_run_cl__seed_42\n","06/11/2021 11:34:46 - INFO - __main__ -   Finished epoch with 543 iterations.\n","06/11/2021 11:34:46 - INFO - __main__ -   Starting epoch 2\n","06/11/2021 11:34:46 - INFO - __main__ -   Training with all_random_batches\n","06/11/2021 11:36:09 - INFO - __main__ -   Iter = 600\n","06/11/2021 11:36:09 - INFO - __main__ -   lr = 1.263351749539595e-05\n","06/11/2021 11:36:09 - INFO - __main__ -   loss = 0.4177109572291374\n","QC:evaluate and save_aps is False\n","06/11/2021 11:36:09 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/11/2021 11:36:12 - INFO - __main__ -   ***** Running evaluation  *****\n","06/11/2021 11:36:12 - INFO - __main__ -     Num examples = 37210\n","06/11/2021 11:36:12 - INFO - __main__ -     Batch size = 64\n","06/11/2021 11:41:03 - INFO - __main__ -   ***** Eval results  *****\n","06/11/2021 11:41:03 - INFO - __main__ -     map = 0.6783415023269908\n","06/11/2021 11:43:33 - INFO - __main__ -   Iter = 700\n","06/11/2021 11:43:33 - INFO - __main__ -   lr = 1.1405770411295274e-05\n","06/11/2021 11:43:33 - INFO - __main__ -   loss = 0.4158913269639015\n","QC:evaluate and save_aps is False\n","06/11/2021 11:43:33 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/11/2021 11:43:36 - INFO - __main__ -   ***** Running evaluation  *****\n","06/11/2021 11:43:36 - INFO - __main__ -     Num examples = 37210\n","06/11/2021 11:43:36 - INFO - __main__ -     Batch size = 64\n","06/11/2021 11:48:27 - INFO - __main__ -   ***** Eval results  *****\n","06/11/2021 11:48:27 - INFO - __main__ -     map = 0.691142720637482\n","06/11/2021 11:50:57 - INFO - __main__ -   Iter = 800\n","06/11/2021 11:50:57 - INFO - __main__ -   lr = 1.01780233271946e-05\n","06/11/2021 11:50:57 - INFO - __main__ -   loss = 0.3931470239162445\n","QC:evaluate and save_aps is False\n","06/11/2021 11:50:57 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/11/2021 11:51:00 - INFO - __main__ -   ***** Running evaluation  *****\n","06/11/2021 11:51:00 - INFO - __main__ -     Num examples = 37210\n","06/11/2021 11:51:00 - INFO - __main__ -     Batch size = 64\n","06/11/2021 11:55:50 - INFO - __main__ -   ***** Eval results  *****\n","06/11/2021 11:55:50 - INFO - __main__ -     map = 0.6907766089504881\n","06/11/2021 11:58:19 - INFO - __main__ -   Iter = 900\n","06/11/2021 11:58:19 - INFO - __main__ -   lr = 8.950276243093923e-06\n","06/11/2021 11:58:19 - INFO - __main__ -   loss = 0.379052437543869\n","QC:evaluate and save_aps is False\n","06/11/2021 11:58:19 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/11/2021 11:58:22 - INFO - __main__ -   ***** Running evaluation  *****\n","06/11/2021 11:58:22 - INFO - __main__ -     Num examples = 37210\n","06/11/2021 11:58:22 - INFO - __main__ -     Batch size = 64\n","06/11/2021 12:03:13 - INFO - __main__ -   ***** Eval results  *****\n","06/11/2021 12:03:13 - INFO - __main__ -     map = 0.6941422130081092\n","06/11/2021 12:03:15 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_5/checkpoint-best_run_cl__seed_42\n","06/11/2021 12:05:44 - INFO - __main__ -   Iter = 1000\n","06/11/2021 12:05:44 - INFO - __main__ -   lr = 7.722529158993248e-06\n","06/11/2021 12:05:44 - INFO - __main__ -   loss = 0.38064321264624595\n","QC:evaluate and save_aps is False\n","06/11/2021 12:05:44 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/11/2021 12:05:47 - INFO - __main__ -   ***** Running evaluation  *****\n","06/11/2021 12:05:47 - INFO - __main__ -     Num examples = 37210\n","06/11/2021 12:05:47 - INFO - __main__ -     Batch size = 64\n","06/11/2021 12:10:39 - INFO - __main__ -   ***** Eval results  *****\n","06/11/2021 12:10:39 - INFO - __main__ -     map = 0.6979725752165964\n","06/11/2021 12:10:41 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_5/checkpoint-best_run_cl__seed_42\n","06/11/2021 12:12:52 - INFO - __main__ -   Finished epoch with 543 iterations.\n","06/11/2021 12:12:52 - INFO - __main__ -   Starting epoch 3\n","06/11/2021 12:12:52 - INFO - __main__ -   Training with all_random_batches\n","06/11/2021 12:13:10 - INFO - __main__ -   Iter = 1100\n","06/11/2021 12:13:10 - INFO - __main__ -   lr = 6.494782074892573e-06\n","06/11/2021 12:13:10 - INFO - __main__ -   loss = 0.37607267588376997\n","QC:evaluate and save_aps is False\n","06/11/2021 12:13:10 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/11/2021 12:13:13 - INFO - __main__ -   ***** Running evaluation  *****\n","06/11/2021 12:13:13 - INFO - __main__ -     Num examples = 37210\n","06/11/2021 12:13:13 - INFO - __main__ -     Batch size = 64\n","06/11/2021 12:18:04 - INFO - __main__ -   ***** Eval results  *****\n","06/11/2021 12:18:04 - INFO - __main__ -     map = 0.6950257653899161\n","06/11/2021 12:20:33 - INFO - __main__ -   Iter = 1200\n","06/11/2021 12:20:33 - INFO - __main__ -   lr = 5.267034990791897e-06\n","06/11/2021 12:20:33 - INFO - __main__ -   loss = 0.34990375325083733\n","QC:evaluate and save_aps is False\n","06/11/2021 12:20:33 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/11/2021 12:20:36 - INFO - __main__ -   ***** Running evaluation  *****\n","06/11/2021 12:20:36 - INFO - __main__ -     Num examples = 37210\n","06/11/2021 12:20:36 - INFO - __main__ -     Batch size = 64\n","06/11/2021 12:25:27 - INFO - __main__ -   ***** Eval results  *****\n","06/11/2021 12:25:27 - INFO - __main__ -     map = 0.698591115206273\n","06/11/2021 12:25:29 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_5/checkpoint-best_run_cl__seed_42\n","06/11/2021 12:27:58 - INFO - __main__ -   Iter = 1300\n","06/11/2021 12:27:58 - INFO - __main__ -   lr = 4.0392879066912225e-06\n","06/11/2021 12:27:58 - INFO - __main__ -   loss = 0.3397818550467491\n","QC:evaluate and save_aps is False\n","06/11/2021 12:27:58 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/11/2021 12:28:01 - INFO - __main__ -   ***** Running evaluation  *****\n","06/11/2021 12:28:01 - INFO - __main__ -     Num examples = 37210\n","06/11/2021 12:28:01 - INFO - __main__ -     Batch size = 64\n","06/11/2021 12:32:52 - INFO - __main__ -   ***** Eval results  *****\n","06/11/2021 12:32:52 - INFO - __main__ -     map = 0.6961158887993083\n","06/11/2021 12:35:21 - INFO - __main__ -   Iter = 1400\n","06/11/2021 12:35:21 - INFO - __main__ -   lr = 2.8115408225905465e-06\n","06/11/2021 12:35:21 - INFO - __main__ -   loss = 0.3217308359593153\n","QC:evaluate and save_aps is False\n","06/11/2021 12:35:21 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/11/2021 12:35:24 - INFO - __main__ -   ***** Running evaluation  *****\n","06/11/2021 12:35:24 - INFO - __main__ -     Num examples = 37210\n","06/11/2021 12:35:24 - INFO - __main__ -     Batch size = 64\n","06/11/2021 12:40:15 - INFO - __main__ -   ***** Eval results  *****\n","06/11/2021 12:40:15 - INFO - __main__ -     map = 0.6944654534751292\n","06/11/2021 12:42:44 - INFO - __main__ -   Iter = 1500\n","06/11/2021 12:42:44 - INFO - __main__ -   lr = 1.5837937384898713e-06\n","06/11/2021 12:42:44 - INFO - __main__ -   loss = 0.32823932692408564\n","QC:evaluate and save_aps is False\n","06/11/2021 12:42:44 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/11/2021 12:42:48 - INFO - __main__ -   ***** Running evaluation  *****\n","06/11/2021 12:42:48 - INFO - __main__ -     Num examples = 37210\n","06/11/2021 12:42:48 - INFO - __main__ -     Batch size = 64\n","06/11/2021 12:47:39 - INFO - __main__ -   ***** Eval results  *****\n","06/11/2021 12:47:39 - INFO - __main__ -     map = 0.6980775137251902\n","06/11/2021 12:50:08 - INFO - __main__ -   Iter = 1600\n","06/11/2021 12:50:08 - INFO - __main__ -   lr = 3.5604665438919586e-07\n","06/11/2021 12:50:08 - INFO - __main__ -   loss = 0.3238292732834816\n","QC:evaluate and save_aps is False\n","06/11/2021 12:50:08 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/11/2021 12:50:11 - INFO - __main__ -   ***** Running evaluation  *****\n","06/11/2021 12:50:11 - INFO - __main__ -     Num examples = 37210\n","06/11/2021 12:50:11 - INFO - __main__ -     Batch size = 64\n","06/11/2021 12:55:02 - INFO - __main__ -   ***** Eval results  *****\n","06/11/2021 12:55:02 - INFO - __main__ -     map = 0.6986150036472538\n","06/11/2021 12:55:04 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_5/checkpoint-best_run_cl__seed_42\n","06/11/2021 12:55:52 - INFO - __main__ -   Finished epoch with 543 iterations.\n","06/11/2021 12:55:52 - INFO - __main__ -    global_step = 1632, average loss = 0.41027585276877326\n","QC: checkpoint.split('-') ['drive/MyDrive/transformers_cl/ms_v2_bert_5/checkpoint', 'best_run_cl__seed_42']\n","QC: global_step: best_run_cl__seed_42 best_run_name best_run_cl__seed_42\n","QC: entered evaluation\n","QC:evaluate and save_aps is True\n","06/11/2021 12:55:56 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_train_bert-base-uncased_128_ms_v2\n","06/11/2021 12:55:59 - INFO - __main__ -   ***** Running evaluation best_run_cl__seed_42 *****\n","06/11/2021 12:55:59 - INFO - __main__ -     Num examples = 34736\n","06/11/2021 12:55:59 - INFO - __main__ -     Batch size = 2\n","drive/MyDrive/transformers_cl/ms_v2_bert_5/  and aps_ saved\n","drive/MyDrive/transformers_cl/ms_v2_bert_5/  and losses_ saved\n","drive/MyDrive/transformers_cl/ms_v2_bert_5/  and preds_ saved\n","06/11/2021 13:01:18 - INFO - __main__ -   ***** Eval results best_run_cl__seed_42 *****\n","06/11/2021 13:01:18 - INFO - __main__ -     map = 0.9778327959465684\n","QC results:  {} , save_aps is True , eval_all_checkpoints True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y9IvZmmlLnV9"},"source":["# import fasttext.util\n","# fasttext.util.download_model('en', if_exists='ignore')  # English\n","# ft = fasttext.load_model('cc.en.300.bin')\n","# ft.save_model('cc.en.100.vec')\n","\n","# from gensim.models import KeyedVectors\n","# wvecs = KeyedVectors.load_word2vec_format('cc.en.300.bin',\n","#         binary=True) \n","# # The following way doesn't work\n","# from gensim.models.fasttext import FastText\n","# mod = FastText.load_fasttext_format('cc.en.300.bin')\n","# from gensim.models.fasttext import FastText as FastText_gensim\n","# pretrained_model=FastText_gensim.load('cc.en.300.bin')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_5xFZtsPIjEe"},"source":["# 06-14 batch size = 64, use untrained model, map = 0.72"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eJg-__e8EGgy","executionInfo":{"status":"ok","timestamp":1623674445678,"user_tz":-120,"elapsed":319366,"user":{"displayName":"Chen Qian","photoUrl":"","userId":"11245437508655380561"}},"outputId":"bc0f05a9-20ea-49ff-9656-d3040e57b8a8"},"source":["# I want to use the untrained model so do_train = False\n","!python drive/MyDrive/transformers_cl/run_glue_copy.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  ms_v2 \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/MSDialog \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 3 \\\n","    --output_dir drive/MyDrive/transformers_cl/ms_v2_bert \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 100 \\\n","    --save_aps \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["06/14/2021 12:35:28 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","06/14/2021 12:35:28 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","06/14/2021 12:35:28 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"ms_v2\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","06/14/2021 12:35:28 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","06/14/2021 12:35:28 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","06/14/2021 12:35:31 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","06/14/2021 12:35:31 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","06/14/2021 12:35:34 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/MSDialog', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=False, eval_all_checkpoints=True, eval_difficult=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise=0.0, num_train_epochs=3.0, output_dir='drive/MyDrive/transformers_cl/ms_v2_bert', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='ms_v2', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","06/14/2021 12:35:34 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_train_bert-base-uncased_128_ms_v2\n","06/14/2021 12:35:37 - INFO - __main__ -   ***** Running evaluation  *****\n","06/14/2021 12:35:37 - INFO - __main__ -     Num examples = 34736\n","06/14/2021 12:35:37 - INFO - __main__ -     Batch size = 2\n","500 samples evaluated\n","1000 samples evaluated\n","1500 samples evaluated\n","2000 samples evaluated\n","2500 samples evaluated\n","3000 samples evaluated\n","3500 samples evaluated\n","4000 samples evaluated\n","4500 samples evaluated\n","5000 samples evaluated\n","5500 samples evaluated\n","6000 samples evaluated\n","6500 samples evaluated\n","7000 samples evaluated\n","7500 samples evaluated\n","8000 samples evaluated\n","8500 samples evaluated\n","9000 samples evaluated\n","9500 samples evaluated\n","10000 samples evaluated\n","10500 samples evaluated\n","11000 samples evaluated\n","11500 samples evaluated\n","12000 samples evaluated\n","12500 samples evaluated\n","13000 samples evaluated\n","13500 samples evaluated\n","14000 samples evaluated\n","14500 samples evaluated\n","15000 samples evaluated\n","15500 samples evaluated\n","16000 samples evaluated\n","16500 samples evaluated\n","17000 samples evaluated\n","17500 samples evaluated\n","18000 samples evaluated\n","18500 samples evaluated\n","19000 samples evaluated\n","19500 samples evaluated\n","20000 samples evaluated\n","20500 samples evaluated\n","21000 samples evaluated\n","21500 samples evaluated\n","22000 samples evaluated\n","22500 samples evaluated\n","23000 samples evaluated\n","23500 samples evaluated\n","24000 samples evaluated\n","24500 samples evaluated\n","25000 samples evaluated\n","25500 samples evaluated\n","26000 samples evaluated\n","26500 samples evaluated\n","27000 samples evaluated\n","27500 samples evaluated\n","28000 samples evaluated\n","28500 samples evaluated\n","29000 samples evaluated\n","29500 samples evaluated\n","30000 samples evaluated\n","30500 samples evaluated\n","31000 samples evaluated\n","31500 samples evaluated\n","32000 samples evaluated\n","32500 samples evaluated\n","33000 samples evaluated\n","33500 samples evaluated\n","34000 samples evaluated\n","34500 samples evaluated\n","QC: started to store aps\n","06/14/2021 12:40:45 - INFO - __main__ -   ***** Eval results  *****\n","06/14/2021 12:40:45 - INFO - __main__ -     map = 0.7280918931368033\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MaSuRBtRiBFU"},"source":["# 06-16 batch size = 64, trained epoch = 1, map = 0.95"]},{"cell_type":"code","metadata":{"id":"umWh-5u5iXkv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623829250309,"user_tz":-120,"elapsed":2701104,"user":{"displayName":"xiaokang qian","photoUrl":"","userId":"16136989389156139825"}},"outputId":"cf6141ba-f4c1-48a2-cc03-b5a6f747ddcd"},"source":["# running timeï¼45m, for 1 epoch\n","!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  ms_v2 \\\n","    --do_train \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/MSDialog \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --output_dir drive/MyDrive/transformers_cl/ms_v2_bert_1/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 100 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["06/16/2021 06:55:49 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","06/16/2021 06:55:49 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","06/16/2021 06:55:49 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"ms_v2\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","06/16/2021 06:55:49 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","06/16/2021 06:55:49 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","06/16/2021 06:55:52 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","06/16/2021 06:55:52 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","06/16/2021 06:55:56 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/MSDialog', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/ms_v2_bert_1/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='ms_v2', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","QC: do_train is True do_eval is True save_aps is True\n","QC: local rank is -1 eval_during_training is True\n","06/16/2021 06:55:56 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_train_bert-base-uncased_128_ms_v2\n","QC:training\n","06/16/2021 06:55:59 - INFO - __main__ -   ***** Running training *****\n","06/16/2021 06:55:59 - INFO - __main__ -     Num examples = 34736\n","06/16/2021 06:55:59 - INFO - __main__ -     Num Epochs = 1\n","06/16/2021 06:55:59 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","06/16/2021 06:55:59 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","06/16/2021 06:55:59 - INFO - __main__ -     Gradient Accumulation steps = 1\n","06/16/2021 06:55:59 - INFO - __main__ -     Total optimization steps = 543\n","06/16/2021 06:55:59 - INFO - __main__ -     percentage by epoch = 1.000000\n","06/16/2021 06:55:59 - INFO - __main__ -     data_loaders = [('all_random_batches', <torch.utils.data.dataloader.DataLoader object at 0x7fb7060ec810>)]\n","06/16/2021 06:55:59 - INFO - __main__ -     QC len(data_loaders) = 1\n","06/16/2021 06:55:59 - INFO - __main__ -   Starting epoch 1\n","06/16/2021 06:55:59 - INFO - __main__ -   Training with all_random_batches\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","06/16/2021 06:58:32 - INFO - __main__ -   Iter = 100\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","06/16/2021 06:58:32 - INFO - __main__ -   lr = 1.6316758747697976e-05\n","06/16/2021 06:58:32 - INFO - __main__ -   loss = 0.6132629922032357\n","QC:evaluate and save_aps is False\n","06/16/2021 06:58:32 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 06:58:35 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 06:58:35 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 06:58:35 - INFO - __main__ -     Batch size = 64\n","06/16/2021 07:03:36 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 07:03:36 - INFO - __main__ -     map = 0.6253646186594319\n","06/16/2021 07:03:37 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_1/checkpoint-best_run_cl__seed_42\n","06/16/2021 07:06:10 - INFO - __main__ -   Iter = 200\n","06/16/2021 07:06:10 - INFO - __main__ -   lr = 1.263351749539595e-05\n","06/16/2021 07:06:10 - INFO - __main__ -   loss = 0.5372397994995117\n","QC:evaluate and save_aps is False\n","06/16/2021 07:06:10 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 07:06:13 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 07:06:13 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 07:06:13 - INFO - __main__ -     Batch size = 64\n","06/16/2021 07:11:14 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 07:11:14 - INFO - __main__ -     map = 0.6730944702524926\n","06/16/2021 07:11:16 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_1/checkpoint-best_run_cl__seed_42\n","06/16/2021 07:13:49 - INFO - __main__ -   Iter = 300\n","06/16/2021 07:13:49 - INFO - __main__ -   lr = 8.950276243093923e-06\n","06/16/2021 07:13:49 - INFO - __main__ -   loss = 0.49666433662176135\n","QC:evaluate and save_aps is False\n","06/16/2021 07:13:49 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 07:13:53 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 07:13:53 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 07:13:53 - INFO - __main__ -     Batch size = 64\n","06/16/2021 07:18:54 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 07:18:54 - INFO - __main__ -     map = 0.683733997943889\n","06/16/2021 07:18:55 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_1/checkpoint-best_run_cl__seed_42\n","06/16/2021 07:21:28 - INFO - __main__ -   Iter = 400\n","06/16/2021 07:21:28 - INFO - __main__ -   lr = 5.267034990791897e-06\n","06/16/2021 07:21:28 - INFO - __main__ -   loss = 0.47771856129169465\n","QC:evaluate and save_aps is False\n","06/16/2021 07:21:28 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 07:21:31 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 07:21:31 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 07:21:31 - INFO - __main__ -     Batch size = 64\n","06/16/2021 07:26:32 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 07:26:32 - INFO - __main__ -     map = 0.6888942211301797\n","06/16/2021 07:26:34 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_1/checkpoint-best_run_cl__seed_42\n","06/16/2021 07:29:07 - INFO - __main__ -   Iter = 500\n","06/16/2021 07:29:07 - INFO - __main__ -   lr = 1.5837937384898713e-06\n","06/16/2021 07:29:07 - INFO - __main__ -   loss = 0.45955868273973466\n","QC:evaluate and save_aps is False\n","06/16/2021 07:29:07 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 07:29:10 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 07:29:10 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 07:29:10 - INFO - __main__ -     Batch size = 64\n","06/16/2021 07:34:11 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 07:34:11 - INFO - __main__ -     map = 0.6896796602722447\n","06/16/2021 07:34:13 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_1/checkpoint-best_run_cl__seed_42\n","06/16/2021 07:35:20 - INFO - __main__ -   Finished epoch with 543 iterations.\n","06/16/2021 07:35:20 - INFO - __main__ -    global_step = 544, average loss = 0.5114050342098755\n","QC: checkpoint.split('-') ['drive/MyDrive/transformers_cl/ms_v2_bert_1/checkpoint', 'best_run_cl__seed_42']\n","QC: global_step: best_run_cl__seed_42 best_run_name best_run_cl__seed_42\n","QC: entered evaluation\n","QC:evaluate and save_aps is True\n","06/16/2021 07:35:23 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_train_bert-base-uncased_128_ms_v2\n","06/16/2021 07:35:27 - INFO - __main__ -   ***** Running evaluation best_run_cl__seed_42 *****\n","06/16/2021 07:35:27 - INFO - __main__ -     Num examples = 34736\n","06/16/2021 07:35:27 - INFO - __main__ -     Batch size = 2\n","drive/MyDrive/transformers_cl/ms_v2_bert_1/  and aps_ saved\n","drive/MyDrive/transformers_cl/ms_v2_bert_1/  and losses_ saved\n","drive/MyDrive/transformers_cl/ms_v2_bert_1/  and preds_ saved\n","06/16/2021 07:40:48 - INFO - __main__ -   ***** Eval results best_run_cl__seed_42 *****\n","06/16/2021 07:40:48 - INFO - __main__ -     map = 0.9457911100875173\n","QC results:  {} , save_aps is True , eval_all_checkpoints True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FwdR4ZuliSn9"},"source":["# 06-16 batch size = 64, trained epoch = 2, map = 0.96"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eQwZ4KKhidw6","executionInfo":{"status":"ok","timestamp":1623832600367,"user_tz":-120,"elapsed":5165822,"user":{"displayName":"T. Z.","photoUrl":"","userId":"04670299702794629529"}},"outputId":"3c5655d7-f9a1-4702-9ede-cfbaa5f73c67"},"source":["# running timeï¼2h5m  for 2 epochs \n","!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  ms_v2 \\\n","    --do_train \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/MSDialog \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 2 \\\n","    --output_dir drive/MyDrive/transformers_cl/ms_v2_bert_2/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 100 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["06/16/2021 07:10:39 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","06/16/2021 07:10:39 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmppbms0bwm\n","\r  0% 0/433 [00:00<?, ?B/s]\r100% 433/433 [00:00<00:00, 494994.18B/s]\n","06/16/2021 07:10:39 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmppbms0bwm to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","06/16/2021 07:10:39 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","06/16/2021 07:10:39 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmppbms0bwm\n","06/16/2021 07:10:39 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","06/16/2021 07:10:39 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"ms_v2\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","06/16/2021 07:10:39 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp3_e92d5b\n","\r  0% 0/231508 [00:00<?, ?B/s]\r100% 231508/231508 [00:00<00:00, 25926917.93B/s]\n","06/16/2021 07:10:39 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp3_e92d5b to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","06/16/2021 07:10:39 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","06/16/2021 07:10:39 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp3_e92d5b\n","06/16/2021 07:10:39 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","06/16/2021 07:10:39 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmp_gqs_lzg\n","100% 440473133/440473133 [00:07<00:00, 58617667.23B/s]\n","06/16/2021 07:10:46 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp_gqs_lzg to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","06/16/2021 07:10:48 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","06/16/2021 07:10:48 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp_gqs_lzg\n","06/16/2021 07:10:48 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","06/16/2021 07:10:51 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","06/16/2021 07:10:51 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","06/16/2021 07:11:02 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/MSDialog', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=2.0, output_dir='drive/MyDrive/transformers_cl/ms_v2_bert_2/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='ms_v2', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","QC: do_train is True do_eval is True save_aps is True\n","QC: local rank is -1 eval_during_training is True\n","06/16/2021 07:11:02 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_train_bert-base-uncased_128_ms_v2\n","QC:training\n","06/16/2021 07:11:06 - INFO - __main__ -   ***** Running training *****\n","06/16/2021 07:11:06 - INFO - __main__ -     Num examples = 34736\n","06/16/2021 07:11:06 - INFO - __main__ -     Num Epochs = 2\n","06/16/2021 07:11:06 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","06/16/2021 07:11:06 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","06/16/2021 07:11:06 - INFO - __main__ -     Gradient Accumulation steps = 1\n","06/16/2021 07:11:06 - INFO - __main__ -     Total optimization steps = 1086\n","06/16/2021 07:11:06 - INFO - __main__ -     percentage by epoch = 1.000000\n","06/16/2021 07:11:06 - INFO - __main__ -     data_loaders = [('all_random_batches', <torch.utils.data.dataloader.DataLoader object at 0x7f10d0d21c50>)]\n","06/16/2021 07:11:06 - INFO - __main__ -     QC len(data_loaders) = 1\n","06/16/2021 07:11:06 - INFO - __main__ -   Starting epoch 1\n","06/16/2021 07:11:06 - INFO - __main__ -   Training with all_random_batches\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","06/16/2021 07:13:36 - INFO - __main__ -   Iter = 100\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","06/16/2021 07:13:36 - INFO - __main__ -   lr = 1.815837937384899e-05\n","06/16/2021 07:13:36 - INFO - __main__ -   loss = 0.6114488297700882\n","QC:evaluate and save_aps is False\n","06/16/2021 07:13:36 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 07:13:40 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 07:13:40 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 07:13:40 - INFO - __main__ -     Batch size = 64\n","06/16/2021 07:18:48 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 07:18:48 - INFO - __main__ -     map = 0.6234613284532652\n","06/16/2021 07:18:50 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_2/checkpoint-best_run_cl__seed_42\n","06/16/2021 07:21:25 - INFO - __main__ -   Iter = 200\n","06/16/2021 07:21:25 - INFO - __main__ -   lr = 1.6316758747697976e-05\n","06/16/2021 07:21:25 - INFO - __main__ -   loss = 0.5367865425348282\n","QC:evaluate and save_aps is False\n","06/16/2021 07:21:25 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 07:21:28 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 07:21:28 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 07:21:28 - INFO - __main__ -     Batch size = 64\n","06/16/2021 07:26:35 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 07:26:35 - INFO - __main__ -     map = 0.6742916650669933\n","06/16/2021 07:26:37 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_2/checkpoint-best_run_cl__seed_42\n","06/16/2021 07:29:12 - INFO - __main__ -   Iter = 300\n","06/16/2021 07:29:12 - INFO - __main__ -   lr = 1.4475138121546963e-05\n","06/16/2021 07:29:12 - INFO - __main__ -   loss = 0.4935488110780716\n","QC:evaluate and save_aps is False\n","06/16/2021 07:29:12 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 07:29:15 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 07:29:15 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 07:29:15 - INFO - __main__ -     Batch size = 64\n","06/16/2021 07:34:24 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 07:34:24 - INFO - __main__ -     map = 0.6872301352682977\n","06/16/2021 07:34:25 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_2/checkpoint-best_run_cl__seed_42\n","06/16/2021 07:37:00 - INFO - __main__ -   Iter = 400\n","06/16/2021 07:37:00 - INFO - __main__ -   lr = 1.263351749539595e-05\n","06/16/2021 07:37:00 - INFO - __main__ -   loss = 0.47632420271635056\n","QC:evaluate and save_aps is False\n","06/16/2021 07:37:00 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 07:37:04 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 07:37:04 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 07:37:04 - INFO - __main__ -     Batch size = 64\n","06/16/2021 07:42:12 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 07:42:12 - INFO - __main__ -     map = 0.690652687662902\n","06/16/2021 07:42:14 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_2/checkpoint-best_run_cl__seed_42\n","06/16/2021 07:44:49 - INFO - __main__ -   Iter = 500\n","06/16/2021 07:44:49 - INFO - __main__ -   lr = 1.0791896869244936e-05\n","06/16/2021 07:44:49 - INFO - __main__ -   loss = 0.4454049083590508\n","QC:evaluate and save_aps is False\n","06/16/2021 07:44:49 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 07:44:52 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 07:44:52 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 07:44:52 - INFO - __main__ -     Batch size = 64\n","06/16/2021 07:49:59 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 07:49:59 - INFO - __main__ -     map = 0.6912613096837784\n","06/16/2021 07:50:01 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_2/checkpoint-best_run_cl__seed_42\n","06/16/2021 07:51:09 - INFO - __main__ -   Finished epoch with 543 iterations.\n","06/16/2021 07:51:09 - INFO - __main__ -   Starting epoch 2\n","06/16/2021 07:51:09 - INFO - __main__ -   Training with all_random_batches\n","06/16/2021 07:52:36 - INFO - __main__ -   Iter = 600\n","06/16/2021 07:52:36 - INFO - __main__ -   lr = 8.950276243093923e-06\n","06/16/2021 07:52:36 - INFO - __main__ -   loss = 0.4248131608963013\n","QC:evaluate and save_aps is False\n","06/16/2021 07:52:36 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 07:52:39 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 07:52:39 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 07:52:39 - INFO - __main__ -     Batch size = 64\n","06/16/2021 07:57:47 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 07:57:47 - INFO - __main__ -     map = 0.681451052157852\n","06/16/2021 08:00:22 - INFO - __main__ -   Iter = 700\n","06/16/2021 08:00:22 - INFO - __main__ -   lr = 7.10865561694291e-06\n","06/16/2021 08:00:22 - INFO - __main__ -   loss = 0.422758022248745\n","QC:evaluate and save_aps is False\n","06/16/2021 08:00:22 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 08:00:25 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 08:00:25 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 08:00:25 - INFO - __main__ -     Batch size = 64\n","06/16/2021 08:05:32 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 08:05:32 - INFO - __main__ -     map = 0.6928049935373246\n","06/16/2021 08:05:33 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_2/checkpoint-best_run_cl__seed_42\n","06/16/2021 08:08:08 - INFO - __main__ -   Iter = 800\n","06/16/2021 08:08:08 - INFO - __main__ -   lr = 5.267034990791897e-06\n","06/16/2021 08:08:08 - INFO - __main__ -   loss = 0.40351421117782593\n","QC:evaluate and save_aps is False\n","06/16/2021 08:08:08 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 08:08:12 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 08:08:12 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 08:08:12 - INFO - __main__ -     Batch size = 64\n","06/16/2021 08:13:20 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 08:13:20 - INFO - __main__ -     map = 0.6940388741719037\n","06/16/2021 08:13:21 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_2/checkpoint-best_run_cl__seed_42\n","06/16/2021 08:15:56 - INFO - __main__ -   Iter = 900\n","06/16/2021 08:15:56 - INFO - __main__ -   lr = 3.4254143646408845e-06\n","06/16/2021 08:15:56 - INFO - __main__ -   loss = 0.3932590425014496\n","QC:evaluate and save_aps is False\n","06/16/2021 08:15:56 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 08:16:00 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 08:16:00 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 08:16:00 - INFO - __main__ -     Batch size = 64\n","06/16/2021 08:21:07 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 08:21:07 - INFO - __main__ -     map = 0.6952660361824575\n","06/16/2021 08:21:09 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_2/checkpoint-best_run_cl__seed_42\n","06/16/2021 08:23:44 - INFO - __main__ -   Iter = 1000\n","06/16/2021 08:23:44 - INFO - __main__ -   lr = 1.5837937384898713e-06\n","06/16/2021 08:23:44 - INFO - __main__ -   loss = 0.40364048585295675\n","QC:evaluate and save_aps is False\n","06/16/2021 08:23:44 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 08:23:47 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 08:23:47 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 08:23:47 - INFO - __main__ -     Batch size = 64\n","06/16/2021 08:28:54 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 08:28:54 - INFO - __main__ -     map = 0.6960677919828692\n","06/16/2021 08:28:56 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_2/checkpoint-best_run_cl__seed_42\n","06/16/2021 08:31:12 - INFO - __main__ -   Finished epoch with 543 iterations.\n","06/16/2021 08:31:12 - INFO - __main__ -    global_step = 1088, average loss = 0.4564572592430255\n","QC: checkpoint.split('-') ['drive/MyDrive/transformers_cl/ms_v2_bert_2/checkpoint', 'best_run_cl__seed_42']\n","QC: global_step: best_run_cl__seed_42 best_run_name best_run_cl__seed_42\n","QC: entered evaluation\n","QC:evaluate and save_aps is True\n","06/16/2021 08:31:15 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_train_bert-base-uncased_128_ms_v2\n","06/16/2021 08:31:18 - INFO - __main__ -   ***** Running evaluation best_run_cl__seed_42 *****\n","06/16/2021 08:31:18 - INFO - __main__ -     Num examples = 34736\n","06/16/2021 08:31:18 - INFO - __main__ -     Batch size = 2\n","drive/MyDrive/transformers_cl/ms_v2_bert_2/  and aps_ saved\n","drive/MyDrive/transformers_cl/ms_v2_bert_2/  and losses_ saved\n","drive/MyDrive/transformers_cl/ms_v2_bert_2/  and preds_ saved\n","06/16/2021 08:36:38 - INFO - __main__ -   ***** Eval results best_run_cl__seed_42 *****\n","06/16/2021 08:36:38 - INFO - __main__ -     map = 0.9645900506678949\n","QC results:  {} , save_aps is True , eval_all_checkpoints True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mNWz-wOqiad9"},"source":["# 06-16 batch size = 64, trained epoch = 4, map = 0.98"]},{"cell_type":"code","metadata":{"id":"Jpl7Q1E4iR3G","colab":{"base_uri":"https://localhost:8080/"},"outputId":"66521974-22d1-4406-d16c-0f6863ce2945"},"source":["# running timeï¼3h  for 4 epochs \n","!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  ms_v2 \\\n","    --do_train \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/MSDialog \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 4 \\\n","    --output_dir drive/MyDrive/transformers_cl/ms_v2_bert_4/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 100 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["06/16/2021 07:52:55 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","06/16/2021 07:52:55 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","06/16/2021 07:52:55 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"ms_v2\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","06/16/2021 07:52:55 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","06/16/2021 07:52:55 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","06/16/2021 07:52:59 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","06/16/2021 07:52:59 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","06/16/2021 07:53:02 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/MSDialog', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=4.0, output_dir='drive/MyDrive/transformers_cl/ms_v2_bert_4/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='ms_v2', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","QC: do_train is True do_eval is True save_aps is True\n","QC: local rank is -1 eval_during_training is True\n","06/16/2021 07:53:02 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_train_bert-base-uncased_128_ms_v2\n","QC:training\n","06/16/2021 07:53:05 - INFO - __main__ -   ***** Running training *****\n","06/16/2021 07:53:05 - INFO - __main__ -     Num examples = 34736\n","06/16/2021 07:53:05 - INFO - __main__ -     Num Epochs = 4\n","06/16/2021 07:53:05 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","06/16/2021 07:53:05 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","06/16/2021 07:53:05 - INFO - __main__ -     Gradient Accumulation steps = 1\n","06/16/2021 07:53:05 - INFO - __main__ -     Total optimization steps = 2172\n","06/16/2021 07:53:05 - INFO - __main__ -     percentage by epoch = 1.000000\n","06/16/2021 07:53:05 - INFO - __main__ -     data_loaders = [('all_random_batches', <torch.utils.data.dataloader.DataLoader object at 0x7f752860e8d0>)]\n","06/16/2021 07:53:05 - INFO - __main__ -     QC len(data_loaders) = 1\n","06/16/2021 07:53:05 - INFO - __main__ -   Starting epoch 1\n","06/16/2021 07:53:05 - INFO - __main__ -   Training with all_random_batches\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","06/16/2021 07:55:31 - INFO - __main__ -   Iter = 100\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","06/16/2021 07:55:31 - INFO - __main__ -   lr = 1.9079189686924494e-05\n","06/16/2021 07:55:31 - INFO - __main__ -   loss = 0.6113564994931221\n","QC:evaluate and save_aps is False\n","06/16/2021 07:55:31 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 07:55:34 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 07:55:34 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 07:55:34 - INFO - __main__ -     Batch size = 64\n","06/16/2021 08:00:34 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 08:00:34 - INFO - __main__ -     map = 0.6189822457693993\n","06/16/2021 08:00:36 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_4/checkpoint-best_run_cl__seed_42\n","06/16/2021 08:03:08 - INFO - __main__ -   Iter = 200\n","06/16/2021 08:03:08 - INFO - __main__ -   lr = 1.815837937384899e-05\n","06/16/2021 08:03:08 - INFO - __main__ -   loss = 0.539174065887928\n","QC:evaluate and save_aps is False\n","06/16/2021 08:03:08 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 08:03:11 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 08:03:11 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 08:03:11 - INFO - __main__ -     Batch size = 64\n","06/16/2021 08:08:12 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 08:08:12 - INFO - __main__ -     map = 0.6737443638209556\n","06/16/2021 08:08:13 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_4/checkpoint-best_run_cl__seed_42\n","06/16/2021 08:10:46 - INFO - __main__ -   Iter = 300\n","06/16/2021 08:10:46 - INFO - __main__ -   lr = 1.7237569060773483e-05\n","06/16/2021 08:10:46 - INFO - __main__ -   loss = 0.4928670293092728\n","QC:evaluate and save_aps is False\n","06/16/2021 08:10:46 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 08:10:49 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 08:10:49 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 08:10:49 - INFO - __main__ -     Batch size = 64\n","06/16/2021 08:15:49 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 08:15:49 - INFO - __main__ -     map = 0.6872216036822334\n","06/16/2021 08:15:51 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_4/checkpoint-best_run_cl__seed_42\n","06/16/2021 08:18:24 - INFO - __main__ -   Iter = 400\n","06/16/2021 08:18:24 - INFO - __main__ -   lr = 1.6316758747697976e-05\n","06/16/2021 08:18:24 - INFO - __main__ -   loss = 0.4781365343928337\n","QC:evaluate and save_aps is False\n","06/16/2021 08:18:24 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 08:18:27 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 08:18:27 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 08:18:27 - INFO - __main__ -     Batch size = 64\n","06/16/2021 08:23:28 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 08:23:28 - INFO - __main__ -     map = 0.6907841807331199\n","06/16/2021 08:23:31 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_4/checkpoint-best_run_cl__seed_42\n","06/16/2021 08:26:03 - INFO - __main__ -   Iter = 500\n","06/16/2021 08:26:03 - INFO - __main__ -   lr = 1.539594843462247e-05\n","06/16/2021 08:26:03 - INFO - __main__ -   loss = 0.44279776722192765\n","QC:evaluate and save_aps is False\n","06/16/2021 08:26:03 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 08:26:06 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 08:26:06 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 08:26:06 - INFO - __main__ -     Batch size = 64\n","06/16/2021 08:31:07 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 08:31:07 - INFO - __main__ -     map = 0.6915728192199584\n","06/16/2021 08:31:09 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_4/checkpoint-best_run_cl__seed_42\n","06/16/2021 08:32:16 - INFO - __main__ -   Finished epoch with 543 iterations.\n","06/16/2021 08:32:16 - INFO - __main__ -   Starting epoch 2\n","06/16/2021 08:32:16 - INFO - __main__ -   Training with all_random_batches\n","06/16/2021 08:33:41 - INFO - __main__ -   Iter = 600\n","06/16/2021 08:33:41 - INFO - __main__ -   lr = 1.4475138121546963e-05\n","06/16/2021 08:33:41 - INFO - __main__ -   loss = 0.4151767408847809\n","QC:evaluate and save_aps is False\n","06/16/2021 08:33:41 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 08:33:44 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 08:33:44 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 08:33:44 - INFO - __main__ -     Batch size = 64\n","06/16/2021 08:38:45 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 08:38:45 - INFO - __main__ -     map = 0.6813663761661618\n","06/16/2021 08:41:17 - INFO - __main__ -   Iter = 700\n","06/16/2021 08:41:17 - INFO - __main__ -   lr = 1.3554327808471458e-05\n","06/16/2021 08:41:17 - INFO - __main__ -   loss = 0.41258544981479645\n","QC:evaluate and save_aps is False\n","06/16/2021 08:41:17 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 08:41:20 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 08:41:20 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 08:41:20 - INFO - __main__ -     Batch size = 64\n","06/16/2021 08:46:21 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 08:46:21 - INFO - __main__ -     map = 0.6928519172606793\n","06/16/2021 08:46:23 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_4/checkpoint-best_run_cl__seed_42\n","06/16/2021 08:48:56 - INFO - __main__ -   Iter = 800\n","06/16/2021 08:48:56 - INFO - __main__ -   lr = 1.263351749539595e-05\n","06/16/2021 08:48:56 - INFO - __main__ -   loss = 0.38872400850057603\n","QC:evaluate and save_aps is False\n","06/16/2021 08:48:56 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 08:48:59 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 08:48:59 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 08:48:59 - INFO - __main__ -     Batch size = 64\n","06/16/2021 08:53:59 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 08:53:59 - INFO - __main__ -     map = 0.6902529828557782\n","06/16/2021 08:56:32 - INFO - __main__ -   Iter = 900\n","06/16/2021 08:56:32 - INFO - __main__ -   lr = 1.1712707182320442e-05\n","06/16/2021 08:56:32 - INFO - __main__ -   loss = 0.37321418449282645\n","QC:evaluate and save_aps is False\n","06/16/2021 08:56:32 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 08:56:35 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 08:56:35 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 08:56:35 - INFO - __main__ -     Batch size = 64\n","06/16/2021 09:01:36 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 09:01:36 - INFO - __main__ -     map = 0.6938004163414004\n","06/16/2021 09:01:37 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_4/checkpoint-best_run_cl__seed_42\n","06/16/2021 09:04:10 - INFO - __main__ -   Iter = 1000\n","06/16/2021 09:04:10 - INFO - __main__ -   lr = 1.0791896869244936e-05\n","06/16/2021 09:04:10 - INFO - __main__ -   loss = 0.36996305987238887\n","QC:evaluate and save_aps is False\n","06/16/2021 09:04:10 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 09:04:13 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 09:04:13 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 09:04:13 - INFO - __main__ -     Batch size = 64\n","06/16/2021 09:09:13 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 09:09:13 - INFO - __main__ -     map = 0.6956422791279021\n","06/16/2021 09:09:14 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_4/checkpoint-best_run_cl__seed_42\n","06/16/2021 09:11:29 - INFO - __main__ -   Finished epoch with 543 iterations.\n","06/16/2021 09:11:29 - INFO - __main__ -   Starting epoch 3\n","06/16/2021 09:11:29 - INFO - __main__ -   Training with all_random_batches\n","06/16/2021 09:11:47 - INFO - __main__ -   Iter = 1100\n","06/16/2021 09:11:47 - INFO - __main__ -   lr = 9.87108655616943e-06\n","06/16/2021 09:11:47 - INFO - __main__ -   loss = 0.3677494393289089\n","QC:evaluate and save_aps is False\n","06/16/2021 09:11:47 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 09:11:50 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 09:11:50 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 09:11:50 - INFO - __main__ -     Batch size = 64\n","06/16/2021 09:16:50 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 09:16:50 - INFO - __main__ -     map = 0.6920192344607853\n","06/16/2021 09:19:23 - INFO - __main__ -   Iter = 1200\n","06/16/2021 09:19:23 - INFO - __main__ -   lr = 8.950276243093923e-06\n","06/16/2021 09:19:23 - INFO - __main__ -   loss = 0.3371755662560463\n","QC:evaluate and save_aps is False\n","06/16/2021 09:19:23 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 09:19:26 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 09:19:26 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 09:19:26 - INFO - __main__ -     Batch size = 64\n","06/16/2021 09:24:26 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 09:24:26 - INFO - __main__ -     map = 0.6999940278897545\n","06/16/2021 09:24:28 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/ms_v2_bert_4/checkpoint-best_run_cl__seed_42\n","06/16/2021 09:27:01 - INFO - __main__ -   Iter = 1300\n","06/16/2021 09:27:01 - INFO - __main__ -   lr = 8.029465930018416e-06\n","06/16/2021 09:27:01 - INFO - __main__ -   loss = 0.3235560588538647\n","QC:evaluate and save_aps is False\n","06/16/2021 09:27:01 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 09:27:04 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 09:27:04 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 09:27:04 - INFO - __main__ -     Batch size = 64\n","06/16/2021 09:32:05 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 09:32:05 - INFO - __main__ -     map = 0.6923257316901505\n","06/16/2021 09:34:37 - INFO - __main__ -   Iter = 1400\n","06/16/2021 09:34:37 - INFO - __main__ -   lr = 7.10865561694291e-06\n","06/16/2021 09:34:37 - INFO - __main__ -   loss = 0.3023115910589695\n","QC:evaluate and save_aps is False\n","06/16/2021 09:34:37 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 09:34:41 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 09:34:41 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 09:34:41 - INFO - __main__ -     Batch size = 64\n","06/16/2021 09:39:42 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 09:39:42 - INFO - __main__ -     map = 0.6874323338580266\n","06/16/2021 09:42:15 - INFO - __main__ -   Iter = 1500\n","06/16/2021 09:42:15 - INFO - __main__ -   lr = 6.187845303867403e-06\n","06/16/2021 09:42:15 - INFO - __main__ -   loss = 0.30700826838612555\n","QC:evaluate and save_aps is False\n","06/16/2021 09:42:15 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 09:42:18 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 09:42:18 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 09:42:18 - INFO - __main__ -     Batch size = 64\n","06/16/2021 09:47:19 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 09:47:19 - INFO - __main__ -     map = 0.6950467744205996\n","06/16/2021 09:49:51 - INFO - __main__ -   Iter = 1600\n","06/16/2021 09:49:51 - INFO - __main__ -   lr = 5.267034990791897e-06\n","06/16/2021 09:49:51 - INFO - __main__ -   loss = 0.2949140454828739\n","QC:evaluate and save_aps is False\n","06/16/2021 09:49:51 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 09:49:54 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 09:49:54 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 09:49:54 - INFO - __main__ -     Batch size = 64\n","06/16/2021 09:54:55 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 09:54:55 - INFO - __main__ -     map = 0.6907442955682689\n","06/16/2021 09:55:44 - INFO - __main__ -   Finished epoch with 543 iterations.\n","06/16/2021 09:55:44 - INFO - __main__ -   Starting epoch 4\n","06/16/2021 09:55:44 - INFO - __main__ -   Training with all_random_batches\n","06/16/2021 09:57:28 - INFO - __main__ -   Iter = 1700\n","06/16/2021 09:57:28 - INFO - __main__ -   lr = 4.3462246777163904e-06\n","06/16/2021 09:57:28 - INFO - __main__ -   loss = 0.2855217091739178\n","QC:evaluate and save_aps is False\n","06/16/2021 09:57:28 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 09:57:31 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 09:57:31 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 09:57:31 - INFO - __main__ -     Batch size = 64\n","06/16/2021 10:02:32 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 10:02:32 - INFO - __main__ -     map = 0.6968529111904559\n","06/16/2021 10:05:04 - INFO - __main__ -   Iter = 1800\n","06/16/2021 10:05:04 - INFO - __main__ -   lr = 3.4254143646408845e-06\n","06/16/2021 10:05:04 - INFO - __main__ -   loss = 0.2797198744118214\n","QC:evaluate and save_aps is False\n","06/16/2021 10:05:04 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 10:05:08 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 10:05:08 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 10:05:08 - INFO - __main__ -     Batch size = 64\n","06/16/2021 10:10:08 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 10:10:08 - INFO - __main__ -     map = 0.6910905713176625\n","06/16/2021 10:12:42 - INFO - __main__ -   Iter = 1900\n","06/16/2021 10:12:42 - INFO - __main__ -   lr = 2.504604051565378e-06\n","06/16/2021 10:12:42 - INFO - __main__ -   loss = 0.27051758632063866\n","QC:evaluate and save_aps is False\n","06/16/2021 10:12:42 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 10:12:45 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 10:12:45 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 10:12:45 - INFO - __main__ -     Batch size = 64\n","06/16/2021 10:17:46 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 10:17:46 - INFO - __main__ -     map = 0.6876800697883756\n","06/16/2021 10:20:18 - INFO - __main__ -   Iter = 2000\n","06/16/2021 10:20:18 - INFO - __main__ -   lr = 1.5837937384898713e-06\n","06/16/2021 10:20:18 - INFO - __main__ -   loss = 0.27126644864678384\n","QC:evaluate and save_aps is False\n","06/16/2021 10:20:18 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 10:20:22 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 10:20:22 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 10:20:22 - INFO - __main__ -     Batch size = 64\n","06/16/2021 10:25:23 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 10:25:23 - INFO - __main__ -     map = 0.6894524001484511\n","06/16/2021 10:27:55 - INFO - __main__ -   Iter = 2100\n","06/16/2021 10:27:55 - INFO - __main__ -   lr = 6.629834254143647e-07\n","06/16/2021 10:27:55 - INFO - __main__ -   loss = 0.27282482996582985\n","QC:evaluate and save_aps is False\n","06/16/2021 10:27:55 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_dev_bert-base-uncased_128_ms_v2\n","06/16/2021 10:27:58 - INFO - __main__ -   ***** Running evaluation  *****\n","06/16/2021 10:27:58 - INFO - __main__ -     Num examples = 37210\n","06/16/2021 10:27:58 - INFO - __main__ -     Batch size = 64\n","06/16/2021 10:32:59 - INFO - __main__ -   ***** Eval results  *****\n","06/16/2021 10:32:59 - INFO - __main__ -     map = 0.6888834500027743\n","06/16/2021 10:34:55 - INFO - __main__ -   Finished epoch with 543 iterations.\n","06/16/2021 10:34:55 - INFO - __main__ -    global_step = 2176, average loss = 0.3694459295502919\n","QC: checkpoint.split('-') ['drive/MyDrive/transformers_cl/ms_v2_bert_4/checkpoint', 'best_run_cl__seed_42']\n","QC: global_step: best_run_cl__seed_42 best_run_name best_run_cl__seed_42\n","QC: entered evaluation\n","QC:evaluate and save_aps is True\n","06/16/2021 10:34:58 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_train_bert-base-uncased_128_ms_v2\n","06/16/2021 10:35:01 - INFO - __main__ -   ***** Running evaluation best_run_cl__seed_42 *****\n","06/16/2021 10:35:01 - INFO - __main__ -     Num examples = 34736\n","06/16/2021 10:35:01 - INFO - __main__ -     Batch size = 2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X-pf-poaawH9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623841557314,"user_tz":-120,"elapsed":793317,"user":{"displayName":"Chen Qian","photoUrl":"","userId":"11245437508655380561"}},"outputId":"98194434-300e-4cfa-fbaa-161d61798f6e"},"source":["!python drive/MyDrive/transformers_cl/run_glue.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  ms_v2 \\\n","    --do_eval \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/MSDialog \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --output_dir drive/MyDrive/transformers_cl/ms_v2_bert_4/ \\\n","    --save_aps \\\n","    --eval_all_checkpoints \\\n","    --logging_steps 100 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["06/16/2021 10:52:49 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","06/16/2021 10:52:50 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpf8bp698j\n","100% 433/433 [00:00<00:00, 355129.77B/s]\n","06/16/2021 10:52:50 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpf8bp698j to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","06/16/2021 10:52:50 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","06/16/2021 10:52:50 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpf8bp698j\n","06/16/2021 10:52:50 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","06/16/2021 10:52:50 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"ms_v2\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","06/16/2021 10:52:51 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp1se47f_9\n","100% 231508/231508 [00:00<00:00, 710127.04B/s]\n","06/16/2021 10:52:51 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp1se47f_9 to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","06/16/2021 10:52:51 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","06/16/2021 10:52:51 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp1se47f_9\n","06/16/2021 10:52:51 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","06/16/2021 10:52:52 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpgcwuu3so\n","100% 440473133/440473133 [00:15<00:00, 28231388.68B/s]\n","06/16/2021 10:53:08 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpgcwuu3so to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","06/16/2021 10:53:09 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","06/16/2021 10:53:09 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpgcwuu3so\n","06/16/2021 10:53:09 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","06/16/2021 10:53:14 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","06/16/2021 10:53:14 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","06/16/2021 10:53:23 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='', data_dir='drive/MyDrive/MSDialog', debug_mode=False, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=False, eval_all_checkpoints=True, eval_difficult=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=False, learning_rate=2e-05, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=3.0, output_dir='drive/MyDrive/transformers_cl/ms_v2_bert_4/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__seed_42', save_aps=True, save_steps=5000, seed=42, server_ip='', server_port='', task_name='ms_v2', tokenizer_name='', use_additive_cl=False, warmup_steps=0, weight_decay=0.0)\n","QC: do_train is False do_eval is True save_aps is True\n","QC: local rank is -1 eval_during_training is True\n","QC: checkpoint.split('-') ['drive/MyDrive/transformers_cl/ms_v2_bert_4/checkpoint', 'best_run_cl__seed_42']\n","QC: global_step: best_run_cl__seed_42 best_run_name best_run_cl__seed_42\n","QC: entered evaluation\n","QC:evaluate and save_aps is True\n","06/16/2021 10:53:36 - INFO - __main__ -   Loading features from cached file drive/MyDrive/MSDialog/cached_train_bert-base-uncased_128_ms_v2\n","06/16/2021 10:53:42 - INFO - __main__ -   ***** Running evaluation best_run_cl__seed_42 *****\n","06/16/2021 10:53:42 - INFO - __main__ -     Num examples = 34736\n","06/16/2021 10:53:42 - INFO - __main__ -     Batch size = 2\n","drive/MyDrive/transformers_cl/ms_v2_bert_4/  and aps_ saved\n","drive/MyDrive/transformers_cl/ms_v2_bert_4/  and losses_ saved\n","drive/MyDrive/transformers_cl/ms_v2_bert_4/  and preds_ saved\n","06/16/2021 11:05:54 - INFO - __main__ -   ***** Eval results best_run_cl__seed_42 *****\n","06/16/2021 11:05:54 - INFO - __main__ -     map = 0.9766812528788577\n","QC results:  {} , save_aps is True , eval_all_checkpoints True\n"],"name":"stdout"}]}]}