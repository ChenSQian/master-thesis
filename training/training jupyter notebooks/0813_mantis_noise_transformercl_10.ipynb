{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"noise_transformercl_10.ipynb","provenance":[{"file_id":"1JPdZJDI3EfwNR9DB4D8nQEv-kDUdhyqc","timestamp":1623066561753},{"file_id":"1MR6fqyFJ0F0CvZ_prOyG8prQRr9h1zwL","timestamp":1621518416179}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"CgncrxE8FEY-"},"source":["function KeepClicking(){\n","console.log(\"Clicking\");\n","document.querySelector(\"colab-connect-button\").click()\n","}\n","setInterval(KeepClicking,60000)\n","Open your Chrome DevTools by pressing F12 or ctrl+shift+i on Linux and enter the following JavaScript snippet in your console:"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1QWVTurKCTMV","executionInfo":{"status":"ok","timestamp":1628933029635,"user_tz":-120,"elapsed":15780,"user":{"displayName":"xy GG","photoUrl":"","userId":"06169222138223251748"}},"outputId":"c957cf9d-9dfa-4eae-bdb5-db3d88d8ac2b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0q-7RWqYrMbI"},"source":["# install transformers\n","!pip install pytorch_transformers\n","# Mount google drive\n","!pip install -r drive/MyDrive/transformers_cl/requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gYNN5sk9-7z8"},"source":["# mantis root_5 with lamdba = 0.99, d_ratio = 1 noise"]},{"cell_type":"code","metadata":{"id":"dCjVt5gn-7z9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628760422360,"user_tz":-120,"elapsed":8245733,"user":{"displayName":"T. Z.","photoUrl":"","userId":"04670299702794629529"}},"outputId":"687b9c31-0f89-4c2e-d677-07ec8da7dfd9"},"source":["# mantison drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 1\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_99_r_1_seed_1 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.99\\\n","    --noise_difficult_ratio 1.0\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/12/2021 07:09:35 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/12/2021 07:09:35 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/12/2021 07:09:35 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/12/2021 07:09:36 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/12/2021 07:09:36 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/12/2021 07:09:39 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/12/2021 07:09:39 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/12/2021 07:09:42 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=1.0, noise_lambda=0.99, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root2_l_99_r_1_seed_1', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1', save_aps=False, save_steps=5000, seed=1, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/12/2021 07:09:42 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/12/2021 07:10:05 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/12/2021 07:10:07 - INFO - __main__ -   ***** Running training *****\n","08/12/2021 07:10:07 - INFO - __main__ -     Num examples = 164544\n","08/12/2021 07:10:07 - INFO - __main__ -     Num Epochs = 1\n","08/12/2021 07:10:07 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/12/2021 07:10:07 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/12/2021 07:10:07 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/12/2021 07:10:07 - INFO - __main__ -     Total optimization steps = 2571\n","08/12/2021 07:10:07 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/12/2021 07:10:07 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7fea45422ed0>)]\n","08/12/2021 07:10:07 - INFO - __main__ -   Starting epoch 1\n","08/12/2021 07:10:07 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/12/2021 07:18:06 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/12/2021 07:18:06 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/12/2021 07:18:06 - INFO - __main__ -   loss = 0.4241668961942196\n","08/12/2021 07:18:06 - INFO - __main__ -   Current data iter size: 1717\n","08/12/2021 07:18:06 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 07:18:28 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 07:18:28 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 07:18:28 - INFO - __main__ -     Batch size = 64\n","08/12/2021 07:26:25 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 07:26:25 - INFO - __main__ -     map = 0.733552296476938\n","08/12/2021 07:26:27 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root2_l_99_r_1_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 164544 length of sample 5390\n","08/12/2021 07:34:35 - INFO - __main__ -   Iter = 600\n","08/12/2021 07:34:35 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/12/2021 07:34:35 - INFO - __main__ -   loss = 0.33620896135767303\n","08/12/2021 07:34:35 - INFO - __main__ -   Current data iter size: 1967\n","08/12/2021 07:34:35 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 07:34:52 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 07:34:52 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 07:34:52 - INFO - __main__ -     Batch size = 64\n","08/12/2021 07:42:50 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 07:42:50 - INFO - __main__ -     map = 0.7550469874185378\n","08/12/2021 07:42:52 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root2_l_99_r_1_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 164544 length of sample 302\n","08/12/2021 07:51:03 - INFO - __main__ -   Iter = 900\n","08/12/2021 07:51:03 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/12/2021 07:51:03 - INFO - __main__ -   loss = 0.37140808055798213\n","08/12/2021 07:51:03 - INFO - __main__ -   Current data iter size: 2131\n","08/12/2021 07:51:03 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 07:51:20 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 07:51:20 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 07:51:20 - INFO - __main__ -     Batch size = 64\n","08/12/2021 07:59:18 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 07:59:18 - INFO - __main__ -     map = 0.7564589864732145\n","08/12/2021 07:59:20 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root2_l_99_r_1_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 164544 length of sample 16\n","08/12/2021 08:07:34 - INFO - __main__ -   Iter = 1200\n","08/12/2021 08:07:34 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/12/2021 08:07:34 - INFO - __main__ -   loss = 0.4000165324409803\n","08/12/2021 08:07:34 - INFO - __main__ -   Current data iter size: 2256\n","08/12/2021 08:07:34 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 08:07:51 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 08:07:51 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 08:07:51 - INFO - __main__ -     Batch size = 64\n","08/12/2021 08:15:49 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 08:15:49 - INFO - __main__ -     map = 0.7549810714958786\n","QC: length of D 164544 length of sample 0\n","08/12/2021 08:24:05 - INFO - __main__ -   Iter = 1500\n","08/12/2021 08:24:05 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/12/2021 08:24:05 - INFO - __main__ -   loss = 0.4088504361609618\n","08/12/2021 08:24:05 - INFO - __main__ -   Current data iter size: 2359\n","08/12/2021 08:24:05 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 08:24:22 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 08:24:22 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 08:24:22 - INFO - __main__ -     Batch size = 64\n","08/12/2021 08:32:19 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 08:32:19 - INFO - __main__ -     map = 0.7630784272335178\n","08/12/2021 08:32:21 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root2_l_99_r_1_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 164544 length of sample 0\n","08/12/2021 08:40:40 - INFO - __main__ -   Iter = 1800\n","08/12/2021 08:40:40 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/12/2021 08:40:40 - INFO - __main__ -   loss = 0.42482849150896074\n","08/12/2021 08:40:40 - INFO - __main__ -   Current data iter size: 2446\n","08/12/2021 08:40:40 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 08:40:57 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 08:40:57 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 08:40:57 - INFO - __main__ -     Batch size = 64\n","08/12/2021 08:48:54 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 08:48:54 - INFO - __main__ -     map = 0.7644922507191529\n","08/12/2021 08:48:56 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root2_l_99_r_1_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 164544 length of sample 0\n","08/12/2021 08:57:16 - INFO - __main__ -   Iter = 2100\n","08/12/2021 08:57:16 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/12/2021 08:57:16 - INFO - __main__ -   loss = 0.4359929253657659\n","08/12/2021 08:57:16 - INFO - __main__ -   Current data iter size: 2522\n","08/12/2021 08:57:16 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 08:57:33 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 08:57:33 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 08:57:33 - INFO - __main__ -     Batch size = 64\n","08/12/2021 09:05:30 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 09:05:30 - INFO - __main__ -     map = 0.7756389472145873\n","08/12/2021 09:05:32 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root2_l_99_r_1_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 164544 length of sample 0\n","08/12/2021 09:13:54 - INFO - __main__ -   Iter = 2400\n","08/12/2021 09:13:54 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/12/2021 09:13:54 - INFO - __main__ -   loss = 0.4624992480377356\n","08/12/2021 09:13:54 - INFO - __main__ -   Current data iter size: 2571\n","08/12/2021 09:13:54 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 09:14:12 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 09:14:12 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 09:14:12 - INFO - __main__ -     Batch size = 64\n","08/12/2021 09:22:10 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 09:22:10 - INFO - __main__ -     map = 0.7676774730619813\n","QC: length of D 164544 length of sample 0\n","08/12/2021 09:26:58 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/12/2021 09:26:58 - INFO - __main__ -    global_step = 2572, average loss = 0.41216399007321886\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T0488mjpJEvL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"24135b90-399e-492d-c35f-e23ccadb379b"},"source":["!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 2\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_99_r_1_seed_2 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.99\\\n","    --noise_difficult_ratio 1.0\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/14/2021 12:03:08 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/14/2021 12:03:09 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 12:03:09 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/14/2021 12:03:09 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 12:03:09 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 12:03:21 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/14/2021 12:03:21 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/14/2021 12:03:24 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=1.0, noise_lambda=0.99, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_99_r_1_seed_2', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2', save_aps=False, save_steps=5000, seed=2, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/14/2021 12:03:24 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/14/2021 12:03:44 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/14/2021 12:03:45 - INFO - __main__ -   ***** Running training *****\n","08/14/2021 12:03:45 - INFO - __main__ -     Num examples = 164544\n","08/14/2021 12:03:45 - INFO - __main__ -     Num Epochs = 1\n","08/14/2021 12:03:45 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/14/2021 12:03:45 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/14/2021 12:03:45 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/14/2021 12:03:45 - INFO - __main__ -     Total optimization steps = 2571\n","08/14/2021 12:03:45 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/14/2021 12:03:45 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7f70b06eff10>)]\n","08/14/2021 12:03:45 - INFO - __main__ -   Starting epoch 1\n","08/14/2021 12:03:45 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/14/2021 12:12:19 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/14/2021 12:12:19 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/14/2021 12:12:19 - INFO - __main__ -   loss = 0.43347452357411387\n","08/14/2021 12:12:19 - INFO - __main__ -   Current data iter size: 1717\n","08/14/2021 12:12:19 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 12:12:37 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 12:12:37 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 12:12:37 - INFO - __main__ -     Batch size = 64\n","08/14/2021 12:21:36 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 12:21:36 - INFO - __main__ -     map = 0.7263563830853357\n","08/14/2021 12:21:37 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_1_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 5390\n","08/14/2021 12:30:35 - INFO - __main__ -   Iter = 600\n","08/14/2021 12:30:35 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/14/2021 12:30:35 - INFO - __main__ -   loss = 0.3458835596839587\n","08/14/2021 12:30:35 - INFO - __main__ -   Current data iter size: 1967\n","08/14/2021 12:30:35 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 12:30:52 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 12:30:52 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 12:30:52 - INFO - __main__ -     Batch size = 64\n","08/14/2021 12:39:50 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 12:39:50 - INFO - __main__ -     map = 0.7399116035092654\n","08/14/2021 12:39:53 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_1_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 302\n","08/14/2021 12:48:54 - INFO - __main__ -   Iter = 900\n","08/14/2021 12:48:54 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/14/2021 12:48:54 - INFO - __main__ -   loss = 0.37327109182874363\n","08/14/2021 12:48:54 - INFO - __main__ -   Current data iter size: 2131\n","08/14/2021 12:48:54 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 12:49:13 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 12:49:13 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 12:49:13 - INFO - __main__ -     Batch size = 64\n","08/14/2021 12:58:12 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 12:58:12 - INFO - __main__ -     map = 0.7529715463577308\n","08/14/2021 12:58:13 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_1_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 16\n","08/14/2021 13:07:18 - INFO - __main__ -   Iter = 1200\n","08/14/2021 13:07:18 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/14/2021 13:07:18 - INFO - __main__ -   loss = 0.40030078242222467\n","08/14/2021 13:07:18 - INFO - __main__ -   Current data iter size: 2256\n","08/14/2021 13:07:18 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 13:07:35 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 13:07:35 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 13:07:35 - INFO - __main__ -     Batch size = 64\n","08/14/2021 13:16:34 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 13:16:34 - INFO - __main__ -     map = 0.7603145110064773\n","08/14/2021 13:16:35 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_1_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 0\n","08/14/2021 13:25:40 - INFO - __main__ -   Iter = 1500\n","08/14/2021 13:25:40 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/14/2021 13:25:40 - INFO - __main__ -   loss = 0.41673129573464396\n","08/14/2021 13:25:40 - INFO - __main__ -   Current data iter size: 2359\n","08/14/2021 13:25:40 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 13:25:56 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 13:25:56 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 13:25:56 - INFO - __main__ -     Batch size = 64\n","08/14/2021 13:34:54 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 13:34:54 - INFO - __main__ -     map = 0.7607838024918689\n","08/14/2021 13:34:56 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_1_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 0\n","08/14/2021 13:44:04 - INFO - __main__ -   Iter = 1800\n","08/14/2021 13:44:04 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/14/2021 13:44:04 - INFO - __main__ -   loss = 0.42221069008111956\n","08/14/2021 13:44:04 - INFO - __main__ -   Current data iter size: 2446\n","08/14/2021 13:44:04 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 13:44:21 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 13:44:21 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 13:44:21 - INFO - __main__ -     Batch size = 64\n","08/14/2021 13:53:18 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 13:53:18 - INFO - __main__ -     map = 0.7615039888821059\n","08/14/2021 13:53:20 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_1_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U_ityyQPJFB2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628944680840,"user_tz":-120,"elapsed":8302030,"user":{"displayName":"Chen Qian","photoUrl":"","userId":"11245437508655380561"}},"outputId":"5549f11b-b57f-4c5d-ba0b-1c0b27852eb0"},"source":["!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 3\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_99_r_1_seed_3 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.99\\\n","    --noise_difficult_ratio 1.0\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/14/2021 10:19:42 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/14/2021 10:19:43 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmp6mdin01g\n","100% 433/433 [00:00<00:00, 451325.46B/s]\n","08/14/2021 10:19:43 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp6mdin01g to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 10:19:43 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 10:19:43 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp6mdin01g\n","08/14/2021 10:19:43 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 10:19:43 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/14/2021 10:19:43 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmprtbudst8\n","100% 231508/231508 [00:00<00:00, 927258.53B/s]\n","08/14/2021 10:19:44 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmprtbudst8 to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 10:19:44 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 10:19:44 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmprtbudst8\n","08/14/2021 10:19:44 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 10:19:44 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpn2fhc6fg\n","100% 440473133/440473133 [00:10<00:00, 40824513.83B/s]\n","08/14/2021 10:19:55 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpn2fhc6fg to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 10:19:56 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 10:19:56 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpn2fhc6fg\n","08/14/2021 10:19:57 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 10:20:00 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/14/2021 10:20:00 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/14/2021 10:20:11 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=1.0, noise_lambda=0.99, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_99_r_1_seed_3', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3', save_aps=False, save_steps=5000, seed=3, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/14/2021 10:20:11 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/14/2021 10:20:33 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/14/2021 10:20:36 - INFO - __main__ -   ***** Running training *****\n","08/14/2021 10:20:36 - INFO - __main__ -     Num examples = 164544\n","08/14/2021 10:20:36 - INFO - __main__ -     Num Epochs = 1\n","08/14/2021 10:20:36 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/14/2021 10:20:36 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/14/2021 10:20:36 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/14/2021 10:20:36 - INFO - __main__ -     Total optimization steps = 2571\n","08/14/2021 10:20:36 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/14/2021 10:20:36 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7fb9b02d9750>)]\n","08/14/2021 10:20:36 - INFO - __main__ -   Starting epoch 1\n","08/14/2021 10:20:36 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/14/2021 10:28:27 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/14/2021 10:28:27 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/14/2021 10:28:27 - INFO - __main__ -   loss = 0.41422033260265984\n","08/14/2021 10:28:27 - INFO - __main__ -   Current data iter size: 1717\n","08/14/2021 10:28:27 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 10:28:49 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 10:28:49 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 10:28:49 - INFO - __main__ -     Batch size = 64\n","08/14/2021 10:36:51 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 10:36:51 - INFO - __main__ -     map = 0.7432515848325676\n","08/14/2021 10:36:52 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_1_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 164544 length of sample 5390\n","08/14/2021 10:45:03 - INFO - __main__ -   Iter = 600\n","08/14/2021 10:45:03 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/14/2021 10:45:03 - INFO - __main__ -   loss = 0.335591862599055\n","08/14/2021 10:45:03 - INFO - __main__ -   Current data iter size: 1967\n","08/14/2021 10:45:03 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 10:45:20 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 10:45:20 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 10:45:20 - INFO - __main__ -     Batch size = 64\n","08/14/2021 10:53:22 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 10:53:22 - INFO - __main__ -     map = 0.747433297098434\n","08/14/2021 10:53:24 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_1_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 164544 length of sample 302\n","08/14/2021 11:01:37 - INFO - __main__ -   Iter = 900\n","08/14/2021 11:01:37 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/14/2021 11:01:37 - INFO - __main__ -   loss = 0.3591903129716714\n","08/14/2021 11:01:37 - INFO - __main__ -   Current data iter size: 2131\n","08/14/2021 11:01:37 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 11:01:55 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 11:01:55 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 11:01:55 - INFO - __main__ -     Batch size = 64\n","08/14/2021 11:09:55 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 11:09:55 - INFO - __main__ -     map = 0.7563222135448572\n","08/14/2021 11:09:57 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_1_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 164544 length of sample 16\n","08/14/2021 11:18:14 - INFO - __main__ -   Iter = 1200\n","08/14/2021 11:18:14 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/14/2021 11:18:14 - INFO - __main__ -   loss = 0.3852546940247218\n","08/14/2021 11:18:14 - INFO - __main__ -   Current data iter size: 2256\n","08/14/2021 11:18:14 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 11:18:31 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 11:18:31 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 11:18:31 - INFO - __main__ -     Batch size = 64\n","08/14/2021 11:26:32 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 11:26:32 - INFO - __main__ -     map = 0.7515852547085009\n","QC: length of D 164544 length of sample 0\n","08/14/2021 11:34:49 - INFO - __main__ -   Iter = 1500\n","08/14/2021 11:34:49 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/14/2021 11:34:49 - INFO - __main__ -   loss = 0.41244602799415586\n","08/14/2021 11:34:49 - INFO - __main__ -   Current data iter size: 2359\n","08/14/2021 11:34:49 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 11:35:06 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 11:35:06 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 11:35:06 - INFO - __main__ -     Batch size = 64\n","08/14/2021 11:43:07 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 11:43:07 - INFO - __main__ -     map = 0.761937865607938\n","08/14/2021 11:43:09 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_1_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 164544 length of sample 0\n","08/14/2021 11:51:29 - INFO - __main__ -   Iter = 1800\n","08/14/2021 11:51:29 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/14/2021 11:51:29 - INFO - __main__ -   loss = 0.4255370868245761\n","08/14/2021 11:51:29 - INFO - __main__ -   Current data iter size: 2446\n","08/14/2021 11:51:29 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 11:51:47 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 11:51:47 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 11:51:47 - INFO - __main__ -     Batch size = 64\n","08/14/2021 11:59:49 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 11:59:49 - INFO - __main__ -     map = 0.7563844307239723\n","QC: length of D 164544 length of sample 0\n","08/14/2021 12:08:10 - INFO - __main__ -   Iter = 2100\n","08/14/2021 12:08:10 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/14/2021 12:08:10 - INFO - __main__ -   loss = 0.43823324580987294\n","08/14/2021 12:08:10 - INFO - __main__ -   Current data iter size: 2522\n","08/14/2021 12:08:10 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 12:08:27 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 12:08:27 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 12:08:27 - INFO - __main__ -     Batch size = 64\n","08/14/2021 12:16:29 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 12:16:29 - INFO - __main__ -     map = 0.7705192423740291\n","08/14/2021 12:16:30 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_1_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 164544 length of sample 0\n","08/14/2021 12:24:51 - INFO - __main__ -   Iter = 2400\n","08/14/2021 12:24:51 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/14/2021 12:24:51 - INFO - __main__ -   loss = 0.4530774975816409\n","08/14/2021 12:24:51 - INFO - __main__ -   Current data iter size: 2571\n","08/14/2021 12:24:51 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 12:25:09 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 12:25:09 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 12:25:09 - INFO - __main__ -     Batch size = 64\n","08/14/2021 12:33:10 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 12:33:10 - INFO - __main__ -     map = 0.7688591963548101\n","QC: length of D 164544 length of sample 0\n","08/14/2021 12:37:56 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/14/2021 12:37:57 - INFO - __main__ -    global_step = 2572, average loss = 0.4069453043512664\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CUdGHOJQI9Iw"},"source":["# mantis root_5 with lamdba = 0.995, d_ratio = 1 noise"]},{"cell_type":"code","metadata":{"id":"i9mO0-xkjNg7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628762233270,"user_tz":-120,"elapsed":8471595,"user":{"displayName":"","photoUrl":"","userId":"04762263270908229891"}},"outputId":"2a6272e3-5617-46f3-aded-f8f61d71d146"},"source":["# mantis root_5 \n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 1\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_995_r_1_seed_1 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.995\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/12/2021 07:36:05 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/12/2021 07:36:05 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmp36adh2c_\n","100% 433/433 [00:00<00:00, 421866.12B/s]\n","08/12/2021 07:36:06 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp36adh2c_ to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/12/2021 07:36:06 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/12/2021 07:36:06 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp36adh2c_\n","08/12/2021 07:36:06 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/12/2021 07:36:06 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/12/2021 07:36:06 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpwgfcp_mb\n","100% 231508/231508 [00:00<00:00, 868426.03B/s]\n","08/12/2021 07:36:06 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpwgfcp_mb to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/12/2021 07:36:06 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/12/2021 07:36:06 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpwgfcp_mb\n","08/12/2021 07:36:06 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/12/2021 07:36:07 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpg_cbs1x7\n","100% 440473133/440473133 [00:13<00:00, 33683385.60B/s]\n","08/12/2021 07:36:20 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpg_cbs1x7 to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/12/2021 07:36:21 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/12/2021 07:36:21 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpg_cbs1x7\n","08/12/2021 07:36:21 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/12/2021 07:36:24 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/12/2021 07:36:24 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/12/2021 07:36:36 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=1, noise_lambda=0.995, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_995_r_1_seed_1', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1', save_aps=False, save_steps=5000, seed=1, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/12/2021 07:36:36 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/12/2021 07:36:58 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/12/2021 07:37:01 - INFO - __main__ -   ***** Running training *****\n","08/12/2021 07:37:01 - INFO - __main__ -     Num examples = 164544\n","08/12/2021 07:37:01 - INFO - __main__ -     Num Epochs = 1\n","08/12/2021 07:37:01 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/12/2021 07:37:01 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/12/2021 07:37:01 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/12/2021 07:37:01 - INFO - __main__ -     Total optimization steps = 2571\n","08/12/2021 07:37:01 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/12/2021 07:37:01 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7faec1059d90>)]\n","08/12/2021 07:37:01 - INFO - __main__ -   Starting epoch 1\n","08/12/2021 07:37:01 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/12/2021 07:45:12 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/12/2021 07:45:12 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/12/2021 07:45:12 - INFO - __main__ -   loss = 0.479019021888574\n","08/12/2021 07:45:12 - INFO - __main__ -   Current data iter size: 1717\n","08/12/2021 07:45:12 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 07:45:30 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 07:45:30 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 07:45:30 - INFO - __main__ -     Batch size = 64\n","08/12/2021 07:53:43 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 07:53:43 - INFO - __main__ -     map = 0.7310222394276469\n","08/12/2021 07:53:45 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_1_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 164544 length of sample 24435\n","08/12/2021 08:02:03 - INFO - __main__ -   Iter = 600\n","08/12/2021 08:02:03 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/12/2021 08:02:03 - INFO - __main__ -   loss = 0.37837132344643276\n","08/12/2021 08:02:03 - INFO - __main__ -   Current data iter size: 1967\n","08/12/2021 08:02:03 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 08:02:19 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 08:02:19 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 08:02:19 - INFO - __main__ -     Batch size = 64\n","08/12/2021 08:10:30 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 08:10:30 - INFO - __main__ -     map = 0.7527879338536833\n","08/12/2021 08:10:32 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_1_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 164544 length of sample 6220\n","08/12/2021 08:18:53 - INFO - __main__ -   Iter = 900\n","08/12/2021 08:18:53 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/12/2021 08:18:53 - INFO - __main__ -   loss = 0.3716795293490092\n","08/12/2021 08:18:53 - INFO - __main__ -   Current data iter size: 2131\n","08/12/2021 08:18:53 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 08:19:10 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 08:19:10 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 08:19:10 - INFO - __main__ -     Batch size = 64\n","08/12/2021 08:27:22 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 08:27:22 - INFO - __main__ -     map = 0.7540973695951197\n","08/12/2021 08:27:24 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_1_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 164544 length of sample 1498\n","08/12/2021 08:35:48 - INFO - __main__ -   Iter = 1200\n","08/12/2021 08:35:48 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/12/2021 08:35:48 - INFO - __main__ -   loss = 0.40763819153110187\n","08/12/2021 08:35:48 - INFO - __main__ -   Current data iter size: 2256\n","08/12/2021 08:35:48 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 08:36:07 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 08:36:07 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 08:36:07 - INFO - __main__ -     Batch size = 64\n","08/12/2021 08:44:20 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 08:44:20 - INFO - __main__ -     map = 0.7670089464944496\n","08/12/2021 08:44:21 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_1_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 164544 length of sample 352\n","08/12/2021 08:52:48 - INFO - __main__ -   Iter = 1500\n","08/12/2021 08:52:48 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/12/2021 08:52:48 - INFO - __main__ -   loss = 0.4018538629015287\n","08/12/2021 08:52:48 - INFO - __main__ -   Current data iter size: 2359\n","08/12/2021 08:52:48 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 08:53:06 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 08:53:06 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 08:53:06 - INFO - __main__ -     Batch size = 64\n","08/12/2021 09:01:17 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 09:01:17 - INFO - __main__ -     map = 0.7642488615542322\n","QC: length of D 164544 length of sample 81\n","08/12/2021 09:09:45 - INFO - __main__ -   Iter = 1800\n","08/12/2021 09:09:45 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/12/2021 09:09:45 - INFO - __main__ -   loss = 0.4298815039296945\n","08/12/2021 09:09:45 - INFO - __main__ -   Current data iter size: 2446\n","08/12/2021 09:09:45 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 09:10:03 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 09:10:03 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 09:10:03 - INFO - __main__ -     Batch size = 64\n","08/12/2021 09:18:15 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 09:18:15 - INFO - __main__ -     map = 0.7600293338502386\n","QC: length of D 164544 length of sample 18\n","08/12/2021 09:26:44 - INFO - __main__ -   Iter = 2100\n","08/12/2021 09:26:44 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/12/2021 09:26:44 - INFO - __main__ -   loss = 0.43699101130167645\n","08/12/2021 09:26:44 - INFO - __main__ -   Current data iter size: 2522\n","08/12/2021 09:26:44 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 09:27:01 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 09:27:01 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 09:27:01 - INFO - __main__ -     Batch size = 64\n","08/12/2021 09:35:14 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 09:35:14 - INFO - __main__ -     map = 0.7653558600864319\n","QC: length of D 164544 length of sample 4\n","08/12/2021 09:43:44 - INFO - __main__ -   Iter = 2400\n","08/12/2021 09:43:44 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/12/2021 09:43:44 - INFO - __main__ -   loss = 0.4590825047095617\n","08/12/2021 09:43:44 - INFO - __main__ -   Current data iter size: 2571\n","08/12/2021 09:43:44 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 09:44:02 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 09:44:02 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 09:44:02 - INFO - __main__ -     Batch size = 64\n","08/12/2021 09:52:15 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 09:52:15 - INFO - __main__ -     map = 0.7646212195656067\n","QC: length of D 164544 length of sample 0\n","08/12/2021 09:57:09 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/12/2021 09:57:09 - INFO - __main__ -    global_step = 2572, average loss = 0.4233865350554371\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bPPm7l4vz_4E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628940986237,"user_tz":-120,"elapsed":7945771,"user":{"displayName":"xy GG","photoUrl":"","userId":"06169222138223251748"}},"outputId":"343aec90-e414-4d6b-cc94-4024063cf3f5"},"source":["# mantis root_5 \n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 2\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_995_r_1_seed_2 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.995\\\n","    --eval_subsize 60000 \\"],"execution_count":3,"outputs":[{"output_type":"stream","text":["08/14/2021 09:24:04 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/14/2021 09:24:04 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpgsjktob0\n","100% 433/433 [00:00<00:00, 430567.48B/s]\n","08/14/2021 09:24:05 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpgsjktob0 to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 09:24:05 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 09:24:05 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpgsjktob0\n","08/14/2021 09:24:05 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 09:24:05 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/14/2021 09:24:05 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpr1t0vfcl\n","100% 231508/231508 [00:00<00:00, 926647.95B/s]\n","08/14/2021 09:24:05 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpr1t0vfcl to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 09:24:05 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 09:24:05 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpr1t0vfcl\n","08/14/2021 09:24:05 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 09:24:06 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpxmio_clq\n","100% 440473133/440473133 [00:12<00:00, 35818830.61B/s]\n","08/14/2021 09:24:18 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpxmio_clq to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 09:24:20 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 09:24:20 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpxmio_clq\n","08/14/2021 09:24:20 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 09:24:23 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/14/2021 09:24:23 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/14/2021 09:24:35 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=1, noise_lambda=0.995, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_995_r_1_seed_2', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2', save_aps=False, save_steps=5000, seed=2, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/14/2021 09:24:35 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/14/2021 09:24:56 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/14/2021 09:24:58 - INFO - __main__ -   ***** Running training *****\n","08/14/2021 09:24:58 - INFO - __main__ -     Num examples = 164544\n","08/14/2021 09:24:58 - INFO - __main__ -     Num Epochs = 1\n","08/14/2021 09:24:58 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/14/2021 09:24:58 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/14/2021 09:24:58 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/14/2021 09:24:58 - INFO - __main__ -     Total optimization steps = 2571\n","08/14/2021 09:24:58 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/14/2021 09:24:58 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7f13cf160ed0>)]\n","08/14/2021 09:24:58 - INFO - __main__ -   Starting epoch 1\n","08/14/2021 09:24:58 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/14/2021 09:32:35 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/14/2021 09:32:35 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/14/2021 09:32:35 - INFO - __main__ -   loss = 0.4916514046986898\n","08/14/2021 09:32:35 - INFO - __main__ -   Current data iter size: 1717\n","08/14/2021 09:32:35 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 09:32:56 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 09:32:56 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 09:32:56 - INFO - __main__ -     Batch size = 64\n","08/14/2021 09:40:32 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 09:40:32 - INFO - __main__ -     map = 0.7262409775886086\n","08/14/2021 09:40:33 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_1_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 24435\n","08/14/2021 09:48:25 - INFO - __main__ -   Iter = 600\n","08/14/2021 09:48:25 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/14/2021 09:48:25 - INFO - __main__ -   loss = 0.3759086264669895\n","08/14/2021 09:48:25 - INFO - __main__ -   Current data iter size: 1967\n","08/14/2021 09:48:25 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 09:48:41 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 09:48:41 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 09:48:41 - INFO - __main__ -     Batch size = 64\n","08/14/2021 09:56:17 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 09:56:17 - INFO - __main__ -     map = 0.7406127471246076\n","08/14/2021 09:56:19 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_1_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 6220\n","08/14/2021 10:04:14 - INFO - __main__ -   Iter = 900\n","08/14/2021 10:04:14 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/14/2021 10:04:14 - INFO - __main__ -   loss = 0.3876801119248072\n","08/14/2021 10:04:14 - INFO - __main__ -   Current data iter size: 2131\n","08/14/2021 10:04:14 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 10:04:30 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 10:04:30 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 10:04:30 - INFO - __main__ -     Batch size = 64\n","08/14/2021 10:12:08 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 10:12:08 - INFO - __main__ -     map = 0.7500003195335705\n","08/14/2021 10:12:10 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_1_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 1498\n","08/14/2021 10:20:12 - INFO - __main__ -   Iter = 1200\n","08/14/2021 10:20:12 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/14/2021 10:20:12 - INFO - __main__ -   loss = 0.3984306012094021\n","08/14/2021 10:20:12 - INFO - __main__ -   Current data iter size: 2256\n","08/14/2021 10:20:12 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 10:20:30 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 10:20:30 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 10:20:30 - INFO - __main__ -     Batch size = 64\n","08/14/2021 10:28:06 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 10:28:06 - INFO - __main__ -     map = 0.747035406287837\n","QC: length of D 164544 length of sample 352\n","08/14/2021 10:36:04 - INFO - __main__ -   Iter = 1500\n","08/14/2021 10:36:04 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/14/2021 10:36:04 - INFO - __main__ -   loss = 0.41643822491168975\n","08/14/2021 10:36:04 - INFO - __main__ -   Current data iter size: 2359\n","08/14/2021 10:36:04 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 10:36:21 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 10:36:21 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 10:36:21 - INFO - __main__ -     Batch size = 64\n","08/14/2021 10:43:57 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 10:43:57 - INFO - __main__ -     map = 0.7591822929861953\n","08/14/2021 10:43:59 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_1_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 81\n","08/14/2021 10:51:59 - INFO - __main__ -   Iter = 1800\n","08/14/2021 10:51:59 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/14/2021 10:51:59 - INFO - __main__ -   loss = 0.42582406759262087\n","08/14/2021 10:51:59 - INFO - __main__ -   Current data iter size: 2446\n","08/14/2021 10:51:59 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 10:52:17 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 10:52:17 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 10:52:17 - INFO - __main__ -     Batch size = 64\n","08/14/2021 10:59:53 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 10:59:53 - INFO - __main__ -     map = 0.7633437783195145\n","08/14/2021 10:59:54 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_1_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 18\n","08/14/2021 11:07:55 - INFO - __main__ -   Iter = 2100\n","08/14/2021 11:07:55 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/14/2021 11:07:55 - INFO - __main__ -   loss = 0.4410225868225098\n","08/14/2021 11:07:55 - INFO - __main__ -   Current data iter size: 2522\n","08/14/2021 11:07:55 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 11:08:13 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 11:08:13 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 11:08:13 - INFO - __main__ -     Batch size = 64\n","08/14/2021 11:15:49 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 11:15:49 - INFO - __main__ -     map = 0.758827252869333\n","QC: length of D 164544 length of sample 4\n","08/14/2021 11:23:50 - INFO - __main__ -   Iter = 2400\n","08/14/2021 11:23:50 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/14/2021 11:23:50 - INFO - __main__ -   loss = 0.4561670244733493\n","08/14/2021 11:23:50 - INFO - __main__ -   Current data iter size: 2571\n","08/14/2021 11:23:50 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 11:24:07 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 11:24:07 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 11:24:07 - INFO - __main__ -     Batch size = 64\n","08/14/2021 11:31:44 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 11:31:44 - INFO - __main__ -     map = 0.7680804481407045\n","08/14/2021 11:31:45 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_1_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 0\n","08/14/2021 11:36:22 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/14/2021 11:36:22 - INFO - __main__ -    global_step = 2572, average loss = 0.42703184992955595\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Dotnsb3BJwiA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628948914913,"user_tz":-120,"elapsed":7914657,"user":{"displayName":"xy GG","photoUrl":"","userId":"06169222138223251748"}},"outputId":"33019b0b-2801-42bb-afd0-13a18afdc55c"},"source":["!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 3\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_995_r_1_seed_3 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.995\\\n","    --eval_subsize 60000 \\"],"execution_count":4,"outputs":[{"output_type":"stream","text":["08/14/2021 11:36:39 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/14/2021 11:36:40 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 11:36:40 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/14/2021 11:36:41 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 11:36:41 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 11:36:56 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/14/2021 11:36:56 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/14/2021 11:36:59 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=1, noise_lambda=0.995, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_995_r_1_seed_3', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3', save_aps=False, save_steps=5000, seed=3, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/14/2021 11:36:59 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/14/2021 11:37:19 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/14/2021 11:37:21 - INFO - __main__ -   ***** Running training *****\n","08/14/2021 11:37:21 - INFO - __main__ -     Num examples = 164544\n","08/14/2021 11:37:21 - INFO - __main__ -     Num Epochs = 1\n","08/14/2021 11:37:21 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/14/2021 11:37:21 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/14/2021 11:37:21 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/14/2021 11:37:21 - INFO - __main__ -     Total optimization steps = 2571\n","08/14/2021 11:37:21 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/14/2021 11:37:21 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7f243ceeefd0>)]\n","08/14/2021 11:37:21 - INFO - __main__ -   Starting epoch 1\n","08/14/2021 11:37:21 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/14/2021 11:45:03 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/14/2021 11:45:03 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/14/2021 11:45:03 - INFO - __main__ -   loss = 0.48088694617152217\n","08/14/2021 11:45:03 - INFO - __main__ -   Current data iter size: 1717\n","08/14/2021 11:45:03 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 11:45:21 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 11:45:21 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 11:45:21 - INFO - __main__ -     Batch size = 64\n","08/14/2021 11:52:57 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 11:52:57 - INFO - __main__ -     map = 0.7262271876507639\n","08/14/2021 11:52:59 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_1_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 164544 length of sample 24435\n","08/14/2021 12:00:50 - INFO - __main__ -   Iter = 600\n","08/14/2021 12:00:50 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/14/2021 12:00:50 - INFO - __main__ -   loss = 0.36454808885852497\n","08/14/2021 12:00:50 - INFO - __main__ -   Current data iter size: 1967\n","08/14/2021 12:00:50 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 12:01:07 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 12:01:07 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 12:01:07 - INFO - __main__ -     Batch size = 64\n","08/14/2021 12:08:43 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 12:08:43 - INFO - __main__ -     map = 0.7574389200772936\n","08/14/2021 12:08:45 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_1_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 164544 length of sample 6220\n","08/14/2021 12:16:39 - INFO - __main__ -   Iter = 900\n","08/14/2021 12:16:39 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/14/2021 12:16:39 - INFO - __main__ -   loss = 0.3733234900732835\n","08/14/2021 12:16:39 - INFO - __main__ -   Current data iter size: 2131\n","08/14/2021 12:16:39 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 12:16:57 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 12:16:57 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 12:16:57 - INFO - __main__ -     Batch size = 64\n","08/14/2021 12:24:33 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 12:24:33 - INFO - __main__ -     map = 0.7629166658645999\n","08/14/2021 12:24:35 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_1_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 164544 length of sample 1498\n","08/14/2021 12:32:30 - INFO - __main__ -   Iter = 1200\n","08/14/2021 12:32:30 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/14/2021 12:32:30 - INFO - __main__ -   loss = 0.3957023245096207\n","08/14/2021 12:32:30 - INFO - __main__ -   Current data iter size: 2256\n","08/14/2021 12:32:30 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 12:32:47 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 12:32:47 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 12:32:47 - INFO - __main__ -     Batch size = 64\n","08/14/2021 12:40:23 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 12:40:23 - INFO - __main__ -     map = 0.7538962653276045\n","QC: length of D 164544 length of sample 352\n","08/14/2021 12:48:20 - INFO - __main__ -   Iter = 1500\n","08/14/2021 12:48:20 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/14/2021 12:48:20 - INFO - __main__ -   loss = 0.4119874189794064\n","08/14/2021 12:48:20 - INFO - __main__ -   Current data iter size: 2359\n","08/14/2021 12:48:20 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 12:48:36 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 12:48:36 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 12:48:36 - INFO - __main__ -     Batch size = 64\n","08/14/2021 12:56:13 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 12:56:13 - INFO - __main__ -     map = 0.7610900829768518\n","QC: length of D 164544 length of sample 81\n","08/14/2021 13:04:11 - INFO - __main__ -   Iter = 1800\n","08/14/2021 13:04:11 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/14/2021 13:04:11 - INFO - __main__ -   loss = 0.4270570694406827\n","08/14/2021 13:04:11 - INFO - __main__ -   Current data iter size: 2446\n","08/14/2021 13:04:11 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 13:04:28 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 13:04:28 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 13:04:28 - INFO - __main__ -     Batch size = 64\n","08/14/2021 13:12:04 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 13:12:04 - INFO - __main__ -     map = 0.7683875004490552\n","08/14/2021 13:12:06 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_1_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 164544 length of sample 18\n","08/14/2021 13:20:05 - INFO - __main__ -   Iter = 2100\n","08/14/2021 13:20:05 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/14/2021 13:20:05 - INFO - __main__ -   loss = 0.43364245623350145\n","08/14/2021 13:20:05 - INFO - __main__ -   Current data iter size: 2522\n","08/14/2021 13:20:05 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 13:20:22 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 13:20:22 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 13:20:22 - INFO - __main__ -     Batch size = 64\n","08/14/2021 13:27:59 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 13:27:59 - INFO - __main__ -     map = 0.7592998029490357\n","QC: length of D 164544 length of sample 4\n","08/14/2021 13:35:59 - INFO - __main__ -   Iter = 2400\n","08/14/2021 13:35:59 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/14/2021 13:35:59 - INFO - __main__ -   loss = 0.45900319854418437\n","08/14/2021 13:35:59 - INFO - __main__ -   Current data iter size: 2571\n","08/14/2021 13:35:59 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 13:36:16 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 13:36:16 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 13:36:16 - INFO - __main__ -     Batch size = 64\n","08/14/2021 13:43:53 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 13:43:53 - INFO - __main__ -     map = 0.7718343417316099\n","08/14/2021 13:43:55 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_1_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 164544 length of sample 0\n","08/14/2021 13:48:31 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/14/2021 13:48:31 - INFO - __main__ -    global_step = 2572, average loss = 0.42144910571734606\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"q48JUnLsI9gv"},"source":["# mantis root_5 with lamdba = 0.999, d_ratio = 1 noise"]},{"cell_type":"code","metadata":{"id":"zsgh1dgdjQLm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628852452078,"user_tz":-120,"elapsed":8394997,"user":{"displayName":"Chen Qian","photoUrl":"","userId":"11245437508655380561"}},"outputId":"af790975-fc50-4395-80f1-f0d666a7c8cf"},"source":["# mantis root_5 \n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 1\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_999_r_1_seed_1 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.999\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/13/2021 08:40:58 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/13/2021 08:40:58 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmprry4jyn7\n","100% 433/433 [00:00<00:00, 438361.97B/s]\n","08/13/2021 08:40:58 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmprry4jyn7 to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 08:40:58 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 08:40:58 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmprry4jyn7\n","08/13/2021 08:40:58 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 08:40:58 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/13/2021 08:40:59 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmps7m5h0w9\n","100% 231508/231508 [00:00<00:00, 961798.97B/s]\n","08/13/2021 08:40:59 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmps7m5h0w9 to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 08:40:59 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 08:40:59 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmps7m5h0w9\n","08/13/2021 08:40:59 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 08:41:00 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmphbd34pcg\n","100% 440473133/440473133 [00:11<00:00, 38738535.61B/s]\n","08/13/2021 08:41:11 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmphbd34pcg to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 08:41:13 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 08:41:13 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmphbd34pcg\n","08/13/2021 08:41:13 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 08:41:16 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/13/2021 08:41:16 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/13/2021 08:41:27 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=1, noise_lambda=0.999, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_999_r_1_seed_1', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1', save_aps=False, save_steps=5000, seed=1, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/13/2021 08:41:27 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/13/2021 08:41:50 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/13/2021 08:41:52 - INFO - __main__ -   ***** Running training *****\n","08/13/2021 08:41:52 - INFO - __main__ -     Num examples = 164544\n","08/13/2021 08:41:52 - INFO - __main__ -     Num Epochs = 1\n","08/13/2021 08:41:52 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/13/2021 08:41:52 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/13/2021 08:41:52 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/13/2021 08:41:52 - INFO - __main__ -     Total optimization steps = 2571\n","08/13/2021 08:41:52 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/13/2021 08:41:52 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7f9bdb0ce910>)]\n","08/13/2021 08:41:52 - INFO - __main__ -   Starting epoch 1\n","08/13/2021 08:41:52 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/13/2021 08:50:00 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/13/2021 08:50:00 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/13/2021 08:50:00 - INFO - __main__ -   loss = 0.5421906643112501\n","08/13/2021 08:50:00 - INFO - __main__ -   Current data iter size: 1717\n","08/13/2021 08:50:00 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 08:50:21 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 08:50:21 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 08:50:21 - INFO - __main__ -     Batch size = 64\n","08/13/2021 08:58:29 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 08:58:29 - INFO - __main__ -     map = 0.7404540842729477\n","08/13/2021 08:58:31 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_1_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 164544 length of sample 81420\n","08/13/2021 09:06:47 - INFO - __main__ -   Iter = 600\n","08/13/2021 09:06:47 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/13/2021 09:06:47 - INFO - __main__ -   loss = 0.4727275929848353\n","08/13/2021 09:06:47 - INFO - __main__ -   Current data iter size: 1967\n","08/13/2021 09:06:47 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 09:07:04 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 09:07:04 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 09:07:04 - INFO - __main__ -     Batch size = 64\n","08/13/2021 09:15:10 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 09:15:10 - INFO - __main__ -     map = 0.7382493169100159\n","QC: length of D 164544 length of sample 69071\n","08/13/2021 09:23:30 - INFO - __main__ -   Iter = 900\n","08/13/2021 09:23:30 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/13/2021 09:23:30 - INFO - __main__ -   loss = 0.43915743559598924\n","08/13/2021 09:23:30 - INFO - __main__ -   Current data iter size: 2131\n","08/13/2021 09:23:30 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 09:23:46 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 09:23:46 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 09:23:46 - INFO - __main__ -     Batch size = 64\n","08/13/2021 09:31:53 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 09:31:53 - INFO - __main__ -     map = 0.7592788644704956\n","08/13/2021 09:31:55 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_1_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 164544 length of sample 55428\n","08/13/2021 09:40:18 - INFO - __main__ -   Iter = 1200\n","08/13/2021 09:40:18 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/13/2021 09:40:18 - INFO - __main__ -   loss = 0.4339472038547198\n","08/13/2021 09:40:18 - INFO - __main__ -   Current data iter size: 2256\n","08/13/2021 09:40:18 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 09:40:36 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 09:40:36 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 09:40:36 - INFO - __main__ -     Batch size = 64\n","08/13/2021 09:48:43 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 09:48:43 - INFO - __main__ -     map = 0.7551787257348103\n","QC: length of D 164544 length of sample 43466\n","08/13/2021 09:57:07 - INFO - __main__ -   Iter = 1500\n","08/13/2021 09:57:07 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/13/2021 09:57:07 - INFO - __main__ -   loss = 0.4380980075399081\n","08/13/2021 09:57:07 - INFO - __main__ -   Current data iter size: 2359\n","08/13/2021 09:57:07 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 09:57:25 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 09:57:25 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 09:57:25 - INFO - __main__ -     Batch size = 64\n","08/13/2021 10:05:31 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 10:05:31 - INFO - __main__ -     map = 0.7613649386865827\n","08/13/2021 10:05:33 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_1_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 164544 length of sample 33654\n","08/13/2021 10:13:58 - INFO - __main__ -   Iter = 1800\n","08/13/2021 10:13:58 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/13/2021 10:13:58 - INFO - __main__ -   loss = 0.43420986741781237\n","08/13/2021 10:13:58 - INFO - __main__ -   Current data iter size: 2446\n","08/13/2021 10:13:58 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 10:14:14 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 10:14:14 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 10:14:14 - INFO - __main__ -     Batch size = 64\n","08/13/2021 10:22:19 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 10:22:19 - INFO - __main__ -     map = 0.7662345869063023\n","08/13/2021 10:22:21 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_1_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 164544 length of sample 25848\n","08/13/2021 10:30:47 - INFO - __main__ -   Iter = 2100\n","08/13/2021 10:30:47 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/13/2021 10:30:47 - INFO - __main__ -   loss = 0.4509023209412893\n","08/13/2021 10:30:47 - INFO - __main__ -   Current data iter size: 2522\n","08/13/2021 10:30:47 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 10:31:03 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 10:31:03 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 10:31:03 - INFO - __main__ -     Batch size = 64\n","08/13/2021 10:39:07 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 10:39:07 - INFO - __main__ -     map = 0.7653996174147661\n","QC: length of D 164544 length of sample 19743\n","08/13/2021 10:47:35 - INFO - __main__ -   Iter = 2400\n","08/13/2021 10:47:35 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/13/2021 10:47:35 - INFO - __main__ -   loss = 0.45947173207998276\n","08/13/2021 10:47:35 - INFO - __main__ -   Current data iter size: 2571\n","08/13/2021 10:47:35 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 10:47:52 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 10:47:52 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 10:47:52 - INFO - __main__ -     Batch size = 64\n","08/13/2021 10:55:56 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 10:55:56 - INFO - __main__ -     map = 0.768280412238439\n","08/13/2021 10:55:58 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_1_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 164544 length of sample 14909\n","08/13/2021 11:00:49 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/13/2021 11:00:50 - INFO - __main__ -    global_step = 2572, average loss = 0.45929652987798303\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_CKvwGhoKIZv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628860851423,"user_tz":-120,"elapsed":8375579,"user":{"displayName":"Chen Qian","photoUrl":"","userId":"11245437508655380561"}},"outputId":"86d65ef7-8885-4ec3-92ce-c8e3308a5703"},"source":["# mantis root_5 \n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 2\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_999_r_1_seed_2 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.999\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/13/2021 11:01:16 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/13/2021 11:01:16 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 11:01:16 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/13/2021 11:01:17 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 11:01:17 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 11:01:27 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/13/2021 11:01:27 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/13/2021 11:01:30 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=1, noise_lambda=0.999, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_999_r_1_seed_2', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2', save_aps=False, save_steps=5000, seed=2, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/13/2021 11:01:30 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/13/2021 11:01:50 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/13/2021 11:01:52 - INFO - __main__ -   ***** Running training *****\n","08/13/2021 11:01:52 - INFO - __main__ -     Num examples = 164544\n","08/13/2021 11:01:52 - INFO - __main__ -     Num Epochs = 1\n","08/13/2021 11:01:52 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/13/2021 11:01:52 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/13/2021 11:01:52 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/13/2021 11:01:52 - INFO - __main__ -     Total optimization steps = 2571\n","08/13/2021 11:01:52 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/13/2021 11:01:52 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7fd023ab6e10>)]\n","08/13/2021 11:01:52 - INFO - __main__ -   Starting epoch 1\n","08/13/2021 11:01:52 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/13/2021 11:09:54 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/13/2021 11:09:54 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/13/2021 11:09:54 - INFO - __main__ -   loss = 0.5479898381233216\n","08/13/2021 11:09:54 - INFO - __main__ -   Current data iter size: 1717\n","08/13/2021 11:09:54 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 11:10:11 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 11:10:11 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 11:10:11 - INFO - __main__ -     Batch size = 64\n","08/13/2021 11:18:17 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 11:18:17 - INFO - __main__ -     map = 0.7399734555829071\n","08/13/2021 11:18:19 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_1_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 81420\n","08/13/2021 11:26:36 - INFO - __main__ -   Iter = 600\n","08/13/2021 11:26:36 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/13/2021 11:26:36 - INFO - __main__ -   loss = 0.470219734509786\n","08/13/2021 11:26:36 - INFO - __main__ -   Current data iter size: 1967\n","08/13/2021 11:26:36 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 11:26:53 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 11:26:53 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 11:26:53 - INFO - __main__ -     Batch size = 64\n","08/13/2021 11:35:01 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 11:35:01 - INFO - __main__ -     map = 0.7447828134240566\n","08/13/2021 11:35:03 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_1_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 69071\n","08/13/2021 11:43:23 - INFO - __main__ -   Iter = 900\n","08/13/2021 11:43:23 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/13/2021 11:43:23 - INFO - __main__ -   loss = 0.45086863309144976\n","08/13/2021 11:43:23 - INFO - __main__ -   Current data iter size: 2131\n","08/13/2021 11:43:23 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 11:43:40 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 11:43:40 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 11:43:40 - INFO - __main__ -     Batch size = 64\n","08/13/2021 11:51:45 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 11:51:45 - INFO - __main__ -     map = 0.7435955238425551\n","QC: length of D 164544 length of sample 55428\n","08/13/2021 12:00:07 - INFO - __main__ -   Iter = 1200\n","08/13/2021 12:00:07 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/13/2021 12:00:07 - INFO - __main__ -   loss = 0.43912912865479786\n","08/13/2021 12:00:07 - INFO - __main__ -   Current data iter size: 2256\n","08/13/2021 12:00:07 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 12:00:25 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 12:00:25 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 12:00:25 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:08:29 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:08:29 - INFO - __main__ -     map = 0.7471168116188966\n","08/13/2021 12:08:31 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_1_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 43466\n","08/13/2021 12:16:57 - INFO - __main__ -   Iter = 1500\n","08/13/2021 12:16:57 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/13/2021 12:16:57 - INFO - __main__ -   loss = 0.43721867819627125\n","08/13/2021 12:16:57 - INFO - __main__ -   Current data iter size: 2359\n","08/13/2021 12:16:57 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 12:17:14 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 12:17:14 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 12:17:14 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:25:19 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:25:19 - INFO - __main__ -     map = 0.7563536003452607\n","08/13/2021 12:25:22 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_1_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 33654\n","08/13/2021 12:33:48 - INFO - __main__ -   Iter = 1800\n","08/13/2021 12:33:48 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/13/2021 12:33:48 - INFO - __main__ -   loss = 0.44385736882686616\n","08/13/2021 12:33:48 - INFO - __main__ -   Current data iter size: 2446\n","08/13/2021 12:33:48 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 12:34:05 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 12:34:05 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 12:34:05 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:42:11 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:42:11 - INFO - __main__ -     map = 0.7686780138000814\n","08/13/2021 12:42:13 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_1_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 25848\n","08/13/2021 12:50:41 - INFO - __main__ -   Iter = 2100\n","08/13/2021 12:50:41 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/13/2021 12:50:41 - INFO - __main__ -   loss = 0.4512918453415235\n","08/13/2021 12:50:41 - INFO - __main__ -   Current data iter size: 2522\n","08/13/2021 12:50:41 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 12:50:58 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 12:50:58 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 12:50:58 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:59:04 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:59:04 - INFO - __main__ -     map = 0.7616858810474478\n","QC: length of D 164544 length of sample 19743\n","08/13/2021 13:07:33 - INFO - __main__ -   Iter = 2400\n","08/13/2021 13:07:33 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/13/2021 13:07:33 - INFO - __main__ -   loss = 0.4651126365860303\n","08/13/2021 13:07:33 - INFO - __main__ -   Current data iter size: 2571\n","08/13/2021 13:07:33 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 13:07:49 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 13:07:49 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 13:07:49 - INFO - __main__ -     Batch size = 64\n","08/13/2021 13:15:56 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 13:15:56 - INFO - __main__ -     map = 0.7609871787574759\n","QC: length of D 164544 length of sample 14909\n","08/13/2021 13:20:49 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/13/2021 13:20:49 - INFO - __main__ -    global_step = 2572, average loss = 0.4633268638750072\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WeTj5R5rusn8","executionInfo":{"status":"ok","timestamp":1628942335217,"user_tz":-120,"elapsed":9166712,"user":{"displayName":"","photoUrl":"","userId":"04762263270908229891"}},"outputId":"b389f427-7dbe-4a32-ab2f-a4be3d002429"},"source":["# mantis root_5 \n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 3\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_999_r_1_seed_3 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.999\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/14/2021 09:26:12 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/14/2021 09:26:12 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpp0ydydve\n","100% 433/433 [00:00<00:00, 468437.87B/s]\n","08/14/2021 09:26:12 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpp0ydydve to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 09:26:12 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 09:26:12 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpp0ydydve\n","08/14/2021 09:26:12 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 09:26:12 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/14/2021 09:26:13 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpfh1cq5y_\n","100% 231508/231508 [00:00<00:00, 942398.07B/s]\n","08/14/2021 09:26:13 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpfh1cq5y_ to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 09:26:13 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 09:26:13 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpfh1cq5y_\n","08/14/2021 09:26:13 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 09:26:14 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpfbdqva8h\n","100% 440473133/440473133 [00:11<00:00, 39589369.37B/s]\n","08/14/2021 09:26:25 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpfbdqva8h to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 09:26:26 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 09:26:26 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpfbdqva8h\n","08/14/2021 09:26:26 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 09:26:29 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/14/2021 09:26:29 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/14/2021 09:26:41 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=1, noise_lambda=0.999, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_999_r_1_seed_3', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3', save_aps=False, save_steps=5000, seed=3, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/14/2021 09:26:41 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/14/2021 09:27:03 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/14/2021 09:27:06 - INFO - __main__ -   ***** Running training *****\n","08/14/2021 09:27:06 - INFO - __main__ -     Num examples = 164544\n","08/14/2021 09:27:06 - INFO - __main__ -     Num Epochs = 1\n","08/14/2021 09:27:06 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/14/2021 09:27:06 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/14/2021 09:27:06 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/14/2021 09:27:06 - INFO - __main__ -     Total optimization steps = 2571\n","08/14/2021 09:27:06 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/14/2021 09:27:06 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7f29cc75c850>)]\n","08/14/2021 09:27:06 - INFO - __main__ -   Starting epoch 1\n","08/14/2021 09:27:06 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/14/2021 09:35:40 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/14/2021 09:35:40 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/14/2021 09:35:40 - INFO - __main__ -   loss = 0.5437064236402511\n","08/14/2021 09:35:40 - INFO - __main__ -   Current data iter size: 1717\n","08/14/2021 09:35:40 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 09:36:00 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 09:36:00 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 09:36:00 - INFO - __main__ -     Batch size = 64\n","08/14/2021 09:44:56 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 09:44:56 - INFO - __main__ -     map = 0.7324124747120337\n","08/14/2021 09:44:58 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_1_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 164544 length of sample 81420\n","08/14/2021 09:53:56 - INFO - __main__ -   Iter = 600\n","08/14/2021 09:53:56 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/14/2021 09:53:56 - INFO - __main__ -   loss = 0.46468562026818594\n","08/14/2021 09:53:56 - INFO - __main__ -   Current data iter size: 1967\n","08/14/2021 09:53:56 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 09:54:13 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 09:54:13 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 09:54:13 - INFO - __main__ -     Batch size = 64\n","08/14/2021 10:03:12 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 10:03:12 - INFO - __main__ -     map = 0.743240521602514\n","08/14/2021 10:03:13 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_1_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 164544 length of sample 69071\n","08/14/2021 10:12:15 - INFO - __main__ -   Iter = 900\n","08/14/2021 10:12:15 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/14/2021 10:12:15 - INFO - __main__ -   loss = 0.4387158011396726\n","08/14/2021 10:12:15 - INFO - __main__ -   Current data iter size: 2131\n","08/14/2021 10:12:15 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 10:12:31 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 10:12:31 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 10:12:31 - INFO - __main__ -     Batch size = 64\n","08/14/2021 10:21:29 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 10:21:29 - INFO - __main__ -     map = 0.7609993305402601\n","08/14/2021 10:21:32 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_1_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 164544 length of sample 55428\n","08/14/2021 10:30:36 - INFO - __main__ -   Iter = 1200\n","08/14/2021 10:30:36 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/14/2021 10:30:36 - INFO - __main__ -   loss = 0.43577880680561065\n","08/14/2021 10:30:36 - INFO - __main__ -   Current data iter size: 2256\n","08/14/2021 10:30:36 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 10:30:54 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 10:30:54 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 10:30:54 - INFO - __main__ -     Batch size = 64\n","08/14/2021 10:39:51 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 10:39:51 - INFO - __main__ -     map = 0.7703867962911897\n","08/14/2021 10:39:53 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_1_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 164544 length of sample 43466\n","08/14/2021 10:49:01 - INFO - __main__ -   Iter = 1500\n","08/14/2021 10:49:01 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/14/2021 10:49:01 - INFO - __main__ -   loss = 0.43177472790082294\n","08/14/2021 10:49:01 - INFO - __main__ -   Current data iter size: 2359\n","08/14/2021 10:49:01 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 10:49:18 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 10:49:18 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 10:49:18 - INFO - __main__ -     Batch size = 64\n","08/14/2021 10:58:15 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 10:58:15 - INFO - __main__ -     map = 0.7631487995808738\n","QC: length of D 164544 length of sample 33654\n","08/14/2021 11:07:25 - INFO - __main__ -   Iter = 1800\n","08/14/2021 11:07:25 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/14/2021 11:07:25 - INFO - __main__ -   loss = 0.43408010855317114\n","08/14/2021 11:07:25 - INFO - __main__ -   Current data iter size: 2446\n","08/14/2021 11:07:25 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 11:07:42 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 11:07:42 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 11:07:42 - INFO - __main__ -     Batch size = 64\n","08/14/2021 11:16:41 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 11:16:41 - INFO - __main__ -     map = 0.7683984509264953\n","QC: length of D 164544 length of sample 25848\n","08/14/2021 11:25:52 - INFO - __main__ -   Iter = 2100\n","08/14/2021 11:25:52 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/14/2021 11:25:52 - INFO - __main__ -   loss = 0.44766472319761913\n","08/14/2021 11:25:52 - INFO - __main__ -   Current data iter size: 2522\n","08/14/2021 11:25:52 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 11:26:09 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 11:26:09 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 11:26:09 - INFO - __main__ -     Batch size = 64\n","08/14/2021 11:35:08 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 11:35:08 - INFO - __main__ -     map = 0.7633556546264122\n","QC: length of D 164544 length of sample 19743\n","08/14/2021 11:44:19 - INFO - __main__ -   Iter = 2400\n","08/14/2021 11:44:19 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/14/2021 11:44:19 - INFO - __main__ -   loss = 0.4548664111892382\n","08/14/2021 11:44:19 - INFO - __main__ -   Current data iter size: 2571\n","08/14/2021 11:44:19 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 11:44:36 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 11:44:36 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 11:44:36 - INFO - __main__ -     Batch size = 64\n","08/14/2021 11:53:34 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 11:53:34 - INFO - __main__ -     map = 0.7696522202214254\n","QC: length of D 164544 length of sample 14909\n","08/14/2021 11:58:51 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/14/2021 11:58:51 - INFO - __main__ -    global_step = 2572, average loss = 0.45641120280462144\n"],"name":"stdout"}]}]}