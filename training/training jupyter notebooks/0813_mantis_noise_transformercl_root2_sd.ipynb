{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"noise_transformercl_root2_sd.ipynb","provenance":[{"file_id":"1Nm--rp5z2fpROturVqZ4tK_rE35BAUOm","timestamp":1627717302987},{"file_id":"1JPdZJDI3EfwNR9DB4D8nQEv-kDUdhyqc","timestamp":1623066561753},{"file_id":"1MR6fqyFJ0F0CvZ_prOyG8prQRr9h1zwL","timestamp":1621518416179}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"CgncrxE8FEY-"},"source":["function KeepClicking(){\n","console.log(\"Clicking\");\n","document.querySelector(\"colab-connect-button\").click()\n","}\n","setInterval(KeepClicking,60000)\n","Open your Chrome DevTools by pressing F12 or ctrl+shift+i on Linux and enter the following JavaScript snippet in your console:"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1QWVTurKCTMV","executionInfo":{"status":"ok","timestamp":1629026711421,"user_tz":-120,"elapsed":58737,"user":{"displayName":"Chen Qian","photoUrl":"","userId":"11245437508655380561"}},"outputId":"c592e1a6-fec8-46a3-8323-99c1de113570"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0q-7RWqYrMbI"},"source":["# install transformers\n","!pip install pytorch_transformers\n","# Mount google drive\n","!pip install -r drive/MyDrive/transformers_cl/requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BgZLOuHJJ0mp"},"source":["# Mantis root_5"]},{"cell_type":"code","metadata":{"id":"vAU8_SEBFLB6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628757921819,"user_tz":-120,"elapsed":8261032,"user":{"displayName":"xy GG","photoUrl":"","userId":"06169222138223251748"}},"outputId":"bd5d301e-26df-48a1-e85d-ca588ca3cfa7"},"source":["# seed 1 60000\n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 1\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_10_root5_seed_1 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --eval_subsize 60000\\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/12/2021 06:27:44 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/12/2021 06:27:45 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpr0o_2ouu\n","100% 433/433 [00:00<00:00, 353608.57B/s]\n","08/12/2021 06:27:45 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpr0o_2ouu to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/12/2021 06:27:45 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/12/2021 06:27:45 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpr0o_2ouu\n","08/12/2021 06:27:45 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/12/2021 06:27:45 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/12/2021 06:27:45 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmprymh31qb\n","100% 231508/231508 [00:00<00:00, 856547.62B/s]\n","08/12/2021 06:27:46 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmprymh31qb to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/12/2021 06:27:46 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/12/2021 06:27:46 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmprymh31qb\n","08/12/2021 06:27:46 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/12/2021 06:27:46 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpddui6f8m\n","100% 440473133/440473133 [00:12<00:00, 36086064.64B/s]\n","08/12/2021 06:27:59 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpddui6f8m to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/12/2021 06:28:00 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/12/2021 06:28:00 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpddui6f8m\n","08/12/2021 06:28:00 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/12/2021 06:28:03 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/12/2021 06:28:03 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/12/2021 06:28:15 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=1, noise_lambda=0.0, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_10_root5_seed_1', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1', save_aps=False, save_steps=5000, seed=1, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/12/2021 06:28:15 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/12/2021 06:28:36 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/12/2021 06:28:39 - INFO - __main__ -   ***** Running training *****\n","08/12/2021 06:28:39 - INFO - __main__ -     Num examples = 164544\n","08/12/2021 06:28:39 - INFO - __main__ -     Num Epochs = 1\n","08/12/2021 06:28:39 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/12/2021 06:28:39 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/12/2021 06:28:39 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/12/2021 06:28:39 - INFO - __main__ -     Total optimization steps = 2571\n","08/12/2021 06:28:39 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/12/2021 06:28:39 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7f1f7b66c850>)]\n","08/12/2021 06:28:39 - INFO - __main__ -   Starting epoch 1\n","08/12/2021 06:28:39 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/12/2021 06:36:38 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/12/2021 06:36:38 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/12/2021 06:36:38 - INFO - __main__ -   loss = 0.31903996030489606\n","08/12/2021 06:36:38 - INFO - __main__ -   Current data iter size: 1717\n","08/12/2021 06:36:38 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 06:36:58 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 06:36:58 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 06:36:58 - INFO - __main__ -     Batch size = 64\n","08/12/2021 06:44:54 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 06:44:54 - INFO - __main__ -     map = 0.7418676576626516\n","08/12/2021 06:44:56 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_root5_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 164544 length of sample 0\n","08/12/2021 06:53:04 - INFO - __main__ -   Iter = 600\n","08/12/2021 06:53:04 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/12/2021 06:53:04 - INFO - __main__ -   loss = 0.31723953180015085\n","08/12/2021 06:53:04 - INFO - __main__ -   Current data iter size: 1967\n","08/12/2021 06:53:04 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 06:53:21 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 06:53:21 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 06:53:21 - INFO - __main__ -     Batch size = 64\n","08/12/2021 07:01:18 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 07:01:18 - INFO - __main__ -     map = 0.7557163753954934\n","08/12/2021 07:01:20 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_root5_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 164544 length of sample 0\n","08/12/2021 07:09:32 - INFO - __main__ -   Iter = 900\n","08/12/2021 07:09:32 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/12/2021 07:09:32 - INFO - __main__ -   loss = 0.35962164029479027\n","08/12/2021 07:09:32 - INFO - __main__ -   Current data iter size: 2131\n","08/12/2021 07:09:32 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 07:09:50 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 07:09:50 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 07:09:50 - INFO - __main__ -     Batch size = 64\n","08/12/2021 07:17:46 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 07:17:46 - INFO - __main__ -     map = 0.7621151100004105\n","08/12/2021 07:17:48 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_root5_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 164544 length of sample 0\n","08/12/2021 07:26:02 - INFO - __main__ -   Iter = 1200\n","08/12/2021 07:26:02 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/12/2021 07:26:02 - INFO - __main__ -   loss = 0.38598147496581076\n","08/12/2021 07:26:02 - INFO - __main__ -   Current data iter size: 2256\n","08/12/2021 07:26:02 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 07:26:19 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 07:26:19 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 07:26:19 - INFO - __main__ -     Batch size = 64\n","08/12/2021 07:34:15 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 07:34:15 - INFO - __main__ -     map = 0.7596307021945441\n","QC: length of D 164544 length of sample 0\n","08/12/2021 07:42:30 - INFO - __main__ -   Iter = 1500\n","08/12/2021 07:42:30 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/12/2021 07:42:30 - INFO - __main__ -   loss = 0.4067253031333288\n","08/12/2021 07:42:30 - INFO - __main__ -   Current data iter size: 2359\n","08/12/2021 07:42:30 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 07:42:48 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 07:42:48 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 07:42:48 - INFO - __main__ -     Batch size = 64\n","08/12/2021 07:50:46 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 07:50:46 - INFO - __main__ -     map = 0.7649847892272473\n","08/12/2021 07:50:48 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_root5_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 164544 length of sample 0\n","08/12/2021 07:59:05 - INFO - __main__ -   Iter = 1800\n","08/12/2021 07:59:05 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/12/2021 07:59:05 - INFO - __main__ -   loss = 0.4237379504243533\n","08/12/2021 07:59:05 - INFO - __main__ -   Current data iter size: 2446\n","08/12/2021 07:59:05 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 07:59:22 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 07:59:22 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 07:59:22 - INFO - __main__ -     Batch size = 64\n","08/12/2021 08:07:18 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 08:07:18 - INFO - __main__ -     map = 0.7608334568098202\n","QC: length of D 164544 length of sample 0\n","08/12/2021 08:15:39 - INFO - __main__ -   Iter = 2100\n","08/12/2021 08:15:39 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/12/2021 08:15:39 - INFO - __main__ -   loss = 0.4405267188946406\n","08/12/2021 08:15:39 - INFO - __main__ -   Current data iter size: 2522\n","08/12/2021 08:15:39 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 08:15:57 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 08:15:57 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 08:15:57 - INFO - __main__ -     Batch size = 64\n","08/12/2021 08:23:54 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 08:23:54 - INFO - __main__ -     map = 0.7766555901301576\n","08/12/2021 08:23:56 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_root5_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 164544 length of sample 0\n","08/12/2021 08:32:16 - INFO - __main__ -   Iter = 2400\n","08/12/2021 08:32:16 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/12/2021 08:32:16 - INFO - __main__ -   loss = 0.4667538559436798\n","08/12/2021 08:32:16 - INFO - __main__ -   Current data iter size: 2571\n","08/12/2021 08:32:16 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 08:32:34 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 08:32:34 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 08:32:34 - INFO - __main__ -     Batch size = 64\n","08/12/2021 08:40:30 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 08:40:30 - INFO - __main__ -     map = 0.7723995191941498\n","QC: length of D 164544 length of sample 0\n","08/12/2021 08:45:17 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/12/2021 08:45:18 - INFO - __main__ -    global_step = 2572, average loss = 0.3957994024690768\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CcHRe7nxl4V_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629025875902,"user_tz":-120,"elapsed":8069004,"user":{"displayName":"xiaokang qian","photoUrl":"","userId":"16136989389156139825"}},"outputId":"a955279b-f894-43d3-a12c-c09c03072dee"},"source":["# seed 1 60000\n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 2\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_10_root5_seed_2 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --eval_subsize 60000\\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/15/2021 08:56:53 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/15/2021 08:56:53 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpfnfys4x3\n","100% 433/433 [00:00<00:00, 523230.66B/s]\n","08/15/2021 08:56:53 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpfnfys4x3 to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/15/2021 08:56:53 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/15/2021 08:56:53 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpfnfys4x3\n","08/15/2021 08:56:53 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/15/2021 08:56:53 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/15/2021 08:56:54 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp3jpa0pfj\n","100% 231508/231508 [00:00<00:00, 957305.36B/s]\n","08/15/2021 08:56:54 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp3jpa0pfj to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/15/2021 08:56:54 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/15/2021 08:56:54 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp3jpa0pfj\n","08/15/2021 08:56:54 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/15/2021 08:56:54 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpyv2q3uvn\n","100% 440473133/440473133 [00:12<00:00, 35062072.82B/s]\n","08/15/2021 08:57:07 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpyv2q3uvn to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/15/2021 08:57:08 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/15/2021 08:57:08 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpyv2q3uvn\n","08/15/2021 08:57:09 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/15/2021 08:57:12 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/15/2021 08:57:12 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/15/2021 08:57:24 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=1, noise_lambda=0.0, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_10_root5_seed_2', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2', save_aps=False, save_steps=5000, seed=2, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/15/2021 08:57:24 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/15/2021 08:57:47 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/15/2021 08:57:50 - INFO - __main__ -   ***** Running training *****\n","08/15/2021 08:57:50 - INFO - __main__ -     Num examples = 164544\n","08/15/2021 08:57:50 - INFO - __main__ -     Num Epochs = 1\n","08/15/2021 08:57:50 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/15/2021 08:57:50 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/15/2021 08:57:50 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/15/2021 08:57:50 - INFO - __main__ -     Total optimization steps = 2571\n","08/15/2021 08:57:50 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/15/2021 08:57:50 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7f3ed0567890>)]\n","08/15/2021 08:57:50 - INFO - __main__ -   Starting epoch 1\n","08/15/2021 08:57:50 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/15/2021 09:05:31 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/15/2021 09:05:31 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/15/2021 09:05:31 - INFO - __main__ -   loss = 0.34882652302583056\n","08/15/2021 09:05:31 - INFO - __main__ -   Current data iter size: 1717\n","08/15/2021 09:05:31 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 09:05:52 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 09:05:52 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 09:05:52 - INFO - __main__ -     Batch size = 64\n","08/15/2021 09:13:36 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 09:13:36 - INFO - __main__ -     map = 0.7226161619661404\n","08/15/2021 09:13:38 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_root5_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 0\n","08/15/2021 09:21:38 - INFO - __main__ -   Iter = 600\n","08/15/2021 09:21:38 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/15/2021 09:21:38 - INFO - __main__ -   loss = 0.3348173097272714\n","08/15/2021 09:21:38 - INFO - __main__ -   Current data iter size: 1967\n","08/15/2021 09:21:38 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 09:21:55 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 09:21:55 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 09:21:55 - INFO - __main__ -     Batch size = 64\n","08/15/2021 09:29:39 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 09:29:39 - INFO - __main__ -     map = 0.7439232164524773\n","08/15/2021 09:29:40 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_root5_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 0\n","08/15/2021 09:37:42 - INFO - __main__ -   Iter = 900\n","08/15/2021 09:37:42 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/15/2021 09:37:42 - INFO - __main__ -   loss = 0.37835227156678836\n","08/15/2021 09:37:42 - INFO - __main__ -   Current data iter size: 2131\n","08/15/2021 09:37:42 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 09:38:00 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 09:38:00 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 09:38:00 - INFO - __main__ -     Batch size = 64\n","08/15/2021 09:45:45 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 09:45:45 - INFO - __main__ -     map = 0.7459298431883985\n","08/15/2021 09:45:46 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_root5_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 0\n","08/15/2021 09:53:51 - INFO - __main__ -   Iter = 1200\n","08/15/2021 09:53:51 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/15/2021 09:53:51 - INFO - __main__ -   loss = 0.40000854710737865\n","08/15/2021 09:53:51 - INFO - __main__ -   Current data iter size: 2256\n","08/15/2021 09:53:51 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 09:54:09 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 09:54:09 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 09:54:09 - INFO - __main__ -     Batch size = 64\n","08/15/2021 10:01:48 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 10:01:48 - INFO - __main__ -     map = 0.7517845434002576\n","08/15/2021 10:01:50 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_root5_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 0\n","08/15/2021 10:09:57 - INFO - __main__ -   Iter = 1500\n","08/15/2021 10:09:57 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/15/2021 10:09:57 - INFO - __main__ -   loss = 0.41317864214380584\n","08/15/2021 10:09:57 - INFO - __main__ -   Current data iter size: 2359\n","08/15/2021 10:09:57 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 10:10:13 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 10:10:13 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 10:10:13 - INFO - __main__ -     Batch size = 64\n","08/15/2021 10:18:00 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 10:18:00 - INFO - __main__ -     map = 0.7588876520069062\n","08/15/2021 10:18:01 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_root5_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 0\n","08/15/2021 10:26:10 - INFO - __main__ -   Iter = 1800\n","08/15/2021 10:26:10 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/15/2021 10:26:10 - INFO - __main__ -   loss = 0.43189804037412005\n","08/15/2021 10:26:10 - INFO - __main__ -   Current data iter size: 2446\n","08/15/2021 10:26:10 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 10:26:27 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 10:26:27 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 10:26:27 - INFO - __main__ -     Batch size = 64\n","08/15/2021 10:34:12 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 10:34:12 - INFO - __main__ -     map = 0.7495069775018971\n","QC: length of D 164544 length of sample 0\n","08/15/2021 10:42:19 - INFO - __main__ -   Iter = 2100\n","08/15/2021 10:42:19 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/15/2021 10:42:19 - INFO - __main__ -   loss = 0.4491224351525307\n","08/15/2021 10:42:19 - INFO - __main__ -   Current data iter size: 2522\n","08/15/2021 10:42:19 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 10:42:37 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 10:42:37 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 10:42:37 - INFO - __main__ -     Batch size = 64\n","08/15/2021 10:50:17 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 10:50:17 - INFO - __main__ -     map = 0.7634516324865243\n","08/15/2021 10:50:19 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_root5_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 164544 length of sample 0\n","08/15/2021 10:58:31 - INFO - __main__ -   Iter = 2400\n","08/15/2021 10:58:31 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/15/2021 10:58:31 - INFO - __main__ -   loss = 0.4620172028740247\n","08/15/2021 10:58:31 - INFO - __main__ -   Current data iter size: 2571\n","08/15/2021 10:58:31 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 10:58:49 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 10:58:49 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 10:58:49 - INFO - __main__ -     Batch size = 64\n","08/15/2021 11:06:32 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 11:06:32 - INFO - __main__ -     map = 0.7632379771101396\n","QC: length of D 164544 length of sample 0\n","08/15/2021 11:11:14 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/15/2021 11:11:14 - INFO - __main__ -    global_step = 2572, average loss = 0.40625663026935577\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9-F0Xw4Bl6tg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629026309669,"user_tz":-120,"elapsed":8442466,"user":{"displayName":"王梦琪","photoUrl":"","userId":"17110178610712270742"}},"outputId":"520da520-dd6c-4501-df7c-a8531879cb25"},"source":["# seed 1 60000\n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 3\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_10_root5_seed_3 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --eval_subsize 60000\\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/15/2021 08:57:53 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/15/2021 08:57:53 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpkrvf5tod\n","100% 433/433 [00:00<00:00, 526568.17B/s]\n","08/15/2021 08:57:53 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpkrvf5tod to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/15/2021 08:57:53 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/15/2021 08:57:53 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpkrvf5tod\n","08/15/2021 08:57:53 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/15/2021 08:57:53 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/15/2021 08:57:54 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp45dc4byj\n","100% 231508/231508 [00:00<00:00, 863777.78B/s]\n","08/15/2021 08:57:54 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp45dc4byj to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/15/2021 08:57:54 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/15/2021 08:57:54 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp45dc4byj\n","08/15/2021 08:57:54 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/15/2021 08:57:55 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpohasojzv\n","100% 440473133/440473133 [00:12<00:00, 35363864.36B/s]\n","08/15/2021 08:58:07 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpohasojzv to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/15/2021 08:58:09 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/15/2021 08:58:09 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpohasojzv\n","08/15/2021 08:58:09 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/15/2021 08:58:12 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/15/2021 08:58:12 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/15/2021 08:58:24 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=1, noise_lambda=0.0, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_10_root5_seed_3', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3', save_aps=False, save_steps=5000, seed=3, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/15/2021 08:58:24 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/15/2021 08:58:45 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/15/2021 08:58:48 - INFO - __main__ -   ***** Running training *****\n","08/15/2021 08:58:48 - INFO - __main__ -     Num examples = 164544\n","08/15/2021 08:58:48 - INFO - __main__ -     Num Epochs = 1\n","08/15/2021 08:58:48 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/15/2021 08:58:48 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/15/2021 08:58:48 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/15/2021 08:58:48 - INFO - __main__ -     Total optimization steps = 2571\n","08/15/2021 08:58:48 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/15/2021 08:58:48 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7f9c1828d8d0>)]\n","08/15/2021 08:58:48 - INFO - __main__ -   Starting epoch 1\n","08/15/2021 08:58:48 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/15/2021 09:06:56 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/15/2021 09:06:56 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/15/2021 09:06:56 - INFO - __main__ -   loss = 0.33900241563717526\n","08/15/2021 09:06:56 - INFO - __main__ -   Current data iter size: 1717\n","08/15/2021 09:06:56 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 09:07:15 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 09:07:15 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 09:07:15 - INFO - __main__ -     Batch size = 64\n","08/15/2021 09:15:29 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 09:15:29 - INFO - __main__ -     map = 0.7335183386971886\n","08/15/2021 09:15:30 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_root5_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 164544 length of sample 0\n","08/15/2021 09:23:47 - INFO - __main__ -   Iter = 600\n","08/15/2021 09:23:47 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/15/2021 09:23:47 - INFO - __main__ -   loss = 0.33098614513874053\n","08/15/2021 09:23:47 - INFO - __main__ -   Current data iter size: 1967\n","08/15/2021 09:23:47 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 09:24:04 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 09:24:04 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 09:24:04 - INFO - __main__ -     Batch size = 64\n","08/15/2021 09:32:17 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 09:32:17 - INFO - __main__ -     map = 0.7521270211571619\n","08/15/2021 09:32:18 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_root5_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 164544 length of sample 0\n","08/15/2021 09:40:37 - INFO - __main__ -   Iter = 900\n","08/15/2021 09:40:37 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/15/2021 09:40:37 - INFO - __main__ -   loss = 0.36255222886800764\n","08/15/2021 09:40:37 - INFO - __main__ -   Current data iter size: 2131\n","08/15/2021 09:40:37 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 09:40:53 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 09:40:53 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 09:40:53 - INFO - __main__ -     Batch size = 64\n","08/15/2021 09:49:01 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 09:49:01 - INFO - __main__ -     map = 0.7557689141728006\n","08/15/2021 09:49:03 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_root5_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 164544 length of sample 0\n","08/15/2021 09:57:22 - INFO - __main__ -   Iter = 1200\n","08/15/2021 09:57:22 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/15/2021 09:57:22 - INFO - __main__ -   loss = 0.3953407927850882\n","08/15/2021 09:57:22 - INFO - __main__ -   Current data iter size: 2256\n","08/15/2021 09:57:22 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 09:57:39 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 09:57:39 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 09:57:39 - INFO - __main__ -     Batch size = 64\n","08/15/2021 10:05:48 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 10:05:48 - INFO - __main__ -     map = 0.7654902458614026\n","08/15/2021 10:05:50 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_root5_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 164544 length of sample 0\n","08/15/2021 10:14:15 - INFO - __main__ -   Iter = 1500\n","08/15/2021 10:14:15 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/15/2021 10:14:15 - INFO - __main__ -   loss = 0.4072242707510789\n","08/15/2021 10:14:15 - INFO - __main__ -   Current data iter size: 2359\n","08/15/2021 10:14:15 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 10:14:31 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 10:14:31 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 10:14:31 - INFO - __main__ -     Batch size = 64\n","08/15/2021 10:22:44 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 10:22:44 - INFO - __main__ -     map = 0.7695302485486565\n","08/15/2021 10:22:45 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_root5_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 164544 length of sample 0\n","08/15/2021 10:31:12 - INFO - __main__ -   Iter = 1800\n","08/15/2021 10:31:12 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/15/2021 10:31:12 - INFO - __main__ -   loss = 0.42581636170546217\n","08/15/2021 10:31:12 - INFO - __main__ -   Current data iter size: 2446\n","08/15/2021 10:31:12 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 10:31:28 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 10:31:28 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 10:31:28 - INFO - __main__ -     Batch size = 64\n","08/15/2021 10:39:40 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 10:39:40 - INFO - __main__ -     map = 0.7646368869409462\n","QC: length of D 164544 length of sample 0\n","08/15/2021 10:48:07 - INFO - __main__ -   Iter = 2100\n","08/15/2021 10:48:07 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/15/2021 10:48:07 - INFO - __main__ -   loss = 0.4455112635095914\n","08/15/2021 10:48:07 - INFO - __main__ -   Current data iter size: 2522\n","08/15/2021 10:48:07 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 10:48:23 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 10:48:23 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 10:48:23 - INFO - __main__ -     Batch size = 64\n","08/15/2021 10:56:34 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 10:56:34 - INFO - __main__ -     map = 0.7707858441891614\n","08/15/2021 10:56:36 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_root5_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 164544 length of sample 0\n","08/15/2021 11:05:05 - INFO - __main__ -   Iter = 2400\n","08/15/2021 11:05:05 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/15/2021 11:05:05 - INFO - __main__ -   loss = 0.46312927136818566\n","08/15/2021 11:05:05 - INFO - __main__ -   Current data iter size: 2571\n","08/15/2021 11:05:05 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 11:05:22 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 11:05:22 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 11:05:22 - INFO - __main__ -     Batch size = 64\n","08/15/2021 11:13:34 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 11:13:34 - INFO - __main__ -     map = 0.7763562172370495\n","08/15/2021 11:13:35 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_root5_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 164544 length of sample 0\n","08/15/2021 11:18:27 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/15/2021 11:18:28 - INFO - __main__ -    global_step = 2572, average loss = 0.4006672725197316\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2-DMwDBwUBIG"},"source":["# Mantis standard_training"]},{"cell_type":"code","metadata":{"id":"P5Em4KH0UBIO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628758356410,"user_tz":-120,"elapsed":8513272,"user":{"displayName":"xiaokang qian","photoUrl":"","userId":"16136989389156139825"}},"outputId":"a487d101-7d46-45e3-969d-316dc8ee78a4"},"source":["# seed 1 60000\n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 1\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_10_standard_training_seed_1 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function standard_training\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --eval_subsize 60000\\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/12/2021 06:30:46 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/12/2021 06:30:47 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpntzvgojh\n","100% 433/433 [00:00<00:00, 382988.96B/s]\n","08/12/2021 06:30:47 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpntzvgojh to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/12/2021 06:30:47 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/12/2021 06:30:47 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpntzvgojh\n","08/12/2021 06:30:47 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/12/2021 06:30:47 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/12/2021 06:30:47 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpkfjbtd6z\n","100% 231508/231508 [00:00<00:00, 840760.16B/s]\n","08/12/2021 06:30:48 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpkfjbtd6z to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/12/2021 06:30:48 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/12/2021 06:30:48 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpkfjbtd6z\n","08/12/2021 06:30:48 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/12/2021 06:30:48 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpxg_7vs1k\n","100% 440473133/440473133 [00:11<00:00, 36711306.62B/s]\n","08/12/2021 06:31:00 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpxg_7vs1k to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/12/2021 06:31:02 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/12/2021 06:31:02 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpxg_7vs1k\n","08/12/2021 06:31:02 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/12/2021 06:31:05 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/12/2021 06:31:05 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/12/2021 06:31:17 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=1, noise_lambda=0.0, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_10_standard_training_seed_1', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='standard_training', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3standard_training_seed_1', save_aps=False, save_steps=5000, seed=1, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/12/2021 06:31:17 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/12/2021 06:31:39 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/12/2021 06:31:42 - INFO - __main__ -   ***** Running training *****\n","08/12/2021 06:31:42 - INFO - __main__ -     Num examples = 164544\n","08/12/2021 06:31:42 - INFO - __main__ -     Num Epochs = 1\n","08/12/2021 06:31:42 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/12/2021 06:31:42 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/12/2021 06:31:42 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/12/2021 06:31:42 - INFO - __main__ -     Total optimization steps = 2571\n","08/12/2021 06:31:42 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/12/2021 06:31:42 - INFO - __main__ -     data_loaders = [('pacing_function_standard_training', <torch.utils.data.dataloader.DataLoader object at 0x7fabc043f810>)]\n","08/12/2021 06:31:42 - INFO - __main__ -   Starting epoch 1\n","08/12/2021 06:31:42 - INFO - __main__ -   Training with pacing_function_standard_training\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/12/2021 06:40:09 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/12/2021 06:40:09 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/12/2021 06:40:09 - INFO - __main__ -   loss = 0.5685057638088862\n","08/12/2021 06:40:09 - INFO - __main__ -   Current data iter size: 2571\n","08/12/2021 06:40:09 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 06:40:30 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 06:40:30 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 06:40:30 - INFO - __main__ -     Batch size = 64\n","08/12/2021 06:48:42 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 06:48:42 - INFO - __main__ -     map = 0.7271335523945488\n","08/12/2021 06:48:44 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_standard_training_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3standard_training_seed_1\n","QC: length of D 164544 length of sample 0\n","08/12/2021 06:57:13 - INFO - __main__ -   Iter = 600\n","08/12/2021 06:57:13 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/12/2021 06:57:13 - INFO - __main__ -   loss = 0.532020569940408\n","08/12/2021 06:57:13 - INFO - __main__ -   Current data iter size: 2571\n","08/12/2021 06:57:13 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 06:57:30 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 06:57:30 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 06:57:30 - INFO - __main__ -     Batch size = 64\n","08/12/2021 07:05:44 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 07:05:44 - INFO - __main__ -     map = 0.7420384390196089\n","08/12/2021 07:05:46 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_standard_training_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3standard_training_seed_1\n","QC: length of D 164544 length of sample 0\n","08/12/2021 07:14:17 - INFO - __main__ -   Iter = 900\n","08/12/2021 07:14:17 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/12/2021 07:14:17 - INFO - __main__ -   loss = 0.5106016091505686\n","08/12/2021 07:14:17 - INFO - __main__ -   Current data iter size: 2571\n","08/12/2021 07:14:17 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 07:14:35 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 07:14:35 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 07:14:35 - INFO - __main__ -     Batch size = 64\n","08/12/2021 07:22:44 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 07:22:44 - INFO - __main__ -     map = 0.7550869206407514\n","08/12/2021 07:22:45 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_standard_training_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3standard_training_seed_1\n","QC: length of D 164544 length of sample 0\n","08/12/2021 07:31:13 - INFO - __main__ -   Iter = 1200\n","08/12/2021 07:31:13 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/12/2021 07:31:13 - INFO - __main__ -   loss = 0.4847264270981153\n","08/12/2021 07:31:13 - INFO - __main__ -   Current data iter size: 2571\n","08/12/2021 07:31:13 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 07:31:31 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 07:31:31 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 07:31:31 - INFO - __main__ -     Batch size = 64\n","08/12/2021 07:39:39 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 07:39:39 - INFO - __main__ -     map = 0.7610288642863142\n","08/12/2021 07:39:41 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_standard_training_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3standard_training_seed_1\n","QC: length of D 164544 length of sample 0\n","08/12/2021 07:48:08 - INFO - __main__ -   Iter = 1500\n","08/12/2021 07:48:08 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/12/2021 07:48:08 - INFO - __main__ -   loss = 0.4800374116500219\n","08/12/2021 07:48:08 - INFO - __main__ -   Current data iter size: 2571\n","08/12/2021 07:48:08 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 07:48:24 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 07:48:24 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 07:48:24 - INFO - __main__ -     Batch size = 64\n","08/12/2021 07:56:36 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 07:56:36 - INFO - __main__ -     map = 0.7577569819221284\n","QC: length of D 164544 length of sample 0\n","08/12/2021 08:05:06 - INFO - __main__ -   Iter = 1800\n","08/12/2021 08:05:06 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/12/2021 08:05:06 - INFO - __main__ -   loss = 0.47462800989548365\n","08/12/2021 08:05:06 - INFO - __main__ -   Current data iter size: 2571\n","08/12/2021 08:05:06 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 08:05:23 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 08:05:23 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 08:05:23 - INFO - __main__ -     Batch size = 64\n","08/12/2021 08:13:35 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 08:13:35 - INFO - __main__ -     map = 0.7593857024471842\n","QC: length of D 164544 length of sample 0\n","08/12/2021 08:22:06 - INFO - __main__ -   Iter = 2100\n","08/12/2021 08:22:06 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/12/2021 08:22:06 - INFO - __main__ -   loss = 0.46803345541159314\n","08/12/2021 08:22:06 - INFO - __main__ -   Current data iter size: 2571\n","08/12/2021 08:22:06 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 08:22:23 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 08:22:23 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 08:22:23 - INFO - __main__ -     Batch size = 64\n","08/12/2021 08:30:36 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 08:30:36 - INFO - __main__ -     map = 0.7660105355871731\n","08/12/2021 08:30:38 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_standard_training_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3standard_training_seed_1\n","QC: length of D 164544 length of sample 0\n","08/12/2021 08:39:10 - INFO - __main__ -   Iter = 2400\n","08/12/2021 08:39:10 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/12/2021 08:39:10 - INFO - __main__ -   loss = 0.46668952743212383\n","08/12/2021 08:39:10 - INFO - __main__ -   Current data iter size: 2571\n","08/12/2021 08:39:10 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/12/2021 08:39:28 - INFO - __main__ -   ***** Running evaluation  *****\n","08/12/2021 08:39:28 - INFO - __main__ -     Num examples = 60000\n","08/12/2021 08:39:28 - INFO - __main__ -     Batch size = 64\n","08/12/2021 08:47:40 - INFO - __main__ -   ***** Eval results  *****\n","08/12/2021 08:47:40 - INFO - __main__ -     map = 0.7638078273125071\n","QC: length of D 164544 length of sample 0\n","08/12/2021 08:52:32 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/12/2021 08:52:32 - INFO - __main__ -    global_step = 2572, average loss = 0.4959750718337195\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZO9LrfMym4DJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f3847978-4299-478a-8dfa-c0248f2647e8"},"source":["# seed 1 60000\n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 2\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_10_standard_training_seed_2 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function standard_training\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --eval_subsize 60000\\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/15/2021 11:25:29 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/15/2021 11:25:30 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpo9sdu_7k\n","100% 433/433 [00:00<00:00, 488207.97B/s]\n","08/15/2021 11:25:30 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpo9sdu_7k to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/15/2021 11:25:30 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/15/2021 11:25:30 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpo9sdu_7k\n","08/15/2021 11:25:30 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/15/2021 11:25:30 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/15/2021 11:25:30 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpkjvubqj0\n","100% 231508/231508 [00:00<00:00, 857236.50B/s]\n","08/15/2021 11:25:31 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpkjvubqj0 to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/15/2021 11:25:31 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/15/2021 11:25:31 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpkjvubqj0\n","08/15/2021 11:25:31 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/15/2021 11:25:31 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpu4euhhzz\n","100% 440473133/440473133 [00:15<00:00, 29090755.15B/s]\n","08/15/2021 11:25:47 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpu4euhhzz to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/15/2021 11:25:48 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/15/2021 11:25:48 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpu4euhhzz\n","08/15/2021 11:25:48 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/15/2021 11:25:51 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/15/2021 11:25:51 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/15/2021 11:26:03 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=1, noise_lambda=0.0, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_10_standard_training_seed_2', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='standard_training', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3standard_training_seed_2', save_aps=False, save_steps=5000, seed=2, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/15/2021 11:26:03 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/15/2021 11:26:23 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/15/2021 11:26:26 - INFO - __main__ -   ***** Running training *****\n","08/15/2021 11:26:26 - INFO - __main__ -     Num examples = 164544\n","08/15/2021 11:26:26 - INFO - __main__ -     Num Epochs = 1\n","08/15/2021 11:26:26 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/15/2021 11:26:26 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/15/2021 11:26:26 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/15/2021 11:26:26 - INFO - __main__ -     Total optimization steps = 2571\n","08/15/2021 11:26:26 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/15/2021 11:26:26 - INFO - __main__ -     data_loaders = [('pacing_function_standard_training', <torch.utils.data.dataloader.DataLoader object at 0x7f819b116850>)]\n","08/15/2021 11:26:26 - INFO - __main__ -   Starting epoch 1\n","08/15/2021 11:26:26 - INFO - __main__ -   Training with pacing_function_standard_training\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/15/2021 11:34:52 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/15/2021 11:34:52 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/15/2021 11:34:52 - INFO - __main__ -   loss = 0.5662350132067998\n","08/15/2021 11:34:52 - INFO - __main__ -   Current data iter size: 2571\n","08/15/2021 11:34:52 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 11:35:11 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 11:35:11 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 11:35:11 - INFO - __main__ -     Batch size = 64\n","08/15/2021 11:43:30 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 11:43:30 - INFO - __main__ -     map = 0.7263313824592855\n","08/15/2021 11:43:32 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_standard_training_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3standard_training_seed_2\n","QC: length of D 164544 length of sample 0\n","08/15/2021 11:52:04 - INFO - __main__ -   Iter = 600\n","08/15/2021 11:52:04 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/15/2021 11:52:04 - INFO - __main__ -   loss = 0.5329022691647212\n","08/15/2021 11:52:04 - INFO - __main__ -   Current data iter size: 2571\n","08/15/2021 11:52:04 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 11:52:21 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 11:52:21 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 11:52:21 - INFO - __main__ -     Batch size = 64\n","08/15/2021 12:00:40 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 12:00:40 - INFO - __main__ -     map = 0.7387212486004494\n","08/15/2021 12:00:42 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_standard_training_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3standard_training_seed_2\n","QC: length of D 164544 length of sample 0\n","08/15/2021 12:09:11 - INFO - __main__ -   Iter = 900\n","08/15/2021 12:09:11 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/15/2021 12:09:11 - INFO - __main__ -   loss = 0.5183763872583708\n","08/15/2021 12:09:11 - INFO - __main__ -   Current data iter size: 2571\n","08/15/2021 12:09:11 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 12:09:27 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 12:09:27 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 12:09:27 - INFO - __main__ -     Batch size = 64\n","08/15/2021 12:17:39 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 12:17:39 - INFO - __main__ -     map = 0.7509775124516769\n","08/15/2021 12:17:40 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_standard_training_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3standard_training_seed_2\n","QC: length of D 164544 length of sample 0\n","08/15/2021 12:26:04 - INFO - __main__ -   Iter = 1200\n","08/15/2021 12:26:04 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/15/2021 12:26:04 - INFO - __main__ -   loss = 0.5019758624831835\n","08/15/2021 12:26:04 - INFO - __main__ -   Current data iter size: 2571\n","08/15/2021 12:26:04 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 12:26:21 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 12:26:21 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 12:26:21 - INFO - __main__ -     Batch size = 64\n","08/15/2021 12:34:31 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 12:34:31 - INFO - __main__ -     map = 0.7477055099922568\n","QC: length of D 164544 length of sample 0\n","08/15/2021 12:42:55 - INFO - __main__ -   Iter = 1500\n","08/15/2021 12:42:55 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/15/2021 12:42:55 - INFO - __main__ -   loss = 0.49351294060548145\n","08/15/2021 12:42:55 - INFO - __main__ -   Current data iter size: 2571\n","08/15/2021 12:42:55 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 12:43:12 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 12:43:12 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 12:43:12 - INFO - __main__ -     Batch size = 64\n","08/15/2021 12:51:22 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 12:51:22 - INFO - __main__ -     map = 0.7489789612545849\n","QC: length of D 164544 length of sample 0\n","08/15/2021 12:59:52 - INFO - __main__ -   Iter = 1800\n","08/15/2021 12:59:52 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/15/2021 12:59:52 - INFO - __main__ -   loss = 0.48081987152496974\n","08/15/2021 12:59:52 - INFO - __main__ -   Current data iter size: 2571\n","08/15/2021 12:59:52 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 13:00:08 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 13:00:08 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 13:00:08 - INFO - __main__ -     Batch size = 64\n","08/15/2021 13:08:27 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 13:08:27 - INFO - __main__ -     map = 0.7592707684132354\n","08/15/2021 13:08:28 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_standard_training_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3standard_training_seed_2\n","QC: length of D 164544 length of sample 0\n","08/15/2021 13:17:01 - INFO - __main__ -   Iter = 2100\n","08/15/2021 13:17:01 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/15/2021 13:17:01 - INFO - __main__ -   loss = 0.46762693097194036\n","08/15/2021 13:17:01 - INFO - __main__ -   Current data iter size: 2571\n","08/15/2021 13:17:01 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 13:17:18 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 13:17:18 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 13:17:18 - INFO - __main__ -     Batch size = 64\n","08/15/2021 13:25:37 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 13:25:37 - INFO - __main__ -     map = 0.7625449868183517\n","08/15/2021 13:25:39 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_standard_training_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3standard_training_seed_2\n","QC: length of D 164544 length of sample 0\n","08/15/2021 13:34:08 - INFO - __main__ -   Iter = 2400\n","08/15/2021 13:34:08 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/15/2021 13:34:08 - INFO - __main__ -   loss = 0.47780025760332745\n","08/15/2021 13:34:08 - INFO - __main__ -   Current data iter size: 2571\n","08/15/2021 13:34:08 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 13:34:24 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 13:34:24 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 13:34:24 - INFO - __main__ -     Batch size = 64\n","08/15/2021 13:42:33 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 13:42:33 - INFO - __main__ -     map = 0.7588393287164986\n","QC: length of D 164544 length of sample 0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f49exKDMT4EJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629026549054,"user_tz":-120,"elapsed":8543211,"user":{"displayName":"Chen Qian","photoUrl":"","userId":"11245437508655380561"}},"outputId":"1b0060df-5e74-495b-c63c-687af39d0992"},"source":["# seed 1 60000\n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 3\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_10_standard_training_seed_3 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function standard_training\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --eval_subsize 60000\\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/15/2021 09:00:11 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/15/2021 09:00:12 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmps3q4v_nu\n","100% 433/433 [00:00<00:00, 519935.19B/s]\n","08/15/2021 09:00:12 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmps3q4v_nu to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/15/2021 09:00:12 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/15/2021 09:00:12 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmps3q4v_nu\n","08/15/2021 09:00:12 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/15/2021 09:00:12 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/15/2021 09:00:12 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpg4rkr50q\n","100% 231508/231508 [00:00<00:00, 957937.17B/s]\n","08/15/2021 09:00:13 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpg4rkr50q to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/15/2021 09:00:13 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/15/2021 09:00:13 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpg4rkr50q\n","08/15/2021 09:00:13 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/15/2021 09:00:13 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpks_auw92\n","100% 440473133/440473133 [00:12<00:00, 35939288.08B/s]\n","08/15/2021 09:00:25 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpks_auw92 to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/15/2021 09:00:27 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/15/2021 09:00:27 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpks_auw92\n","08/15/2021 09:00:27 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/15/2021 09:00:30 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/15/2021 09:00:30 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/15/2021 09:00:42 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=1, noise_lambda=0.0, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_10_standard_training_seed_3', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='standard_training', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3standard_training_seed_3', save_aps=False, save_steps=5000, seed=3, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/15/2021 09:00:42 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/15/2021 09:01:05 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/15/2021 09:01:08 - INFO - __main__ -   ***** Running training *****\n","08/15/2021 09:01:08 - INFO - __main__ -     Num examples = 164544\n","08/15/2021 09:01:08 - INFO - __main__ -     Num Epochs = 1\n","08/15/2021 09:01:08 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/15/2021 09:01:08 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/15/2021 09:01:08 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/15/2021 09:01:08 - INFO - __main__ -     Total optimization steps = 2571\n","08/15/2021 09:01:08 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/15/2021 09:01:08 - INFO - __main__ -     data_loaders = [('pacing_function_standard_training', <torch.utils.data.dataloader.DataLoader object at 0x7f8bed0ff310>)]\n","08/15/2021 09:01:08 - INFO - __main__ -   Starting epoch 1\n","08/15/2021 09:01:08 - INFO - __main__ -   Training with pacing_function_standard_training\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/15/2021 09:09:30 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/15/2021 09:09:30 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/15/2021 09:09:30 - INFO - __main__ -   loss = 0.5767923632264137\n","08/15/2021 09:09:30 - INFO - __main__ -   Current data iter size: 2571\n","08/15/2021 09:09:30 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 09:09:52 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 09:09:52 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 09:09:52 - INFO - __main__ -     Batch size = 64\n","08/15/2021 09:18:06 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 09:18:06 - INFO - __main__ -     map = 0.724709550945032\n","08/15/2021 09:18:08 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_standard_training_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3standard_training_seed_3\n","QC: length of D 164544 length of sample 0\n","08/15/2021 09:26:39 - INFO - __main__ -   Iter = 600\n","08/15/2021 09:26:39 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/15/2021 09:26:39 - INFO - __main__ -   loss = 0.5240333567063014\n","08/15/2021 09:26:39 - INFO - __main__ -   Current data iter size: 2571\n","08/15/2021 09:26:39 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 09:26:57 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 09:26:57 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 09:26:57 - INFO - __main__ -     Batch size = 64\n","08/15/2021 09:35:11 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 09:35:11 - INFO - __main__ -     map = 0.7313611962096822\n","08/15/2021 09:35:13 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_standard_training_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3standard_training_seed_3\n","QC: length of D 164544 length of sample 0\n","08/15/2021 09:43:45 - INFO - __main__ -   Iter = 900\n","08/15/2021 09:43:45 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/15/2021 09:43:45 - INFO - __main__ -   loss = 0.5048283959428469\n","08/15/2021 09:43:45 - INFO - __main__ -   Current data iter size: 2571\n","08/15/2021 09:43:45 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 09:44:02 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 09:44:02 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 09:44:02 - INFO - __main__ -     Batch size = 64\n","08/15/2021 09:52:17 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 09:52:17 - INFO - __main__ -     map = 0.7577085529328162\n","08/15/2021 09:52:19 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_standard_training_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3standard_training_seed_3\n","QC: length of D 164544 length of sample 0\n","08/15/2021 10:00:50 - INFO - __main__ -   Iter = 1200\n","08/15/2021 10:00:50 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/15/2021 10:00:50 - INFO - __main__ -   loss = 0.4988503710428874\n","08/15/2021 10:00:50 - INFO - __main__ -   Current data iter size: 2571\n","08/15/2021 10:00:50 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 10:01:09 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 10:01:09 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 10:01:09 - INFO - __main__ -     Batch size = 64\n","08/15/2021 10:09:23 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 10:09:23 - INFO - __main__ -     map = 0.7558727653996038\n","QC: length of D 164544 length of sample 0\n","08/15/2021 10:17:56 - INFO - __main__ -   Iter = 1500\n","08/15/2021 10:17:56 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/15/2021 10:17:56 - INFO - __main__ -   loss = 0.4857365436355273\n","08/15/2021 10:17:56 - INFO - __main__ -   Current data iter size: 2571\n","08/15/2021 10:17:56 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 10:18:13 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 10:18:13 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 10:18:13 - INFO - __main__ -     Batch size = 64\n","08/15/2021 10:26:27 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 10:26:27 - INFO - __main__ -     map = 0.7647594778790486\n","08/15/2021 10:26:29 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_standard_training_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3standard_training_seed_3\n","QC: length of D 164544 length of sample 0\n","08/15/2021 10:35:00 - INFO - __main__ -   Iter = 1800\n","08/15/2021 10:35:00 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/15/2021 10:35:00 - INFO - __main__ -   loss = 0.4799848125378291\n","08/15/2021 10:35:00 - INFO - __main__ -   Current data iter size: 2571\n","08/15/2021 10:35:00 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 10:35:17 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 10:35:17 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 10:35:17 - INFO - __main__ -     Batch size = 64\n","08/15/2021 10:43:31 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 10:43:31 - INFO - __main__ -     map = 0.7617672389672883\n","QC: length of D 164544 length of sample 0\n","08/15/2021 10:52:03 - INFO - __main__ -   Iter = 2100\n","08/15/2021 10:52:03 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/15/2021 10:52:03 - INFO - __main__ -   loss = 0.47361111094554265\n","08/15/2021 10:52:03 - INFO - __main__ -   Current data iter size: 2571\n","08/15/2021 10:52:03 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 10:52:19 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 10:52:19 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 10:52:19 - INFO - __main__ -     Batch size = 64\n","08/15/2021 11:00:33 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 11:00:33 - INFO - __main__ -     map = 0.7684374398933953\n","08/15/2021 11:00:34 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_10_standard_training_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3standard_training_seed_3\n","QC: length of D 164544 length of sample 0\n","08/15/2021 11:09:06 - INFO - __main__ -   Iter = 2400\n","08/15/2021 11:09:06 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/15/2021 11:09:06 - INFO - __main__ -   loss = 0.4733305629094442\n","08/15/2021 11:09:06 - INFO - __main__ -   Current data iter size: 2571\n","08/15/2021 11:09:06 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/15/2021 11:09:23 - INFO - __main__ -   ***** Running evaluation  *****\n","08/15/2021 11:09:23 - INFO - __main__ -     Num examples = 60000\n","08/15/2021 11:09:23 - INFO - __main__ -     Batch size = 64\n","08/15/2021 11:17:38 - INFO - __main__ -   ***** Eval results  *****\n","08/15/2021 11:17:38 - INFO - __main__ -     map = 0.7645293162366052\n","QC: length of D 164544 length of sample 0\n","08/15/2021 11:22:27 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/15/2021 11:22:27 - INFO - __main__ -    global_step = 2572, average loss = 0.4993175755531569\n"],"name":"stdout"}]}]}