{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"noise_transformercl_66.ipynb","provenance":[{"file_id":"1MttUBPHnUJo40poSwmH61w9TaDG8_F7z","timestamp":1628843855448},{"file_id":"1Gslqz9zqY_JDqJzzm03bUiIUaQ2brtoc","timestamp":1628843384918},{"file_id":"1JPdZJDI3EfwNR9DB4D8nQEv-kDUdhyqc","timestamp":1623066561753},{"file_id":"1MR6fqyFJ0F0CvZ_prOyG8prQRr9h1zwL","timestamp":1621518416179}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"CgncrxE8FEY-"},"source":["function KeepClicking(){\n","console.log(\"Clicking\");\n","document.querySelector(\"colab-connect-button\").click()\n","}\n","setInterval(KeepClicking,60000)\n","Open your Chrome DevTools by pressing F12 or ctrl+shift+i on Linux and enter the following JavaScript snippet in your console:"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1QWVTurKCTMV","executionInfo":{"status":"ok","timestamp":1628945424969,"user_tz":-120,"elapsed":16763,"user":{"displayName":"Chen Qian","photoUrl":"","userId":"11245437508655380561"}},"outputId":"06cd9605-5329-4744-a7aa-b37bc080d521"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0q-7RWqYrMbI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628945435617,"user_tz":-120,"elapsed":10664,"user":{"displayName":"Chen Qian","photoUrl":"","userId":"11245437508655380561"}},"outputId":"34706adb-f4db-4e45-e048-05268f314b8e"},"source":["# install transformers\n","!pip install pytorch_transformers\n","# Mount google drive\n","!pip install -r drive/MyDrive/transformers_cl/requirements.txt"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting pytorch_transformers\n","  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n","\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 38.8 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 35.7 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 21.5 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 176 kB 9.3 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (4.62.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2019.12.20)\n","Collecting boto3\n","  Downloading boto3-1.18.21-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 59.9 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 65.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.19.5)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.9.0+cu102)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 60.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.7.4.3)\n","Collecting botocore<1.22.0,>=1.21.21\n","  Downloading botocore-1.21.21-py3-none-any.whl (7.8 MB)\n","\u001b[K     |████████████████████████████████| 7.8 MB 69.7 MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 9.7 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.21->boto3->pytorch_transformers) (2.8.2)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 44.8 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->pytorch_transformers) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2.10)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 49.8 MB/s \n","\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3, pytorch-transformers\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.18.21 botocore-1.21.21 jmespath-0.10.0 pytorch-transformers-1.2.0 s3transfer-0.5.0 sacremoses-0.0.45 sentencepiece-0.1.96 urllib3-1.25.11\n","Collecting tensorboardX\n","  Downloading tensorboardX-2.4-py2.py3-none-any.whl (124 kB)\n","\u001b[K     |████████████████████████████████| 124 kB 7.9 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r drive/MyDrive/transformers_cl/requirements.txt (line 2)) (0.22.2.post1)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from -r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (5.5.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->-r drive/MyDrive/transformers_cl/requirements.txt (line 1)) (3.17.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX->-r drive/MyDrive/transformers_cl/requirements.txt (line 1)) (1.19.5)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX->-r drive/MyDrive/transformers_cl/requirements.txt (line 1)) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r drive/MyDrive/transformers_cl/requirements.txt (line 2)) (1.0.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r drive/MyDrive/transformers_cl/requirements.txt (line 2)) (1.4.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (0.7.5)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (4.8.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (4.4.2)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (1.0.18)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (57.2.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (0.8.1)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (2.6.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (5.0.5)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (0.2.5)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (0.2.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (0.7.0)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gYNN5sk9-7z8"},"source":["# mantis root_5 with lamdba = 0.99, d_ratio = 0.66 noise"]},{"cell_type":"code","metadata":{"id":"dCjVt5gn-7z9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628852398136,"user_tz":-120,"elapsed":8130425,"user":{"displayName":"王梦琪","photoUrl":"","userId":"17110178610712270742"}},"outputId":"f3968e3e-4c4b-4521-f1de-5d9c3640f054"},"source":["# mantison drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 1\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_1 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.99\\\n","    --noise_difficult_ratio 0.66\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/13/2021 08:44:33 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/13/2021 08:44:33 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmp6_ho5bg5\n","100% 433/433 [00:00<00:00, 378913.76B/s]\n","08/13/2021 08:44:33 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp6_ho5bg5 to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 08:44:33 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 08:44:33 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp6_ho5bg5\n","08/13/2021 08:44:33 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 08:44:33 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/13/2021 08:44:33 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp0s521b0c\n","100% 231508/231508 [00:00<00:00, 948355.86B/s]\n","08/13/2021 08:44:34 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp0s521b0c to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 08:44:34 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 08:44:34 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp0s521b0c\n","08/13/2021 08:44:34 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 08:44:34 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpi3f9q3uh\n","100% 440473133/440473133 [00:11<00:00, 37000497.14B/s]\n","08/13/2021 08:44:46 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpi3f9q3uh to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 08:44:48 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 08:44:48 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpi3f9q3uh\n","08/13/2021 08:44:48 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 08:44:51 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/13/2021 08:44:51 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/13/2021 08:45:03 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=0.66, noise_lambda=0.99, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_1', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1', save_aps=False, save_steps=5000, seed=1, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/13/2021 08:45:03 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/13/2021 08:45:25 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/13/2021 08:45:28 - INFO - __main__ -   ***** Running training *****\n","08/13/2021 08:45:28 - INFO - __main__ -     Num examples = 164544\n","08/13/2021 08:45:28 - INFO - __main__ -     Num Epochs = 1\n","08/13/2021 08:45:28 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/13/2021 08:45:28 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/13/2021 08:45:28 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/13/2021 08:45:28 - INFO - __main__ -     Total optimization steps = 2571\n","08/13/2021 08:45:28 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/13/2021 08:45:28 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7ff8785eb8d0>)]\n","08/13/2021 08:45:28 - INFO - __main__ -   Starting epoch 1\n","08/13/2021 08:45:28 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/13/2021 08:53:22 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/13/2021 08:53:22 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/13/2021 08:53:22 - INFO - __main__ -   loss = 0.4766154248515765\n","08/13/2021 08:53:22 - INFO - __main__ -   Current data iter size: 1717\n","08/13/2021 08:53:22 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 08:53:42 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 08:53:42 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 08:53:42 - INFO - __main__ -     Batch size = 64\n","08/13/2021 09:01:31 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 09:01:31 - INFO - __main__ -     map = 0.738585581551774\n","08/13/2021 09:01:33 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 108600 length of sample 5390\n","08/13/2021 09:09:35 - INFO - __main__ -   Iter = 600\n","08/13/2021 09:09:35 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/13/2021 09:09:35 - INFO - __main__ -   loss = 0.34574579377969106\n","08/13/2021 09:09:35 - INFO - __main__ -   Current data iter size: 1967\n","08/13/2021 09:09:35 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 09:09:53 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 09:09:53 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 09:09:53 - INFO - __main__ -     Batch size = 64\n","08/13/2021 09:17:41 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 09:17:41 - INFO - __main__ -     map = 0.7432093158518563\n","08/13/2021 09:17:43 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 108600 length of sample 302\n","08/13/2021 09:25:49 - INFO - __main__ -   Iter = 900\n","08/13/2021 09:25:49 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/13/2021 09:25:49 - INFO - __main__ -   loss = 0.36671646510561307\n","08/13/2021 09:25:49 - INFO - __main__ -   Current data iter size: 2131\n","08/13/2021 09:25:49 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 09:26:06 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 09:26:06 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 09:26:06 - INFO - __main__ -     Batch size = 64\n","08/13/2021 09:33:53 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 09:33:53 - INFO - __main__ -     map = 0.7574688372018813\n","08/13/2021 09:33:56 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 108600 length of sample 16\n","08/13/2021 09:42:03 - INFO - __main__ -   Iter = 1200\n","08/13/2021 09:42:03 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/13/2021 09:42:03 - INFO - __main__ -   loss = 0.3864778823653857\n","08/13/2021 09:42:03 - INFO - __main__ -   Current data iter size: 2256\n","08/13/2021 09:42:03 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 09:42:20 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 09:42:20 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 09:42:20 - INFO - __main__ -     Batch size = 64\n","08/13/2021 09:50:07 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 09:50:07 - INFO - __main__ -     map = 0.7601877667505182\n","08/13/2021 09:50:09 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 108600 length of sample 0\n","08/13/2021 09:58:19 - INFO - __main__ -   Iter = 1500\n","08/13/2021 09:58:19 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/13/2021 09:58:19 - INFO - __main__ -   loss = 0.40306855604052544\n","08/13/2021 09:58:19 - INFO - __main__ -   Current data iter size: 2359\n","08/13/2021 09:58:19 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 09:58:35 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 09:58:35 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 09:58:35 - INFO - __main__ -     Batch size = 64\n","08/13/2021 10:06:22 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 10:06:22 - INFO - __main__ -     map = 0.7632688871031978\n","08/13/2021 10:06:24 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 108600 length of sample 0\n","08/13/2021 10:14:36 - INFO - __main__ -   Iter = 1800\n","08/13/2021 10:14:36 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/13/2021 10:14:36 - INFO - __main__ -   loss = 0.42360761761665344\n","08/13/2021 10:14:36 - INFO - __main__ -   Current data iter size: 2446\n","08/13/2021 10:14:36 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 10:14:54 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 10:14:54 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 10:14:54 - INFO - __main__ -     Batch size = 64\n","08/13/2021 10:22:41 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 10:22:41 - INFO - __main__ -     map = 0.7660729032762561\n","08/13/2021 10:22:42 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 108600 length of sample 0\n","08/13/2021 10:30:52 - INFO - __main__ -   Iter = 2100\n","08/13/2021 10:30:52 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/13/2021 10:30:52 - INFO - __main__ -   loss = 0.4414613774418831\n","08/13/2021 10:30:52 - INFO - __main__ -   Current data iter size: 2522\n","08/13/2021 10:30:52 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 10:31:09 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 10:31:09 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 10:31:09 - INFO - __main__ -     Batch size = 64\n","08/13/2021 10:38:57 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 10:38:57 - INFO - __main__ -     map = 0.7714279932025022\n","08/13/2021 10:38:59 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 108600 length of sample 0\n","08/13/2021 10:47:10 - INFO - __main__ -   Iter = 2400\n","08/13/2021 10:47:10 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/13/2021 10:47:10 - INFO - __main__ -   loss = 0.45921399086713793\n","08/13/2021 10:47:10 - INFO - __main__ -   Current data iter size: 2571\n","08/13/2021 10:47:10 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 10:47:27 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 10:47:27 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 10:47:27 - INFO - __main__ -     Batch size = 64\n","08/13/2021 10:55:14 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 10:55:14 - INFO - __main__ -     map = 0.769089220862956\n","QC: length of D 108600 length of sample 0\n","08/13/2021 10:59:55 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/13/2021 10:59:56 - INFO - __main__ -    global_step = 2572, average loss = 0.4157748683058826\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T0488mjpJEvL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b03cf181-ae7d-4484-fd97-05bf0ead04ad"},"source":["!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 2\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_2 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.99\\\n","    --noise_difficult_ratio 0.66\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/13/2021 11:01:38 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/13/2021 11:01:38 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 11:01:38 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/13/2021 11:01:38 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 11:01:39 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 11:01:53 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/13/2021 11:01:53 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/13/2021 11:01:57 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=0.66, noise_lambda=0.99, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_2', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2', save_aps=False, save_steps=5000, seed=2, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/13/2021 11:01:57 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/13/2021 11:02:17 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/13/2021 11:02:19 - INFO - __main__ -   ***** Running training *****\n","08/13/2021 11:02:19 - INFO - __main__ -     Num examples = 164544\n","08/13/2021 11:02:19 - INFO - __main__ -     Num Epochs = 1\n","08/13/2021 11:02:19 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/13/2021 11:02:19 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/13/2021 11:02:19 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/13/2021 11:02:19 - INFO - __main__ -     Total optimization steps = 2571\n","08/13/2021 11:02:19 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/13/2021 11:02:19 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7f139cec8ed0>)]\n","08/13/2021 11:02:19 - INFO - __main__ -   Starting epoch 1\n","08/13/2021 11:02:19 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/13/2021 11:10:11 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/13/2021 11:10:11 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/13/2021 11:10:11 - INFO - __main__ -   loss = 0.4843575581908226\n","08/13/2021 11:10:11 - INFO - __main__ -   Current data iter size: 1717\n","08/13/2021 11:10:11 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 11:10:29 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 11:10:29 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 11:10:29 - INFO - __main__ -     Batch size = 64\n","08/13/2021 11:18:15 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 11:18:15 - INFO - __main__ -     map = 0.7330298157135338\n","08/13/2021 11:18:17 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 108600 length of sample 5390\n","08/13/2021 11:26:17 - INFO - __main__ -   Iter = 600\n","08/13/2021 11:26:17 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/13/2021 11:26:17 - INFO - __main__ -   loss = 0.3501623629530271\n","08/13/2021 11:26:17 - INFO - __main__ -   Current data iter size: 1967\n","08/13/2021 11:26:17 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 11:26:33 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 11:26:33 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 11:26:33 - INFO - __main__ -     Batch size = 64\n","08/13/2021 11:34:19 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 11:34:19 - INFO - __main__ -     map = 0.7477629741446147\n","08/13/2021 11:34:21 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 108600 length of sample 302\n","08/13/2021 11:42:23 - INFO - __main__ -   Iter = 900\n","08/13/2021 11:42:23 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/13/2021 11:42:23 - INFO - __main__ -   loss = 0.37464969113469127\n","08/13/2021 11:42:23 - INFO - __main__ -   Current data iter size: 2131\n","08/13/2021 11:42:23 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 11:42:39 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 11:42:39 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 11:42:39 - INFO - __main__ -     Batch size = 64\n","08/13/2021 11:50:25 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 11:50:25 - INFO - __main__ -     map = 0.7594658777057203\n","08/13/2021 11:50:27 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 108600 length of sample 16\n","08/13/2021 11:58:31 - INFO - __main__ -   Iter = 1200\n","08/13/2021 11:58:31 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/13/2021 11:58:31 - INFO - __main__ -   loss = 0.39455297857522964\n","08/13/2021 11:58:31 - INFO - __main__ -   Current data iter size: 2256\n","08/13/2021 11:58:31 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 11:58:49 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 11:58:49 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 11:58:49 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:06:36 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:06:36 - INFO - __main__ -     map = 0.7523851071627708\n","QC: length of D 108600 length of sample 0\n","08/13/2021 12:14:45 - INFO - __main__ -   Iter = 1500\n","08/13/2021 12:14:45 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/13/2021 12:14:45 - INFO - __main__ -   loss = 0.42050234178702034\n","08/13/2021 12:14:45 - INFO - __main__ -   Current data iter size: 2359\n","08/13/2021 12:14:45 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 12:15:02 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 12:15:02 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 12:15:02 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:22:50 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:22:50 - INFO - __main__ -     map = 0.7505358664896559\n","QC: length of D 108600 length of sample 0\n","08/13/2021 12:30:59 - INFO - __main__ -   Iter = 1800\n","08/13/2021 12:30:59 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/13/2021 12:30:59 - INFO - __main__ -   loss = 0.431579742928346\n","08/13/2021 12:30:59 - INFO - __main__ -   Current data iter size: 2446\n","08/13/2021 12:30:59 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 12:31:16 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 12:31:16 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 12:31:16 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:39:03 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:39:03 - INFO - __main__ -     map = 0.761487485971045\n","08/13/2021 12:39:05 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 108600 length of sample 0\n","08/13/2021 12:47:17 - INFO - __main__ -   Iter = 2100\n","08/13/2021 12:47:17 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/13/2021 12:47:17 - INFO - __main__ -   loss = 0.4405054886639118\n","08/13/2021 12:47:17 - INFO - __main__ -   Current data iter size: 2522\n","08/13/2021 12:47:17 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 12:47:34 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 12:47:34 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 12:47:34 - INFO - __main__ -     Batch size = 64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U_ityyQPJFB2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628954088601,"user_tz":-120,"elapsed":8652994,"user":{"displayName":"Chen Qian","photoUrl":"","userId":"11245437508655380561"}},"outputId":"68c41e2a-3fa2-415e-defc-aa7a420a3c20"},"source":["!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 3\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_3 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.99\\\n","    --noise_difficult_ratio 0.66\\\n","    --eval_subsize 60000 \\"],"execution_count":3,"outputs":[{"output_type":"stream","text":["08/14/2021 12:50:39 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/14/2021 12:50:39 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmp_p7v92ez\n","100% 433/433 [00:00<00:00, 541805.98B/s]\n","08/14/2021 12:50:40 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp_p7v92ez to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 12:50:40 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 12:50:40 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp_p7v92ez\n","08/14/2021 12:50:40 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 12:50:40 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/14/2021 12:50:40 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp8nyp4q64\n","100% 231508/231508 [00:00<00:00, 957304.42B/s]\n","08/14/2021 12:50:40 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp8nyp4q64 to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 12:50:40 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 12:50:40 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp8nyp4q64\n","08/14/2021 12:50:40 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 12:50:41 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpu4_tn286\n","100% 440473133/440473133 [00:10<00:00, 42077671.25B/s]\n","08/14/2021 12:50:52 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpu4_tn286 to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 12:50:53 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 12:50:53 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpu4_tn286\n","08/14/2021 12:50:53 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 12:50:56 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/14/2021 12:50:56 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/14/2021 12:51:07 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=0.66, noise_lambda=0.99, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_3', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3', save_aps=False, save_steps=5000, seed=3, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/14/2021 12:51:07 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/14/2021 12:51:29 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/14/2021 12:51:32 - INFO - __main__ -   ***** Running training *****\n","08/14/2021 12:51:32 - INFO - __main__ -     Num examples = 164544\n","08/14/2021 12:51:32 - INFO - __main__ -     Num Epochs = 1\n","08/14/2021 12:51:32 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/14/2021 12:51:32 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/14/2021 12:51:32 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/14/2021 12:51:32 - INFO - __main__ -     Total optimization steps = 2571\n","08/14/2021 12:51:32 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/14/2021 12:51:32 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7f77ea41d950>)]\n","08/14/2021 12:51:32 - INFO - __main__ -   Starting epoch 1\n","08/14/2021 12:51:32 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/14/2021 12:59:51 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/14/2021 12:59:51 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/14/2021 12:59:51 - INFO - __main__ -   loss = 0.4750334769487381\n","08/14/2021 12:59:51 - INFO - __main__ -   Current data iter size: 1717\n","08/14/2021 12:59:51 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 13:00:11 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 13:00:11 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 13:00:11 - INFO - __main__ -     Batch size = 64\n","08/14/2021 13:08:37 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 13:08:37 - INFO - __main__ -     map = 0.7318562352205817\n","08/14/2021 13:08:39 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 108600 length of sample 5390\n","08/14/2021 13:17:06 - INFO - __main__ -   Iter = 600\n","08/14/2021 13:17:06 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/14/2021 13:17:06 - INFO - __main__ -   loss = 0.3477889799575011\n","08/14/2021 13:17:06 - INFO - __main__ -   Current data iter size: 1967\n","08/14/2021 13:17:06 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 13:17:24 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 13:17:24 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 13:17:24 - INFO - __main__ -     Batch size = 64\n","08/14/2021 13:25:50 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 13:25:50 - INFO - __main__ -     map = 0.7434461076865966\n","08/14/2021 13:25:52 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 108600 length of sample 302\n","08/14/2021 13:34:23 - INFO - __main__ -   Iter = 900\n","08/14/2021 13:34:23 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/14/2021 13:34:23 - INFO - __main__ -   loss = 0.36532112086812657\n","08/14/2021 13:34:23 - INFO - __main__ -   Current data iter size: 2131\n","08/14/2021 13:34:23 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 13:34:40 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 13:34:40 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 13:34:40 - INFO - __main__ -     Batch size = 64\n","08/14/2021 13:43:05 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 13:43:05 - INFO - __main__ -     map = 0.7606728401472285\n","08/14/2021 13:43:07 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 108600 length of sample 16\n","08/14/2021 13:51:41 - INFO - __main__ -   Iter = 1200\n","08/14/2021 13:51:41 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/14/2021 13:51:41 - INFO - __main__ -   loss = 0.39391459872325263\n","08/14/2021 13:51:41 - INFO - __main__ -   Current data iter size: 2256\n","08/14/2021 13:51:41 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 13:51:58 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 13:51:58 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 13:51:58 - INFO - __main__ -     Batch size = 64\n","08/14/2021 14:00:23 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 14:00:23 - INFO - __main__ -     map = 0.7600881475387289\n","QC: length of D 108600 length of sample 0\n","08/14/2021 14:08:57 - INFO - __main__ -   Iter = 1500\n","08/14/2021 14:08:57 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/14/2021 14:08:57 - INFO - __main__ -   loss = 0.4070160100857417\n","08/14/2021 14:08:57 - INFO - __main__ -   Current data iter size: 2359\n","08/14/2021 14:08:57 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 14:09:13 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 14:09:13 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 14:09:13 - INFO - __main__ -     Batch size = 64\n","08/14/2021 14:17:39 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 14:17:39 - INFO - __main__ -     map = 0.7650170903141814\n","08/14/2021 14:17:41 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 108600 length of sample 0\n","08/14/2021 14:26:18 - INFO - __main__ -   Iter = 1800\n","08/14/2021 14:26:18 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/14/2021 14:26:18 - INFO - __main__ -   loss = 0.4209999632338683\n","08/14/2021 14:26:18 - INFO - __main__ -   Current data iter size: 2446\n","08/14/2021 14:26:18 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 14:26:35 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 14:26:35 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 14:26:35 - INFO - __main__ -     Batch size = 64\n","08/14/2021 14:35:00 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 14:35:00 - INFO - __main__ -     map = 0.7706267395489016\n","08/14/2021 14:35:01 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_66_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 108600 length of sample 0\n","08/14/2021 14:43:41 - INFO - __main__ -   Iter = 2100\n","08/14/2021 14:43:41 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/14/2021 14:43:41 - INFO - __main__ -   loss = 0.4324837326010068\n","08/14/2021 14:43:41 - INFO - __main__ -   Current data iter size: 2522\n","08/14/2021 14:43:41 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 14:43:59 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 14:43:59 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 14:43:59 - INFO - __main__ -     Batch size = 64\n","08/14/2021 14:52:24 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 14:52:24 - INFO - __main__ -     map = 0.7657891515142087\n","QC: length of D 108600 length of sample 0\n","08/14/2021 15:01:04 - INFO - __main__ -   Iter = 2400\n","08/14/2021 15:01:04 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/14/2021 15:01:04 - INFO - __main__ -   loss = 0.46273086776336037\n","08/14/2021 15:01:04 - INFO - __main__ -   Current data iter size: 2571\n","08/14/2021 15:01:04 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 15:01:21 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 15:01:21 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 15:01:21 - INFO - __main__ -     Batch size = 64\n","08/14/2021 15:09:45 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 15:09:45 - INFO - __main__ -     map = 0.7676259473110091\n","QC: length of D 108600 length of sample 0\n","08/14/2021 15:14:45 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/14/2021 15:14:45 - INFO - __main__ -    global_step = 2572, average loss = 0.4163710437019821\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CUdGHOJQI9Iw"},"source":["# mantis root_5 with lamdba = 0.995, d_ratio = 0.66 noise"]},{"cell_type":"code","metadata":{"id":"i9mO0-xkjNg7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628853007375,"user_tz":-120,"elapsed":8700534,"user":{"displayName":"xy GG","photoUrl":"","userId":"06169222138223251748"}},"outputId":"a2ed2412-f559-4d19-9f3e-b7cd47f3c6b2"},"source":["# mantis root_5 \n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 1\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_1 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.995\\\n","    --noise_difficult_ratio 0.66\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/13/2021 08:45:12 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/13/2021 08:45:12 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmptqxzs022\n","100% 433/433 [00:00<00:00, 489787.93B/s]\n","08/13/2021 08:45:12 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmptqxzs022 to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 08:45:12 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 08:45:12 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmptqxzs022\n","08/13/2021 08:45:12 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 08:45:12 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/13/2021 08:45:13 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpwc4x9dx1\n","100% 231508/231508 [00:00<00:00, 945769.51B/s]\n","08/13/2021 08:45:13 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpwc4x9dx1 to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 08:45:13 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 08:45:13 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpwc4x9dx1\n","08/13/2021 08:45:13 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 08:45:13 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmp1dnncnx_\n","100% 440473133/440473133 [00:11<00:00, 38086239.14B/s]\n","08/13/2021 08:45:25 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp1dnncnx_ to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 08:45:26 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 08:45:26 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp1dnncnx_\n","08/13/2021 08:45:26 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 08:45:29 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/13/2021 08:45:29 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/13/2021 08:45:41 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=0.66, noise_lambda=0.995, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_1', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1', save_aps=False, save_steps=5000, seed=1, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/13/2021 08:45:41 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/13/2021 08:46:03 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/13/2021 08:46:06 - INFO - __main__ -   ***** Running training *****\n","08/13/2021 08:46:06 - INFO - __main__ -     Num examples = 164544\n","08/13/2021 08:46:06 - INFO - __main__ -     Num Epochs = 1\n","08/13/2021 08:46:06 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/13/2021 08:46:06 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/13/2021 08:46:06 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/13/2021 08:46:06 - INFO - __main__ -     Total optimization steps = 2571\n","08/13/2021 08:46:06 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/13/2021 08:46:06 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7f9b9049cd50>)]\n","08/13/2021 08:46:06 - INFO - __main__ -   Starting epoch 1\n","08/13/2021 08:46:06 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/13/2021 08:54:29 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/13/2021 08:54:29 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/13/2021 08:54:29 - INFO - __main__ -   loss = 0.5453454686204592\n","08/13/2021 08:54:29 - INFO - __main__ -   Current data iter size: 1717\n","08/13/2021 08:54:29 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 08:54:49 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 08:54:49 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 08:54:49 - INFO - __main__ -     Batch size = 64\n","08/13/2021 09:03:16 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 09:03:16 - INFO - __main__ -     map = 0.7325284983710901\n","08/13/2021 09:03:18 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 108600 length of sample 24435\n","08/13/2021 09:11:49 - INFO - __main__ -   Iter = 600\n","08/13/2021 09:11:49 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/13/2021 09:11:49 - INFO - __main__ -   loss = 0.40849291935563087\n","08/13/2021 09:11:49 - INFO - __main__ -   Current data iter size: 1967\n","08/13/2021 09:11:49 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 09:12:06 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 09:12:06 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 09:12:06 - INFO - __main__ -     Batch size = 64\n","08/13/2021 09:20:35 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 09:20:35 - INFO - __main__ -     map = 0.7485915459389603\n","08/13/2021 09:20:37 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 108600 length of sample 6220\n","08/13/2021 09:29:11 - INFO - __main__ -   Iter = 900\n","08/13/2021 09:29:11 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/13/2021 09:29:11 - INFO - __main__ -   loss = 0.3740490224957466\n","08/13/2021 09:29:11 - INFO - __main__ -   Current data iter size: 2131\n","08/13/2021 09:29:11 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 09:29:27 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 09:29:27 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 09:29:27 - INFO - __main__ -     Batch size = 64\n","08/13/2021 09:37:54 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 09:37:54 - INFO - __main__ -     map = 0.7506041962871085\n","08/13/2021 09:37:55 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 108600 length of sample 1498\n","08/13/2021 09:46:32 - INFO - __main__ -   Iter = 1200\n","08/13/2021 09:46:32 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/13/2021 09:46:32 - INFO - __main__ -   loss = 0.3935949913660685\n","08/13/2021 09:46:32 - INFO - __main__ -   Current data iter size: 2256\n","08/13/2021 09:46:32 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 09:46:49 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 09:46:49 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 09:46:49 - INFO - __main__ -     Batch size = 64\n","08/13/2021 09:55:17 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 09:55:17 - INFO - __main__ -     map = 0.7536451273438786\n","08/13/2021 09:55:19 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 108600 length of sample 352\n","08/13/2021 10:03:57 - INFO - __main__ -   Iter = 1500\n","08/13/2021 10:03:57 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/13/2021 10:03:57 - INFO - __main__ -   loss = 0.41283850342035294\n","08/13/2021 10:03:57 - INFO - __main__ -   Current data iter size: 2359\n","08/13/2021 10:03:57 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 10:04:15 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 10:04:15 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 10:04:15 - INFO - __main__ -     Batch size = 64\n","08/13/2021 10:12:42 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 10:12:42 - INFO - __main__ -     map = 0.7584705405493788\n","08/13/2021 10:12:44 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 108600 length of sample 81\n","08/13/2021 10:21:24 - INFO - __main__ -   Iter = 1800\n","08/13/2021 10:21:24 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/13/2021 10:21:24 - INFO - __main__ -   loss = 0.4327621989945571\n","08/13/2021 10:21:24 - INFO - __main__ -   Current data iter size: 2446\n","08/13/2021 10:21:24 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 10:21:41 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 10:21:41 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 10:21:41 - INFO - __main__ -     Batch size = 64\n","08/13/2021 10:30:08 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 10:30:08 - INFO - __main__ -     map = 0.757739355955303\n","QC: length of D 108600 length of sample 18\n","08/13/2021 10:38:49 - INFO - __main__ -   Iter = 2100\n","08/13/2021 10:38:49 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/13/2021 10:38:49 - INFO - __main__ -   loss = 0.4431235949198405\n","08/13/2021 10:38:49 - INFO - __main__ -   Current data iter size: 2522\n","08/13/2021 10:38:49 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 10:39:06 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 10:39:06 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 10:39:06 - INFO - __main__ -     Batch size = 64\n","08/13/2021 10:47:33 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 10:47:33 - INFO - __main__ -     map = 0.7641340760834234\n","08/13/2021 10:47:35 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 108600 length of sample 4\n","08/13/2021 10:56:18 - INFO - __main__ -   Iter = 2400\n","08/13/2021 10:56:18 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/13/2021 10:56:18 - INFO - __main__ -   loss = 0.4620473662018776\n","08/13/2021 10:56:18 - INFO - __main__ -   Current data iter size: 2571\n","08/13/2021 10:56:18 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 10:56:35 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 10:56:35 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 10:56:35 - INFO - __main__ -     Batch size = 64\n","08/13/2021 11:05:02 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 11:05:02 - INFO - __main__ -     map = 0.7733191127472446\n","08/13/2021 11:05:04 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 108600 length of sample 0\n","08/13/2021 11:10:04 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/13/2021 11:10:05 - INFO - __main__ -    global_step = 2572, average loss = 0.4361498852725348\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bPPm7l4vz_4E","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7566581c-43fa-411f-8524-832a32317cf6"},"source":["# mantis root_5 \n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 2\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_2 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.995\\\n","    --noise_difficult_ratio 0.66\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/13/2021 11:10:16 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/13/2021 11:10:16 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 11:10:16 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/13/2021 11:10:17 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 11:10:17 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 11:10:31 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/13/2021 11:10:31 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/13/2021 11:10:35 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=0.66, noise_lambda=0.995, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_2', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2', save_aps=False, save_steps=5000, seed=2, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/13/2021 11:10:35 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/13/2021 11:10:55 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/13/2021 11:10:57 - INFO - __main__ -   ***** Running training *****\n","08/13/2021 11:10:57 - INFO - __main__ -     Num examples = 164544\n","08/13/2021 11:10:57 - INFO - __main__ -     Num Epochs = 1\n","08/13/2021 11:10:57 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/13/2021 11:10:57 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/13/2021 11:10:57 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/13/2021 11:10:57 - INFO - __main__ -     Total optimization steps = 2571\n","08/13/2021 11:10:57 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/13/2021 11:10:57 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7fb0fb3b3e90>)]\n","08/13/2021 11:10:57 - INFO - __main__ -   Starting epoch 1\n","08/13/2021 11:10:57 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/13/2021 11:19:22 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/13/2021 11:19:22 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/13/2021 11:19:22 - INFO - __main__ -   loss = 0.5504336726665496\n","08/13/2021 11:19:22 - INFO - __main__ -   Current data iter size: 1717\n","08/13/2021 11:19:22 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 11:19:39 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 11:19:39 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 11:19:39 - INFO - __main__ -     Batch size = 64\n","08/13/2021 11:28:05 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 11:28:05 - INFO - __main__ -     map = 0.727007579842315\n","08/13/2021 11:28:06 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 108600 length of sample 24435\n","08/13/2021 11:36:37 - INFO - __main__ -   Iter = 600\n","08/13/2021 11:36:37 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/13/2021 11:36:37 - INFO - __main__ -   loss = 0.3960349717239539\n","08/13/2021 11:36:37 - INFO - __main__ -   Current data iter size: 1967\n","08/13/2021 11:36:37 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 11:36:54 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 11:36:54 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 11:36:54 - INFO - __main__ -     Batch size = 64\n","08/13/2021 11:45:22 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 11:45:22 - INFO - __main__ -     map = 0.7362202534890993\n","08/13/2021 11:45:23 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 108600 length of sample 6220\n","08/13/2021 11:53:58 - INFO - __main__ -   Iter = 900\n","08/13/2021 11:53:58 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/13/2021 11:53:58 - INFO - __main__ -   loss = 0.3890511413415273\n","08/13/2021 11:53:58 - INFO - __main__ -   Current data iter size: 2131\n","08/13/2021 11:53:58 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 11:54:15 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 11:54:15 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 11:54:15 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:02:44 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:02:44 - INFO - __main__ -     map = 0.746916692111885\n","08/13/2021 12:02:46 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 108600 length of sample 1498\n","08/13/2021 12:11:22 - INFO - __main__ -   Iter = 1200\n","08/13/2021 12:11:22 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/13/2021 12:11:22 - INFO - __main__ -   loss = 0.4014387689034144\n","08/13/2021 12:11:22 - INFO - __main__ -   Current data iter size: 2256\n","08/13/2021 12:11:22 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 12:11:39 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 12:11:39 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 12:11:39 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:20:06 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:20:06 - INFO - __main__ -     map = 0.7600049483330554\n","08/13/2021 12:20:08 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 108600 length of sample 352\n","08/13/2021 12:28:47 - INFO - __main__ -   Iter = 1500\n","08/13/2021 12:28:47 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/13/2021 12:28:47 - INFO - __main__ -   loss = 0.4091579878826936\n","08/13/2021 12:28:47 - INFO - __main__ -   Current data iter size: 2359\n","08/13/2021 12:28:47 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 12:29:03 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 12:29:03 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 12:29:03 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:37:32 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:37:32 - INFO - __main__ -     map = 0.7505051276428117\n","QC: length of D 108600 length of sample 81\n","08/13/2021 12:46:14 - INFO - __main__ -   Iter = 1800\n","08/13/2021 12:46:14 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/13/2021 12:46:14 - INFO - __main__ -   loss = 0.42732630530993143\n","08/13/2021 12:46:14 - INFO - __main__ -   Current data iter size: 2446\n","08/13/2021 12:46:14 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 12:46:30 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 12:46:30 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 12:46:30 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:54:59 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:54:59 - INFO - __main__ -     map = 0.7653444729662665\n","08/13/2021 12:55:00 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 108600 length of sample 18\n","08/13/2021 13:03:47 - INFO - __main__ -   Iter = 2100\n","08/13/2021 13:03:47 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/13/2021 13:03:47 - INFO - __main__ -   loss = 0.4423773114879926\n","08/13/2021 13:03:47 - INFO - __main__ -   Current data iter size: 2522\n","08/13/2021 13:03:47 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 13:04:05 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 13:04:05 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 13:04:05 - INFO - __main__ -     Batch size = 64\n","08/13/2021 13:12:33 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 13:12:33 - INFO - __main__ -     map = 0.7701986649775316\n","08/13/2021 13:12:34 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 108600 length of sample 4\n","08/13/2021 13:21:17 - INFO - __main__ -   Iter = 2400\n","08/13/2021 13:21:17 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/13/2021 13:21:17 - INFO - __main__ -   loss = 0.4717008156577746\n","08/13/2021 13:21:17 - INFO - __main__ -   Current data iter size: 2571\n","08/13/2021 13:21:17 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 13:21:34 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 13:21:34 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 13:21:34 - INFO - __main__ -     Batch size = 64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Dotnsb3BJwiA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628954035214,"user_tz":-120,"elapsed":8512316,"user":{"displayName":"T. Z.","photoUrl":"","userId":"04670299702794629529"}},"outputId":"7c8dd0ec-caa0-4877-8151-dab28771c5c5"},"source":["!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 3\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_3 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.995\\\n","    --noise_difficult_ratio 0.66\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/14/2021 12:52:06 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/14/2021 12:52:06 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmp5sfu0c6h\n","100% 433/433 [00:00<00:00, 468679.65B/s]\n","08/14/2021 12:52:07 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp5sfu0c6h to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 12:52:07 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 12:52:07 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp5sfu0c6h\n","08/14/2021 12:52:07 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 12:52:07 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/14/2021 12:52:07 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpbcqus4i5\n","100% 231508/231508 [00:00<00:00, 863770.10B/s]\n","08/14/2021 12:52:08 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpbcqus4i5 to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 12:52:08 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 12:52:08 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpbcqus4i5\n","08/14/2021 12:52:08 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 12:52:08 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpic38duhi\n","100% 440473133/440473133 [00:12<00:00, 36219420.08B/s]\n","08/14/2021 12:52:20 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpic38duhi to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 12:52:22 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 12:52:22 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpic38duhi\n","08/14/2021 12:52:22 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 12:52:25 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/14/2021 12:52:25 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/14/2021 12:52:36 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=0.66, noise_lambda=0.995, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_3', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3', save_aps=False, save_steps=5000, seed=3, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/14/2021 12:52:36 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/14/2021 12:52:56 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/14/2021 12:52:59 - INFO - __main__ -   ***** Running training *****\n","08/14/2021 12:52:59 - INFO - __main__ -     Num examples = 164544\n","08/14/2021 12:52:59 - INFO - __main__ -     Num Epochs = 1\n","08/14/2021 12:52:59 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/14/2021 12:52:59 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/14/2021 12:52:59 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/14/2021 12:52:59 - INFO - __main__ -     Total optimization steps = 2571\n","08/14/2021 12:52:59 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/14/2021 12:52:59 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7f464e920f90>)]\n","08/14/2021 12:52:59 - INFO - __main__ -   Starting epoch 1\n","08/14/2021 12:52:59 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/14/2021 13:01:11 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/14/2021 13:01:11 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/14/2021 13:01:11 - INFO - __main__ -   loss = 0.5537861934304238\n","08/14/2021 13:01:11 - INFO - __main__ -   Current data iter size: 1717\n","08/14/2021 13:01:11 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 13:01:29 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 13:01:29 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 13:01:29 - INFO - __main__ -     Batch size = 64\n","08/14/2021 13:09:46 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 13:09:46 - INFO - __main__ -     map = 0.7235627159928567\n","08/14/2021 13:09:47 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 108600 length of sample 24435\n","08/14/2021 13:18:09 - INFO - __main__ -   Iter = 600\n","08/14/2021 13:18:09 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/14/2021 13:18:09 - INFO - __main__ -   loss = 0.39291020835439366\n","08/14/2021 13:18:09 - INFO - __main__ -   Current data iter size: 1967\n","08/14/2021 13:18:09 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 13:18:25 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 13:18:25 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 13:18:25 - INFO - __main__ -     Batch size = 64\n","08/14/2021 13:26:42 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 13:26:42 - INFO - __main__ -     map = 0.7283064209971597\n","08/14/2021 13:26:44 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 108600 length of sample 6220\n","08/14/2021 13:35:08 - INFO - __main__ -   Iter = 900\n","08/14/2021 13:35:08 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/14/2021 13:35:08 - INFO - __main__ -   loss = 0.384280409514904\n","08/14/2021 13:35:08 - INFO - __main__ -   Current data iter size: 2131\n","08/14/2021 13:35:08 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 13:35:24 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 13:35:24 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 13:35:24 - INFO - __main__ -     Batch size = 64\n","08/14/2021 13:43:41 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 13:43:41 - INFO - __main__ -     map = 0.758523407943975\n","08/14/2021 13:43:43 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 108600 length of sample 1498\n","08/14/2021 13:52:09 - INFO - __main__ -   Iter = 1200\n","08/14/2021 13:52:09 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/14/2021 13:52:09 - INFO - __main__ -   loss = 0.39854502017299337\n","08/14/2021 13:52:09 - INFO - __main__ -   Current data iter size: 2256\n","08/14/2021 13:52:09 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 13:52:26 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 13:52:26 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 13:52:26 - INFO - __main__ -     Batch size = 64\n","08/14/2021 14:00:42 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 14:00:42 - INFO - __main__ -     map = 0.7604652071793878\n","08/14/2021 14:00:44 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 108600 length of sample 352\n","08/14/2021 14:09:12 - INFO - __main__ -   Iter = 1500\n","08/14/2021 14:09:12 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/14/2021 14:09:12 - INFO - __main__ -   loss = 0.41101360072692233\n","08/14/2021 14:09:12 - INFO - __main__ -   Current data iter size: 2359\n","08/14/2021 14:09:12 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 14:09:28 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 14:09:28 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 14:09:28 - INFO - __main__ -     Batch size = 64\n","08/14/2021 14:17:43 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 14:17:43 - INFO - __main__ -     map = 0.7614575580923268\n","08/14/2021 14:17:45 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 108600 length of sample 81\n","08/14/2021 14:26:14 - INFO - __main__ -   Iter = 1800\n","08/14/2021 14:26:14 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/14/2021 14:26:14 - INFO - __main__ -   loss = 0.4204908061027527\n","08/14/2021 14:26:14 - INFO - __main__ -   Current data iter size: 2446\n","08/14/2021 14:26:14 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 14:26:31 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 14:26:31 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 14:26:31 - INFO - __main__ -     Batch size = 64\n","08/14/2021 14:34:46 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 14:34:46 - INFO - __main__ -     map = 0.7568618684559217\n","QC: length of D 108600 length of sample 18\n","08/14/2021 14:43:16 - INFO - __main__ -   Iter = 2100\n","08/14/2021 14:43:16 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/14/2021 14:43:16 - INFO - __main__ -   loss = 0.4457007971405983\n","08/14/2021 14:43:16 - INFO - __main__ -   Current data iter size: 2522\n","08/14/2021 14:43:16 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 14:43:33 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 14:43:33 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 14:43:33 - INFO - __main__ -     Batch size = 64\n","08/14/2021 14:51:50 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 14:51:50 - INFO - __main__ -     map = 0.767848946982713\n","08/14/2021 14:51:51 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 108600 length of sample 4\n","08/14/2021 15:00:22 - INFO - __main__ -   Iter = 2400\n","08/14/2021 15:00:22 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/14/2021 15:00:22 - INFO - __main__ -   loss = 0.4614320742090543\n","08/14/2021 15:00:22 - INFO - __main__ -   Current data iter size: 2571\n","08/14/2021 15:00:22 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 15:00:39 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 15:00:39 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 15:00:39 - INFO - __main__ -     Batch size = 64\n","08/14/2021 15:08:56 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 15:08:56 - INFO - __main__ -     map = 0.7728748683934721\n","08/14/2021 15:08:57 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_66_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 108600 length of sample 0\n","08/14/2021 15:13:51 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/14/2021 15:13:51 - INFO - __main__ -    global_step = 2572, average loss = 0.4351433362481568\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"q48JUnLsI9gv"},"source":["# mantis root_5 with lamdba = 0.999, d_ratio = 0.66 noise"]},{"cell_type":"code","metadata":{"id":"zsgh1dgdjQLm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628858950793,"user_tz":-120,"elapsed":8059239,"user":{"displayName":"长安故里","photoUrl":"","userId":"04762263270908229891"}},"outputId":"3f614efc-7bc8-4dfd-f5f2-27250e9fbb06"},"source":["# mantis root_5 \n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 1\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_999_r_66_seed_1 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.999\\\n","    --noise_difficult_ratio 0.66\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/13/2021 10:34:56 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/13/2021 10:34:56 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpnbktpcuk\n","100% 433/433 [00:00<00:00, 500864.21B/s]\n","08/13/2021 10:34:57 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpnbktpcuk to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 10:34:57 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 10:34:57 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpnbktpcuk\n","08/13/2021 10:34:57 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 10:34:57 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/13/2021 10:34:57 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpt86ftept\n","100% 231508/231508 [00:00<00:00, 947203.19B/s]\n","08/13/2021 10:34:57 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpt86ftept to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 10:34:57 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 10:34:57 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpt86ftept\n","08/13/2021 10:34:57 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 10:34:58 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpur4ynrmy\n","100% 440473133/440473133 [00:12<00:00, 36368528.50B/s]\n","08/13/2021 10:35:10 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpur4ynrmy to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 10:35:12 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 10:35:12 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpur4ynrmy\n","08/13/2021 10:35:12 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 10:35:14 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/13/2021 10:35:14 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/13/2021 10:35:26 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=0.66, noise_lambda=0.999, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_999_r_66_seed_1', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1', save_aps=False, save_steps=5000, seed=1, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/13/2021 10:35:26 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/13/2021 10:35:48 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/13/2021 10:35:51 - INFO - __main__ -   ***** Running training *****\n","08/13/2021 10:35:51 - INFO - __main__ -     Num examples = 164544\n","08/13/2021 10:35:51 - INFO - __main__ -     Num Epochs = 1\n","08/13/2021 10:35:51 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/13/2021 10:35:51 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/13/2021 10:35:51 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/13/2021 10:35:51 - INFO - __main__ -     Total optimization steps = 2571\n","08/13/2021 10:35:51 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/13/2021 10:35:51 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7fa3e0d06810>)]\n","08/13/2021 10:35:51 - INFO - __main__ -   Starting epoch 1\n","08/13/2021 10:35:51 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/13/2021 10:43:31 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/13/2021 10:43:31 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/13/2021 10:43:31 - INFO - __main__ -   loss = 0.6365241694450379\n","08/13/2021 10:43:31 - INFO - __main__ -   Current data iter size: 1717\n","08/13/2021 10:43:31 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 10:43:51 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 10:43:51 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 10:43:51 - INFO - __main__ -     Batch size = 64\n","08/13/2021 10:51:34 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 10:51:34 - INFO - __main__ -     map = 0.7359743341686631\n","08/13/2021 10:51:35 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_66_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 108600 length of sample 81420\n","08/13/2021 10:59:35 - INFO - __main__ -   Iter = 600\n","08/13/2021 10:59:35 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/13/2021 10:59:35 - INFO - __main__ -   loss = 0.5715864537159602\n","08/13/2021 10:59:35 - INFO - __main__ -   Current data iter size: 1967\n","08/13/2021 10:59:35 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 10:59:51 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 10:59:51 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 10:59:51 - INFO - __main__ -     Batch size = 64\n","08/13/2021 11:07:33 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 11:07:33 - INFO - __main__ -     map = 0.7423891473908663\n","08/13/2021 11:07:35 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_66_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 108600 length of sample 69071\n","08/13/2021 11:15:38 - INFO - __main__ -   Iter = 900\n","08/13/2021 11:15:38 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/13/2021 11:15:38 - INFO - __main__ -   loss = 0.5214303214351336\n","08/13/2021 11:15:38 - INFO - __main__ -   Current data iter size: 2131\n","08/13/2021 11:15:38 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 11:15:54 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 11:15:54 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 11:15:54 - INFO - __main__ -     Batch size = 64\n","08/13/2021 11:23:37 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 11:23:37 - INFO - __main__ -     map = 0.7468240062262731\n","08/13/2021 11:23:39 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_66_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 108600 length of sample 55428\n","08/13/2021 11:31:44 - INFO - __main__ -   Iter = 1200\n","08/13/2021 11:31:44 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/13/2021 11:31:44 - INFO - __main__ -   loss = 0.5043328199783961\n","08/13/2021 11:31:44 - INFO - __main__ -   Current data iter size: 2256\n","08/13/2021 11:31:44 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 11:32:02 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 11:32:02 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 11:32:02 - INFO - __main__ -     Batch size = 64\n","08/13/2021 11:39:46 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 11:39:46 - INFO - __main__ -     map = 0.7619563088828116\n","08/13/2021 11:39:47 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_66_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 108600 length of sample 43466\n","08/13/2021 11:47:54 - INFO - __main__ -   Iter = 1500\n","08/13/2021 11:47:54 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/13/2021 11:47:54 - INFO - __main__ -   loss = 0.472451295653979\n","08/13/2021 11:47:54 - INFO - __main__ -   Current data iter size: 2359\n","08/13/2021 11:47:54 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 11:48:11 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 11:48:11 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 11:48:11 - INFO - __main__ -     Batch size = 64\n","08/13/2021 11:55:54 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 11:55:54 - INFO - __main__ -     map = 0.7610957065824864\n","QC: length of D 108600 length of sample 33654\n","08/13/2021 12:04:02 - INFO - __main__ -   Iter = 1800\n","08/13/2021 12:04:02 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/13/2021 12:04:02 - INFO - __main__ -   loss = 0.472985379199187\n","08/13/2021 12:04:02 - INFO - __main__ -   Current data iter size: 2446\n","08/13/2021 12:04:02 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 12:04:18 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 12:04:18 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 12:04:18 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:12:01 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:12:01 - INFO - __main__ -     map = 0.7744064518830407\n","08/13/2021 12:12:03 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_66_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 108600 length of sample 25848\n","08/13/2021 12:20:13 - INFO - __main__ -   Iter = 2100\n","08/13/2021 12:20:13 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/13/2021 12:20:13 - INFO - __main__ -   loss = 0.47693454017241793\n","08/13/2021 12:20:13 - INFO - __main__ -   Current data iter size: 2522\n","08/13/2021 12:20:13 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 12:20:30 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 12:20:30 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 12:20:30 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:28:13 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:28:13 - INFO - __main__ -     map = 0.7636824295868034\n","QC: length of D 108600 length of sample 19743\n","08/13/2021 12:36:25 - INFO - __main__ -   Iter = 2400\n","08/13/2021 12:36:25 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/13/2021 12:36:25 - INFO - __main__ -   loss = 0.4713360923528671\n","08/13/2021 12:36:25 - INFO - __main__ -   Current data iter size: 2571\n","08/13/2021 12:36:25 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 12:36:42 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 12:36:42 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 12:36:42 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:44:26 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:44:26 - INFO - __main__ -     map = 0.7635546391906375\n","QC: length of D 108600 length of sample 14909\n","08/13/2021 12:49:08 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/13/2021 12:49:08 - INFO - __main__ -    global_step = 2572, average loss = 0.512722668262607\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_CKvwGhoKIZv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"536a2af7-944b-411b-b916-da406f9d805f"},"source":["# mantis root_5 \n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 2\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_999_r_66_seed_2 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.999\\\n","    --noise_difficult_ratio 0.66\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/13/2021 12:57:41 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/13/2021 12:57:42 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 12:57:42 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/13/2021 12:57:42 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 12:57:42 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 12:57:53 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/13/2021 12:57:53 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/13/2021 12:57:57 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=0.66, noise_lambda=0.999, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_999_r_66_seed_2', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2', save_aps=False, save_steps=5000, seed=2, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/13/2021 12:57:57 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/13/2021 12:58:16 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/13/2021 12:58:18 - INFO - __main__ -   ***** Running training *****\n","08/13/2021 12:58:18 - INFO - __main__ -     Num examples = 164544\n","08/13/2021 12:58:18 - INFO - __main__ -     Num Epochs = 1\n","08/13/2021 12:58:18 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/13/2021 12:58:18 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/13/2021 12:58:18 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/13/2021 12:58:18 - INFO - __main__ -     Total optimization steps = 2571\n","08/13/2021 12:58:18 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/13/2021 12:58:18 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7fd12de9be90>)]\n","08/13/2021 12:58:18 - INFO - __main__ -   Starting epoch 1\n","08/13/2021 12:58:18 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/13/2021 13:06:05 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/13/2021 13:06:05 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/13/2021 13:06:05 - INFO - __main__ -   loss = 0.6434420998891195\n","08/13/2021 13:06:05 - INFO - __main__ -   Current data iter size: 1717\n","08/13/2021 13:06:05 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 13:06:23 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 13:06:23 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 13:06:23 - INFO - __main__ -     Batch size = 64\n","08/13/2021 13:14:07 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 13:14:07 - INFO - __main__ -     map = 0.7286713867985757\n","08/13/2021 13:14:09 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_66_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 108600 length of sample 81420\n","08/13/2021 13:22:08 - INFO - __main__ -   Iter = 600\n","08/13/2021 13:22:08 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/13/2021 13:22:08 - INFO - __main__ -   loss = 0.5701481252908707\n","08/13/2021 13:22:08 - INFO - __main__ -   Current data iter size: 1967\n","08/13/2021 13:22:08 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 13:22:25 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 13:22:25 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 13:22:25 - INFO - __main__ -     Batch size = 64\n","08/13/2021 13:30:10 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 13:30:10 - INFO - __main__ -     map = 0.7335437497511117\n","08/13/2021 13:30:13 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_66_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 108600 length of sample 69071\n","08/13/2021 13:38:16 - INFO - __main__ -   Iter = 900\n","08/13/2021 13:38:16 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/13/2021 13:38:16 - INFO - __main__ -   loss = 0.5205939332644145\n","08/13/2021 13:38:16 - INFO - __main__ -   Current data iter size: 2131\n","08/13/2021 13:38:16 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 13:38:32 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 13:38:32 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 13:38:32 - INFO - __main__ -     Batch size = 64\n","08/13/2021 13:46:16 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 13:46:16 - INFO - __main__ -     map = 0.7461780195516503\n","08/13/2021 13:46:18 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_66_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 108600 length of sample 55428\n","08/13/2021 13:54:23 - INFO - __main__ -   Iter = 1200\n","08/13/2021 13:54:23 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/13/2021 13:54:23 - INFO - __main__ -   loss = 0.49720561226209004\n","08/13/2021 13:54:23 - INFO - __main__ -   Current data iter size: 2256\n","08/13/2021 13:54:23 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 13:54:40 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 13:54:40 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 13:54:40 - INFO - __main__ -     Batch size = 64\n","08/13/2021 14:02:25 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 14:02:25 - INFO - __main__ -     map = 0.7547642537934535\n","08/13/2021 14:02:26 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_66_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 108600 length of sample 43466\n","08/13/2021 14:10:33 - INFO - __main__ -   Iter = 1500\n","08/13/2021 14:10:33 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/13/2021 14:10:33 - INFO - __main__ -   loss = 0.47619552989800773\n","08/13/2021 14:10:33 - INFO - __main__ -   Current data iter size: 2359\n","08/13/2021 14:10:33 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 14:10:49 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 14:10:49 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 14:10:49 - INFO - __main__ -     Batch size = 64\n","08/13/2021 14:18:33 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 14:18:33 - INFO - __main__ -     map = 0.7541513636483685\n","QC: length of D 108600 length of sample 33654\n","08/13/2021 14:26:40 - INFO - __main__ -   Iter = 1800\n","08/13/2021 14:26:40 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/13/2021 14:26:40 - INFO - __main__ -   loss = 0.47285672565301257\n","08/13/2021 14:26:40 - INFO - __main__ -   Current data iter size: 2446\n","08/13/2021 14:26:40 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 14:26:58 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 14:26:58 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 14:26:58 - INFO - __main__ -     Batch size = 64\n","08/13/2021 14:34:42 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 14:34:42 - INFO - __main__ -     map = 0.7533425937869482\n","QC: length of D 108600 length of sample 25848\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vp0DZQh5KJHu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d7fc9db0-8e38-4761-e7d2-05a9c80c1627"},"source":["# mantis root_5 \n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 3\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_999_r_66_seed_3 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.999\\\n","    --noise_difficult_ratio 0.66\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/14/2021 12:53:03 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/14/2021 12:53:03 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpjg8ssztv\n","100% 433/433 [00:00<00:00, 544404.57B/s]\n","08/14/2021 12:53:04 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpjg8ssztv to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 12:53:04 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 12:53:04 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpjg8ssztv\n","08/14/2021 12:53:04 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 12:53:04 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/14/2021 12:53:04 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpuh6s6tgn\n","100% 231508/231508 [00:00<00:00, 950880.98B/s]\n","08/14/2021 12:53:04 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpuh6s6tgn to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 12:53:04 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 12:53:04 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpuh6s6tgn\n","08/14/2021 12:53:04 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 12:53:05 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmp0xxu8rx3\n","100% 440473133/440473133 [00:11<00:00, 38594377.33B/s]\n","08/14/2021 12:53:16 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp0xxu8rx3 to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 12:53:17 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 12:53:17 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp0xxu8rx3\n","08/14/2021 12:53:17 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 12:53:21 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/14/2021 12:53:21 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/14/2021 12:53:32 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=0.66, noise_lambda=0.999, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_999_r_66_seed_3', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3', save_aps=False, save_steps=5000, seed=3, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/14/2021 12:53:32 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/14/2021 12:53:54 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/14/2021 12:53:57 - INFO - __main__ -   ***** Running training *****\n","08/14/2021 12:53:57 - INFO - __main__ -     Num examples = 164544\n","08/14/2021 12:53:57 - INFO - __main__ -     Num Epochs = 1\n","08/14/2021 12:53:57 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/14/2021 12:53:57 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/14/2021 12:53:57 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/14/2021 12:53:57 - INFO - __main__ -     Total optimization steps = 2571\n","08/14/2021 12:53:57 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/14/2021 12:53:57 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7fc51e5e5890>)]\n","08/14/2021 12:53:57 - INFO - __main__ -   Starting epoch 1\n","08/14/2021 12:53:57 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/14/2021 13:02:05 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/14/2021 13:02:05 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/14/2021 13:02:05 - INFO - __main__ -   loss = 0.6378567592302958\n","08/14/2021 13:02:05 - INFO - __main__ -   Current data iter size: 1717\n","08/14/2021 13:02:05 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 13:02:26 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 13:02:26 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 13:02:26 - INFO - __main__ -     Batch size = 64\n","08/14/2021 13:10:42 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 13:10:42 - INFO - __main__ -     map = 0.730709945732877\n","08/14/2021 13:10:44 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_66_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 108600 length of sample 81420\n","08/14/2021 13:19:04 - INFO - __main__ -   Iter = 600\n","08/14/2021 13:19:04 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/14/2021 13:19:04 - INFO - __main__ -   loss = 0.5601990985870361\n","08/14/2021 13:19:04 - INFO - __main__ -   Current data iter size: 1967\n","08/14/2021 13:19:04 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 13:19:21 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 13:19:21 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 13:19:21 - INFO - __main__ -     Batch size = 64\n","08/14/2021 13:27:37 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 13:27:37 - INFO - __main__ -     map = 0.7424467258564647\n","08/14/2021 13:27:39 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_66_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 108600 length of sample 69071\n","08/14/2021 13:36:03 - INFO - __main__ -   Iter = 900\n","08/14/2021 13:36:03 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/14/2021 13:36:03 - INFO - __main__ -   loss = 0.5254596031705538\n","08/14/2021 13:36:03 - INFO - __main__ -   Current data iter size: 2131\n","08/14/2021 13:36:03 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 13:36:20 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 13:36:20 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 13:36:20 - INFO - __main__ -     Batch size = 64\n","08/14/2021 13:44:35 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 13:44:35 - INFO - __main__ -     map = 0.7467156594659645\n","08/14/2021 13:44:37 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_66_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 108600 length of sample 55428\n","08/14/2021 13:53:03 - INFO - __main__ -   Iter = 1200\n","08/14/2021 13:53:03 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/14/2021 13:53:03 - INFO - __main__ -   loss = 0.4982395232717196\n","08/14/2021 13:53:03 - INFO - __main__ -   Current data iter size: 2256\n","08/14/2021 13:53:03 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 13:53:21 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 13:53:21 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 13:53:21 - INFO - __main__ -     Batch size = 64\n","08/14/2021 14:01:37 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 14:01:37 - INFO - __main__ -     map = 0.7515360531132861\n","08/14/2021 14:01:38 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_66_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 108600 length of sample 43466\n","08/14/2021 14:10:06 - INFO - __main__ -   Iter = 1500\n","08/14/2021 14:10:06 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/14/2021 14:10:06 - INFO - __main__ -   loss = 0.48111465166012446\n","08/14/2021 14:10:06 - INFO - __main__ -   Current data iter size: 2359\n","08/14/2021 14:10:06 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 14:10:22 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 14:10:22 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 14:10:22 - INFO - __main__ -     Batch size = 64\n","08/14/2021 14:18:38 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 14:18:38 - INFO - __main__ -     map = 0.7670317346050336\n","08/14/2021 14:18:40 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_999_r_66_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 108600 length of sample 33654\n","08/14/2021 14:27:11 - INFO - __main__ -   Iter = 1800\n","08/14/2021 14:27:11 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/14/2021 14:27:11 - INFO - __main__ -   loss = 0.4693017760912577\n","08/14/2021 14:27:11 - INFO - __main__ -   Current data iter size: 2446\n","08/14/2021 14:27:11 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 14:27:28 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 14:27:28 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 14:27:28 - INFO - __main__ -     Batch size = 64\n","08/14/2021 14:35:44 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 14:35:44 - INFO - __main__ -     map = 0.7622904055561393\n","QC: length of D 108600 length of sample 25848\n"],"name":"stdout"}]}]}