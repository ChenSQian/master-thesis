{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"noise_transformercl_05.ipynb","provenance":[{"file_id":"1Gslqz9zqY_JDqJzzm03bUiIUaQ2brtoc","timestamp":1628843384918},{"file_id":"1JPdZJDI3EfwNR9DB4D8nQEv-kDUdhyqc","timestamp":1623066561753},{"file_id":"1MR6fqyFJ0F0CvZ_prOyG8prQRr9h1zwL","timestamp":1621518416179}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"CgncrxE8FEY-"},"source":["function KeepClicking(){\n","console.log(\"Clicking\");\n","document.querySelector(\"colab-connect-button\").click()\n","}\n","setInterval(KeepClicking,60000)\n","Open your Chrome DevTools by pressing F12 or ctrl+shift+i on Linux and enter the following JavaScript snippet in your console:"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1QWVTurKCTMV","executionInfo":{"status":"ok","timestamp":1628936502683,"user_tz":-120,"elapsed":17934,"user":{"displayName":"王梦琪","photoUrl":"","userId":"17110178610712270742"}},"outputId":"038ab865-41a6-4087-97c6-a2259ff27090"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0q-7RWqYrMbI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628936567096,"user_tz":-120,"elapsed":10305,"user":{"displayName":"王梦琪","photoUrl":"","userId":"17110178610712270742"}},"outputId":"ebeb088e-bf30-474d-b9b4-7d623182502a"},"source":["# install transformers\n","!pip install pytorch_transformers\n","# Mount google drive\n","!pip install -r drive/MyDrive/transformers_cl/requirements.txt"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting pytorch_transformers\n","  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n","\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 19.1 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 23.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 176 kB 8.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (4.62.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 58.8 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.9.0+cu102)\n","Collecting boto3\n","  Downloading boto3-1.18.21-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 72.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 75.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.7.4.3)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 11.2 MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting botocore<1.22.0,>=1.21.21\n","  Downloading botocore-1.21.21-py3-none-any.whl (7.8 MB)\n","\u001b[K     |████████████████████████████████| 7.8 MB 60.1 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.21->boto3->pytorch_transformers) (2.8.2)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 76.2 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->pytorch_transformers) (1.15.0)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 70.4 MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2021.5.30)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.0.1)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3, pytorch-transformers\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.18.21 botocore-1.21.21 jmespath-0.10.0 pytorch-transformers-1.2.0 s3transfer-0.5.0 sacremoses-0.0.45 sentencepiece-0.1.96 urllib3-1.25.11\n","Collecting tensorboardX\n","  Downloading tensorboardX-2.4-py2.py3-none-any.whl (124 kB)\n","\u001b[K     |████████████████████████████████| 124 kB 8.9 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r drive/MyDrive/transformers_cl/requirements.txt (line 2)) (0.22.2.post1)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from -r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (5.5.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->-r drive/MyDrive/transformers_cl/requirements.txt (line 1)) (3.17.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX->-r drive/MyDrive/transformers_cl/requirements.txt (line 1)) (1.19.5)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX->-r drive/MyDrive/transformers_cl/requirements.txt (line 1)) (1.15.0)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r drive/MyDrive/transformers_cl/requirements.txt (line 2)) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r drive/MyDrive/transformers_cl/requirements.txt (line 2)) (1.0.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (1.0.18)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (4.8.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (5.0.5)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (57.2.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (2.6.1)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (0.8.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (0.7.5)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (4.4.2)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (0.2.5)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (0.2.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->-r drive/MyDrive/transformers_cl/requirements.txt (line 3)) (0.7.0)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gYNN5sk9-7z8"},"source":["# mantis root_5 with lamdba = 0.99, d_ratio = 0.5 noise"]},{"cell_type":"code","metadata":{"id":"dCjVt5gn-7z9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628852348974,"user_tz":-120,"elapsed":8214159,"user":{"displayName":"xiaokang qian","photoUrl":"","userId":"16136989389156139825"}},"outputId":"fb870c19-cc37-49bf-9c3a-7d4f4239d818"},"source":["# mantison drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 1\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_1 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.99\\\n","    --noise_difficult_ratio 0.5\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/13/2021 08:42:19 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/13/2021 08:42:20 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpvo9c1lqi\n","100% 433/433 [00:00<00:00, 411635.00B/s]\n","08/13/2021 08:42:20 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpvo9c1lqi to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 08:42:20 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 08:42:20 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpvo9c1lqi\n","08/13/2021 08:42:20 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 08:42:20 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/13/2021 08:42:20 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp0pzqj1sg\n","100% 231508/231508 [00:00<00:00, 875509.14B/s]\n","08/13/2021 08:42:21 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp0pzqj1sg to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 08:42:21 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 08:42:21 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp0pzqj1sg\n","08/13/2021 08:42:21 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 08:42:21 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpmuf3mbb4\n","100% 440473133/440473133 [00:13<00:00, 33469541.45B/s]\n","08/13/2021 08:42:35 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpmuf3mbb4 to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 08:42:36 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 08:42:36 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpmuf3mbb4\n","08/13/2021 08:42:36 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 08:42:39 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/13/2021 08:42:39 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/13/2021 08:42:51 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=0.5, noise_lambda=0.99, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_1', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1', save_aps=False, save_steps=5000, seed=1, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/13/2021 08:42:51 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/13/2021 08:43:12 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/13/2021 08:43:14 - INFO - __main__ -   ***** Running training *****\n","08/13/2021 08:43:14 - INFO - __main__ -     Num examples = 164544\n","08/13/2021 08:43:14 - INFO - __main__ -     Num Epochs = 1\n","08/13/2021 08:43:14 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/13/2021 08:43:14 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/13/2021 08:43:14 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/13/2021 08:43:14 - INFO - __main__ -     Total optimization steps = 2571\n","08/13/2021 08:43:14 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/13/2021 08:43:14 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7fda2ac76850>)]\n","08/13/2021 08:43:14 - INFO - __main__ -   Starting epoch 1\n","08/13/2021 08:43:14 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/13/2021 08:51:04 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/13/2021 08:51:04 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/13/2021 08:51:04 - INFO - __main__ -   loss = 0.49462632621328034\n","08/13/2021 08:51:04 - INFO - __main__ -   Current data iter size: 1717\n","08/13/2021 08:51:04 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 08:51:24 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 08:51:24 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 08:51:24 - INFO - __main__ -     Batch size = 64\n","08/13/2021 08:59:18 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 08:59:18 - INFO - __main__ -     map = 0.7250790560647437\n","08/13/2021 08:59:21 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 82272 length of sample 5390\n","08/13/2021 09:07:27 - INFO - __main__ -   Iter = 600\n","08/13/2021 09:07:27 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/13/2021 09:07:27 - INFO - __main__ -   loss = 0.35428997586170835\n","08/13/2021 09:07:27 - INFO - __main__ -   Current data iter size: 1967\n","08/13/2021 09:07:27 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 09:07:43 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 09:07:43 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 09:07:43 - INFO - __main__ -     Batch size = 64\n","08/13/2021 09:15:38 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 09:15:38 - INFO - __main__ -     map = 0.7503286977107759\n","08/13/2021 09:15:40 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 82272 length of sample 302\n","08/13/2021 09:23:48 - INFO - __main__ -   Iter = 900\n","08/13/2021 09:23:48 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/13/2021 09:23:48 - INFO - __main__ -   loss = 0.37351620450615886\n","08/13/2021 09:23:48 - INFO - __main__ -   Current data iter size: 2131\n","08/13/2021 09:23:48 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 09:24:05 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 09:24:05 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 09:24:05 - INFO - __main__ -     Batch size = 64\n","08/13/2021 09:31:59 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 09:31:59 - INFO - __main__ -     map = 0.7576821595106134\n","08/13/2021 09:32:02 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 82272 length of sample 16\n","08/13/2021 09:40:13 - INFO - __main__ -   Iter = 1200\n","08/13/2021 09:40:13 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/13/2021 09:40:13 - INFO - __main__ -   loss = 0.3979086909194787\n","08/13/2021 09:40:13 - INFO - __main__ -   Current data iter size: 2256\n","08/13/2021 09:40:13 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 09:40:29 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 09:40:29 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 09:40:29 - INFO - __main__ -     Batch size = 64\n","08/13/2021 09:48:23 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 09:48:23 - INFO - __main__ -     map = 0.7658128366188934\n","08/13/2021 09:48:25 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 82272 length of sample 0\n","08/13/2021 09:56:39 - INFO - __main__ -   Iter = 1500\n","08/13/2021 09:56:39 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/13/2021 09:56:39 - INFO - __main__ -   loss = 0.4102559783558051\n","08/13/2021 09:56:39 - INFO - __main__ -   Current data iter size: 2359\n","08/13/2021 09:56:39 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 09:56:55 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 09:56:55 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 09:56:55 - INFO - __main__ -     Batch size = 64\n","08/13/2021 10:04:50 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 10:04:50 - INFO - __main__ -     map = 0.7655558530711913\n","QC: length of D 82272 length of sample 0\n","08/13/2021 10:13:05 - INFO - __main__ -   Iter = 1800\n","08/13/2021 10:13:05 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/13/2021 10:13:05 - INFO - __main__ -   loss = 0.4279340460896492\n","08/13/2021 10:13:05 - INFO - __main__ -   Current data iter size: 2446\n","08/13/2021 10:13:05 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 10:13:21 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 10:13:21 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 10:13:21 - INFO - __main__ -     Batch size = 64\n","08/13/2021 10:21:15 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 10:21:15 - INFO - __main__ -     map = 0.7687303478336567\n","08/13/2021 10:21:17 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 82272 length of sample 0\n","08/13/2021 10:29:34 - INFO - __main__ -   Iter = 2100\n","08/13/2021 10:29:34 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/13/2021 10:29:34 - INFO - __main__ -   loss = 0.4341401024659475\n","08/13/2021 10:29:34 - INFO - __main__ -   Current data iter size: 2522\n","08/13/2021 10:29:34 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 10:29:52 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 10:29:52 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 10:29:52 - INFO - __main__ -     Batch size = 64\n","08/13/2021 10:37:46 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 10:37:46 - INFO - __main__ -     map = 0.770487508435062\n","08/13/2021 10:37:48 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 82272 length of sample 0\n","08/13/2021 10:46:08 - INFO - __main__ -   Iter = 2400\n","08/13/2021 10:46:08 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/13/2021 10:46:08 - INFO - __main__ -   loss = 0.4581138609846433\n","08/13/2021 10:46:08 - INFO - __main__ -   Current data iter size: 2571\n","08/13/2021 10:46:08 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 10:46:25 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 10:46:25 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 10:46:25 - INFO - __main__ -     Batch size = 64\n","08/13/2021 10:54:19 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 10:54:19 - INFO - __main__ -     map = 0.7646338925083016\n","QC: length of D 82272 length of sample 0\n","08/13/2021 10:59:05 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/13/2021 10:59:06 - INFO - __main__ -    global_step = 2572, average loss = 0.4211030008957879\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T0488mjpJEvL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628860711473,"user_tz":-120,"elapsed":8223262,"user":{"displayName":"xiaokang qian","photoUrl":"","userId":"16136989389156139825"}},"outputId":"218bfbc9-530a-49cd-9e3a-1fc77d3f2906"},"source":["!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 2\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_2 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.99\\\n","    --noise_difficult_ratio 0.5\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/13/2021 11:01:28 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/13/2021 11:01:29 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 11:01:29 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/13/2021 11:01:29 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 11:01:29 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 11:01:43 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/13/2021 11:01:43 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/13/2021 11:01:47 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=0.5, noise_lambda=0.99, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_2', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2', save_aps=False, save_steps=5000, seed=2, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/13/2021 11:01:47 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/13/2021 11:02:06 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/13/2021 11:02:09 - INFO - __main__ -   ***** Running training *****\n","08/13/2021 11:02:09 - INFO - __main__ -     Num examples = 164544\n","08/13/2021 11:02:09 - INFO - __main__ -     Num Epochs = 1\n","08/13/2021 11:02:09 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/13/2021 11:02:09 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/13/2021 11:02:09 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/13/2021 11:02:09 - INFO - __main__ -     Total optimization steps = 2571\n","08/13/2021 11:02:09 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/13/2021 11:02:09 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7f14fb637f50>)]\n","08/13/2021 11:02:09 - INFO - __main__ -   Starting epoch 1\n","08/13/2021 11:02:09 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/13/2021 11:10:04 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/13/2021 11:10:04 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/13/2021 11:10:04 - INFO - __main__ -   loss = 0.4934080841640631\n","08/13/2021 11:10:04 - INFO - __main__ -   Current data iter size: 1717\n","08/13/2021 11:10:04 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 11:10:21 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 11:10:21 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 11:10:21 - INFO - __main__ -     Batch size = 64\n","08/13/2021 11:18:17 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 11:18:17 - INFO - __main__ -     map = 0.7348724557275724\n","08/13/2021 11:18:18 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 82272 length of sample 5390\n","08/13/2021 11:26:24 - INFO - __main__ -   Iter = 600\n","08/13/2021 11:26:24 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/13/2021 11:26:24 - INFO - __main__ -   loss = 0.345998085240523\n","08/13/2021 11:26:24 - INFO - __main__ -   Current data iter size: 1967\n","08/13/2021 11:26:24 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 11:26:42 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 11:26:42 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 11:26:42 - INFO - __main__ -     Batch size = 64\n","08/13/2021 11:34:37 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 11:34:37 - INFO - __main__ -     map = 0.7440474662777246\n","08/13/2021 11:34:38 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 82272 length of sample 302\n","08/13/2021 11:42:48 - INFO - __main__ -   Iter = 900\n","08/13/2021 11:42:48 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/13/2021 11:42:48 - INFO - __main__ -   loss = 0.37147844026486077\n","08/13/2021 11:42:48 - INFO - __main__ -   Current data iter size: 2131\n","08/13/2021 11:42:48 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 11:43:04 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 11:43:04 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 11:43:04 - INFO - __main__ -     Batch size = 64\n","08/13/2021 11:51:00 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 11:51:00 - INFO - __main__ -     map = 0.7513068346927149\n","08/13/2021 11:51:01 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 82272 length of sample 16\n","08/13/2021 11:59:13 - INFO - __main__ -   Iter = 1200\n","08/13/2021 11:59:13 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/13/2021 11:59:13 - INFO - __main__ -   loss = 0.39622371112306914\n","08/13/2021 11:59:13 - INFO - __main__ -   Current data iter size: 2256\n","08/13/2021 11:59:13 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 11:59:31 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 11:59:31 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 11:59:31 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:07:25 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:07:25 - INFO - __main__ -     map = 0.7581351464605881\n","08/13/2021 12:07:27 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 82272 length of sample 0\n","08/13/2021 12:15:43 - INFO - __main__ -   Iter = 1500\n","08/13/2021 12:15:43 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/13/2021 12:15:43 - INFO - __main__ -   loss = 0.41351596797506013\n","08/13/2021 12:15:43 - INFO - __main__ -   Current data iter size: 2359\n","08/13/2021 12:15:43 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 12:15:59 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 12:15:59 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 12:15:59 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:23:54 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:23:54 - INFO - __main__ -     map = 0.7538023215874274\n","QC: length of D 82272 length of sample 0\n","08/13/2021 12:32:15 - INFO - __main__ -   Iter = 1800\n","08/13/2021 12:32:15 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/13/2021 12:32:15 - INFO - __main__ -   loss = 0.42891097322106364\n","08/13/2021 12:32:15 - INFO - __main__ -   Current data iter size: 2446\n","08/13/2021 12:32:15 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 12:32:33 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 12:32:33 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 12:32:33 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:40:29 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:40:29 - INFO - __main__ -     map = 0.7601117765091358\n","08/13/2021 12:40:31 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 82272 length of sample 0\n","08/13/2021 12:48:52 - INFO - __main__ -   Iter = 2100\n","08/13/2021 12:48:52 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/13/2021 12:48:52 - INFO - __main__ -   loss = 0.4387380083898703\n","08/13/2021 12:48:52 - INFO - __main__ -   Current data iter size: 2522\n","08/13/2021 12:48:52 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 12:49:09 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 12:49:09 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 12:49:09 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:57:05 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:57:05 - INFO - __main__ -     map = 0.7584517999416734\n","QC: length of D 82272 length of sample 0\n","08/13/2021 13:05:26 - INFO - __main__ -   Iter = 2400\n","08/13/2021 13:05:26 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/13/2021 13:05:26 - INFO - __main__ -   loss = 0.457860328356425\n","08/13/2021 13:05:26 - INFO - __main__ -   Current data iter size: 2571\n","08/13/2021 13:05:26 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 13:05:44 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 13:05:44 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 13:05:44 - INFO - __main__ -     Batch size = 64\n","08/13/2021 13:13:40 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 13:13:40 - INFO - __main__ -     map = 0.7616572693438227\n","08/13/2021 13:13:41 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 82272 length of sample 0\n","08/13/2021 13:18:29 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/13/2021 13:18:29 - INFO - __main__ -    global_step = 2572, average loss = 0.4210369458847895\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U_ityyQPJFB2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628945146950,"user_tz":-120,"elapsed":8579858,"user":{"displayName":"王梦琪","photoUrl":"","userId":"17110178610712270742"}},"outputId":"643285c3-0a95-40a8-efe7-6db5d931e76f"},"source":["!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 3\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_3 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.99\\\n","    --noise_difficult_ratio 0.5\\\n","    --eval_subsize 60000 \\"],"execution_count":4,"outputs":[{"output_type":"stream","text":["08/14/2021 10:22:46 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/14/2021 10:22:47 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmp1vfxew53\n","100% 433/433 [00:00<00:00, 415496.14B/s]\n","08/14/2021 10:22:47 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp1vfxew53 to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 10:22:47 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 10:22:47 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp1vfxew53\n","08/14/2021 10:22:47 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 10:22:47 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/14/2021 10:22:47 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpt5e9s05y\n","100% 231508/231508 [00:00<00:00, 913122.94B/s]\n","08/14/2021 10:22:48 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpt5e9s05y to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 10:22:48 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 10:22:48 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpt5e9s05y\n","08/14/2021 10:22:48 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 10:22:48 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpzeryfg9i\n","100% 440473133/440473133 [00:11<00:00, 39856209.26B/s]\n","08/14/2021 10:22:59 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpzeryfg9i to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 10:23:00 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 10:23:00 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpzeryfg9i\n","08/14/2021 10:23:01 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 10:23:03 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/14/2021 10:23:03 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/14/2021 10:23:15 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=0.5, noise_lambda=0.99, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_3', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3', save_aps=False, save_steps=5000, seed=3, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/14/2021 10:23:15 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/14/2021 10:23:37 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/14/2021 10:23:39 - INFO - __main__ -   ***** Running training *****\n","08/14/2021 10:23:39 - INFO - __main__ -     Num examples = 164544\n","08/14/2021 10:23:39 - INFO - __main__ -     Num Epochs = 1\n","08/14/2021 10:23:39 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/14/2021 10:23:39 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/14/2021 10:23:39 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/14/2021 10:23:39 - INFO - __main__ -     Total optimization steps = 2571\n","08/14/2021 10:23:39 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/14/2021 10:23:39 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7f5c64826850>)]\n","08/14/2021 10:23:39 - INFO - __main__ -   Starting epoch 1\n","08/14/2021 10:23:39 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/14/2021 10:31:42 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/14/2021 10:31:42 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/14/2021 10:31:42 - INFO - __main__ -   loss = 0.4979499618212382\n","08/14/2021 10:31:42 - INFO - __main__ -   Current data iter size: 1717\n","08/14/2021 10:31:42 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 10:32:02 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 10:32:02 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 10:32:02 - INFO - __main__ -     Batch size = 64\n","08/14/2021 10:40:24 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 10:40:24 - INFO - __main__ -     map = 0.7299901495323633\n","08/14/2021 10:40:25 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 82272 length of sample 5390\n","08/14/2021 10:48:52 - INFO - __main__ -   Iter = 600\n","08/14/2021 10:48:52 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/14/2021 10:48:52 - INFO - __main__ -   loss = 0.34628037303686143\n","08/14/2021 10:48:52 - INFO - __main__ -   Current data iter size: 1967\n","08/14/2021 10:48:52 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 10:49:09 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 10:49:09 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 10:49:09 - INFO - __main__ -     Batch size = 64\n","08/14/2021 10:57:30 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 10:57:30 - INFO - __main__ -     map = 0.7510166928653368\n","08/14/2021 10:57:32 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 82272 length of sample 302\n","08/14/2021 11:06:02 - INFO - __main__ -   Iter = 900\n","08/14/2021 11:06:02 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/14/2021 11:06:02 - INFO - __main__ -   loss = 0.3702498882512252\n","08/14/2021 11:06:02 - INFO - __main__ -   Current data iter size: 2131\n","08/14/2021 11:06:02 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 11:06:19 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 11:06:19 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 11:06:19 - INFO - __main__ -     Batch size = 64\n","08/14/2021 11:14:41 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 11:14:41 - INFO - __main__ -     map = 0.7593154908238209\n","08/14/2021 11:14:43 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 82272 length of sample 16\n","08/14/2021 11:23:13 - INFO - __main__ -   Iter = 1200\n","08/14/2021 11:23:13 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/14/2021 11:23:13 - INFO - __main__ -   loss = 0.4015711513658365\n","08/14/2021 11:23:13 - INFO - __main__ -   Current data iter size: 2256\n","08/14/2021 11:23:13 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 11:23:32 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 11:23:32 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 11:23:32 - INFO - __main__ -     Batch size = 64\n","08/14/2021 11:31:54 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 11:31:54 - INFO - __main__ -     map = 0.7575078739358656\n","QC: length of D 82272 length of sample 0\n","08/14/2021 11:40:25 - INFO - __main__ -   Iter = 1500\n","08/14/2021 11:40:25 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/14/2021 11:40:25 - INFO - __main__ -   loss = 0.4064400930702686\n","08/14/2021 11:40:25 - INFO - __main__ -   Current data iter size: 2359\n","08/14/2021 11:40:25 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 11:40:42 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 11:40:42 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 11:40:42 - INFO - __main__ -     Batch size = 64\n","08/14/2021 11:49:03 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 11:49:03 - INFO - __main__ -     map = 0.7613508147530288\n","08/14/2021 11:49:04 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 82272 length of sample 0\n","08/14/2021 11:57:38 - INFO - __main__ -   Iter = 1800\n","08/14/2021 11:57:38 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/14/2021 11:57:38 - INFO - __main__ -   loss = 0.4185567111770312\n","08/14/2021 11:57:38 - INFO - __main__ -   Current data iter size: 2446\n","08/14/2021 11:57:38 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 11:57:54 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 11:57:54 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 11:57:54 - INFO - __main__ -     Batch size = 64\n","08/14/2021 12:06:16 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 12:06:16 - INFO - __main__ -     map = 0.7605456244724045\n","QC: length of D 82272 length of sample 0\n","08/14/2021 12:14:50 - INFO - __main__ -   Iter = 2100\n","08/14/2021 12:14:50 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/14/2021 12:14:50 - INFO - __main__ -   loss = 0.4379255603750547\n","08/14/2021 12:14:50 - INFO - __main__ -   Current data iter size: 2522\n","08/14/2021 12:14:50 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 12:15:08 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 12:15:08 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 12:15:08 - INFO - __main__ -     Batch size = 64\n","08/14/2021 12:23:29 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 12:23:29 - INFO - __main__ -     map = 0.7609047810245464\n","QC: length of D 82272 length of sample 0\n","08/14/2021 12:32:05 - INFO - __main__ -   Iter = 2400\n","08/14/2021 12:32:05 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/14/2021 12:32:05 - INFO - __main__ -   loss = 0.46320596198240915\n","08/14/2021 12:32:05 - INFO - __main__ -   Current data iter size: 2571\n","08/14/2021 12:32:05 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 12:32:23 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 12:32:23 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 12:32:23 - INFO - __main__ -     Batch size = 64\n","08/14/2021 12:40:44 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 12:40:44 - INFO - __main__ -     map = 0.7702187254707532\n","08/14/2021 12:40:46 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_99_r_05_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 82272 length of sample 0\n","08/14/2021 12:45:43 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/14/2021 12:45:43 - INFO - __main__ -    global_step = 2572, average loss = 0.42071688729649753\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CUdGHOJQI9Iw"},"source":["# mantis root_5 with lamdba = 0.995, d_ratio = 0.5 noise"]},{"cell_type":"code","metadata":{"id":"i9mO0-xkjNg7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628852282376,"user_tz":-120,"elapsed":8106911,"user":{"displayName":"T. Z.","photoUrl":"","userId":"04670299702794629529"}},"outputId":"5aad1470-ddfa-4799-f8e8-c6ad7b86ae64"},"source":["# mantis root_5 \n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 1\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_1 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.995\\\n","    --noise_difficult_ratio 0.5\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/13/2021 08:43:00 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/13/2021 08:43:00 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpu5u_29c4\n","100% 433/433 [00:00<00:00, 474930.34B/s]\n","08/13/2021 08:43:01 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpu5u_29c4 to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 08:43:01 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 08:43:01 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpu5u_29c4\n","08/13/2021 08:43:01 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 08:43:01 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/13/2021 08:43:01 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpxj0qw1gb\n","100% 231508/231508 [00:00<00:00, 877359.44B/s]\n","08/13/2021 08:43:01 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpxj0qw1gb to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 08:43:01 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 08:43:01 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpxj0qw1gb\n","08/13/2021 08:43:01 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 08:43:02 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpawtg9yfm\n","100% 440473133/440473133 [00:11<00:00, 39633242.28B/s]\n","08/13/2021 08:43:13 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpawtg9yfm to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 08:43:14 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 08:43:14 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpawtg9yfm\n","08/13/2021 08:43:14 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 08:43:17 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/13/2021 08:43:17 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/13/2021 08:43:29 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=0.5, noise_lambda=0.995, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_1', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1', save_aps=False, save_steps=5000, seed=1, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/13/2021 08:43:29 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/13/2021 08:43:49 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/13/2021 08:43:51 - INFO - __main__ -   ***** Running training *****\n","08/13/2021 08:43:51 - INFO - __main__ -     Num examples = 164544\n","08/13/2021 08:43:51 - INFO - __main__ -     Num Epochs = 1\n","08/13/2021 08:43:51 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/13/2021 08:43:51 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/13/2021 08:43:51 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/13/2021 08:43:51 - INFO - __main__ -     Total optimization steps = 2571\n","08/13/2021 08:43:51 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/13/2021 08:43:51 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7fdcc92f88d0>)]\n","08/13/2021 08:43:51 - INFO - __main__ -   Starting epoch 1\n","08/13/2021 08:43:51 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/13/2021 08:51:45 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/13/2021 08:51:45 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/13/2021 08:51:45 - INFO - __main__ -   loss = 0.5803025013208389\n","08/13/2021 08:51:45 - INFO - __main__ -   Current data iter size: 1717\n","08/13/2021 08:51:45 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 08:52:05 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 08:52:05 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 08:52:05 - INFO - __main__ -     Batch size = 64\n","08/13/2021 08:59:52 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 08:59:52 - INFO - __main__ -     map = 0.7319675222138058\n","08/13/2021 08:59:54 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 82272 length of sample 24435\n","08/13/2021 09:07:56 - INFO - __main__ -   Iter = 600\n","08/13/2021 09:07:56 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/13/2021 09:07:56 - INFO - __main__ -   loss = 0.4157853279511134\n","08/13/2021 09:07:56 - INFO - __main__ -   Current data iter size: 1967\n","08/13/2021 09:07:56 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 09:08:12 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 09:08:12 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 09:08:12 - INFO - __main__ -     Batch size = 64\n","08/13/2021 09:16:00 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 09:16:00 - INFO - __main__ -     map = 0.7459665626403228\n","08/13/2021 09:16:01 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 82272 length of sample 6220\n","08/13/2021 09:24:05 - INFO - __main__ -   Iter = 900\n","08/13/2021 09:24:05 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/13/2021 09:24:05 - INFO - __main__ -   loss = 0.3845506432155768\n","08/13/2021 09:24:05 - INFO - __main__ -   Current data iter size: 2131\n","08/13/2021 09:24:05 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 09:24:21 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 09:24:21 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 09:24:21 - INFO - __main__ -     Batch size = 64\n","08/13/2021 09:32:09 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 09:32:09 - INFO - __main__ -     map = 0.7607725901899728\n","08/13/2021 09:32:11 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 82272 length of sample 1498\n","08/13/2021 09:40:18 - INFO - __main__ -   Iter = 1200\n","08/13/2021 09:40:18 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/13/2021 09:40:18 - INFO - __main__ -   loss = 0.39858784099419914\n","08/13/2021 09:40:18 - INFO - __main__ -   Current data iter size: 2256\n","08/13/2021 09:40:18 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 09:40:36 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 09:40:36 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 09:40:36 - INFO - __main__ -     Batch size = 64\n","08/13/2021 09:48:21 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 09:48:21 - INFO - __main__ -     map = 0.7589651209078311\n","QC: length of D 82272 length of sample 352\n","08/13/2021 09:56:28 - INFO - __main__ -   Iter = 1500\n","08/13/2021 09:56:28 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/13/2021 09:56:28 - INFO - __main__ -   loss = 0.4083957364658515\n","08/13/2021 09:56:28 - INFO - __main__ -   Current data iter size: 2359\n","08/13/2021 09:56:28 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 09:56:45 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 09:56:45 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 09:56:45 - INFO - __main__ -     Batch size = 64\n","08/13/2021 10:04:30 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 10:04:30 - INFO - __main__ -     map = 0.7641904966969509\n","08/13/2021 10:04:32 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 82272 length of sample 81\n","08/13/2021 10:12:40 - INFO - __main__ -   Iter = 1800\n","08/13/2021 10:12:40 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/13/2021 10:12:40 - INFO - __main__ -   loss = 0.4233516148726145\n","08/13/2021 10:12:40 - INFO - __main__ -   Current data iter size: 2446\n","08/13/2021 10:12:40 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 10:12:56 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 10:12:56 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 10:12:56 - INFO - __main__ -     Batch size = 64\n","08/13/2021 10:20:43 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 10:20:43 - INFO - __main__ -     map = 0.7647047949570972\n","08/13/2021 10:20:45 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 82272 length of sample 18\n","08/13/2021 10:28:55 - INFO - __main__ -   Iter = 2100\n","08/13/2021 10:28:55 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/13/2021 10:28:55 - INFO - __main__ -   loss = 0.4393889363606771\n","08/13/2021 10:28:55 - INFO - __main__ -   Current data iter size: 2522\n","08/13/2021 10:28:55 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 10:29:12 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 10:29:12 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 10:29:12 - INFO - __main__ -     Batch size = 64\n","08/13/2021 10:36:59 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 10:36:59 - INFO - __main__ -     map = 0.7666257791123178\n","08/13/2021 10:37:00 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 82272 length of sample 4\n","08/13/2021 10:45:11 - INFO - __main__ -   Iter = 2400\n","08/13/2021 10:45:11 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/13/2021 10:45:11 - INFO - __main__ -   loss = 0.45370763311783474\n","08/13/2021 10:45:11 - INFO - __main__ -   Current data iter size: 2571\n","08/13/2021 10:45:11 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 10:45:29 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 10:45:29 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 10:45:29 - INFO - __main__ -     Batch size = 64\n","08/13/2021 10:53:16 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 10:53:16 - INFO - __main__ -     map = 0.7769085179969356\n","08/13/2021 10:53:18 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_1/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_1\n","QC: length of D 82272 length of sample 0\n","08/13/2021 10:57:59 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/13/2021 10:58:00 - INFO - __main__ -    global_step = 2572, average loss = 0.4397081668440884\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bPPm7l4vz_4E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628860560545,"user_tz":-120,"elapsed":8068005,"user":{"displayName":"T. Z.","photoUrl":"","userId":"04670299702794629529"}},"outputId":"ced49eea-058e-43f7-8724-e8f092ffa364"},"source":["# mantis root_5 \n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 2\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_2 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.995\\\n","    --noise_difficult_ratio 0.5\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/13/2021 11:01:33 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/13/2021 11:01:34 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/13/2021 11:01:34 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/13/2021 11:01:34 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/13/2021 11:01:34 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/13/2021 11:01:49 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/13/2021 11:01:49 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/13/2021 11:01:53 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=0.5, noise_lambda=0.995, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_2', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2', save_aps=False, save_steps=5000, seed=2, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/13/2021 11:01:53 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/13/2021 11:02:12 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/13/2021 11:02:15 - INFO - __main__ -   ***** Running training *****\n","08/13/2021 11:02:15 - INFO - __main__ -     Num examples = 164544\n","08/13/2021 11:02:15 - INFO - __main__ -     Num Epochs = 1\n","08/13/2021 11:02:15 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/13/2021 11:02:15 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/13/2021 11:02:15 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/13/2021 11:02:15 - INFO - __main__ -     Total optimization steps = 2571\n","08/13/2021 11:02:15 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/13/2021 11:02:15 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7f54c7781ed0>)]\n","08/13/2021 11:02:15 - INFO - __main__ -   Starting epoch 1\n","08/13/2021 11:02:15 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/13/2021 11:10:05 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/13/2021 11:10:05 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/13/2021 11:10:05 - INFO - __main__ -   loss = 0.5786867215236028\n","08/13/2021 11:10:05 - INFO - __main__ -   Current data iter size: 1717\n","08/13/2021 11:10:05 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 11:10:23 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 11:10:23 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 11:10:23 - INFO - __main__ -     Batch size = 64\n","08/13/2021 11:18:10 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 11:18:10 - INFO - __main__ -     map = 0.7345798016890157\n","08/13/2021 11:18:12 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 82272 length of sample 24435\n","08/13/2021 11:26:13 - INFO - __main__ -   Iter = 600\n","08/13/2021 11:26:13 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/13/2021 11:26:13 - INFO - __main__ -   loss = 0.4095076061785221\n","08/13/2021 11:26:13 - INFO - __main__ -   Current data iter size: 1967\n","08/13/2021 11:26:13 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 11:26:30 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 11:26:30 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 11:26:30 - INFO - __main__ -     Batch size = 64\n","08/13/2021 11:34:15 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 11:34:15 - INFO - __main__ -     map = 0.7468705341813608\n","08/13/2021 11:34:17 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 82272 length of sample 6220\n","08/13/2021 11:42:19 - INFO - __main__ -   Iter = 900\n","08/13/2021 11:42:19 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/13/2021 11:42:19 - INFO - __main__ -   loss = 0.38503631045420966\n","08/13/2021 11:42:19 - INFO - __main__ -   Current data iter size: 2131\n","08/13/2021 11:42:19 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 11:42:35 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 11:42:35 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 11:42:35 - INFO - __main__ -     Batch size = 64\n","08/13/2021 11:50:21 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 11:50:21 - INFO - __main__ -     map = 0.7425327989230138\n","QC: length of D 82272 length of sample 1498\n","08/13/2021 11:58:25 - INFO - __main__ -   Iter = 1200\n","08/13/2021 11:58:25 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/13/2021 11:58:25 - INFO - __main__ -   loss = 0.4092900811135769\n","08/13/2021 11:58:25 - INFO - __main__ -   Current data iter size: 2256\n","08/13/2021 11:58:25 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 11:58:42 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 11:58:42 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 11:58:42 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:06:26 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:06:26 - INFO - __main__ -     map = 0.7582432919772533\n","08/13/2021 12:06:28 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 82272 length of sample 352\n","08/13/2021 12:14:34 - INFO - __main__ -   Iter = 1500\n","08/13/2021 12:14:34 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/13/2021 12:14:34 - INFO - __main__ -   loss = 0.4181209498643875\n","08/13/2021 12:14:34 - INFO - __main__ -   Current data iter size: 2359\n","08/13/2021 12:14:34 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 12:14:50 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 12:14:50 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 12:14:50 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:22:34 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:22:34 - INFO - __main__ -     map = 0.7621767095838957\n","08/13/2021 12:22:35 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 82272 length of sample 81\n","08/13/2021 12:30:42 - INFO - __main__ -   Iter = 1800\n","08/13/2021 12:30:42 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/13/2021 12:30:42 - INFO - __main__ -   loss = 0.4353509923815727\n","08/13/2021 12:30:42 - INFO - __main__ -   Current data iter size: 2446\n","08/13/2021 12:30:42 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 12:30:59 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 12:30:59 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 12:30:59 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:38:43 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:38:43 - INFO - __main__ -     map = 0.7616900465828815\n","QC: length of D 82272 length of sample 18\n","08/13/2021 12:46:54 - INFO - __main__ -   Iter = 2100\n","08/13/2021 12:46:54 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/13/2021 12:46:54 - INFO - __main__ -   loss = 0.44332943300406136\n","08/13/2021 12:46:54 - INFO - __main__ -   Current data iter size: 2522\n","08/13/2021 12:46:54 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 12:47:12 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 12:47:12 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 12:47:12 - INFO - __main__ -     Batch size = 64\n","08/13/2021 12:54:58 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 12:54:58 - INFO - __main__ -     map = 0.7539789200350603\n","QC: length of D 82272 length of sample 4\n","08/13/2021 13:03:09 - INFO - __main__ -   Iter = 2400\n","08/13/2021 13:03:09 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/13/2021 13:03:09 - INFO - __main__ -   loss = 0.45774928033351897\n","08/13/2021 13:03:09 - INFO - __main__ -   Current data iter size: 2571\n","08/13/2021 13:03:09 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/13/2021 13:03:26 - INFO - __main__ -   ***** Running evaluation  *****\n","08/13/2021 13:03:26 - INFO - __main__ -     Num examples = 60000\n","08/13/2021 13:03:26 - INFO - __main__ -     Batch size = 64\n","08/13/2021 13:11:14 - INFO - __main__ -   ***** Eval results  *****\n","08/13/2021 13:11:14 - INFO - __main__ -     map = 0.7655981017091389\n","08/13/2021 13:11:15 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_2/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_2\n","QC: length of D 82272 length of sample 0\n","08/13/2021 13:15:58 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/13/2021 13:15:58 - INFO - __main__ -    global_step = 2572, average loss = 0.44339266804106314\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Dotnsb3BJwiA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628941247389,"user_tz":-120,"elapsed":8704229,"user":{"displayName":"xiaokang qian","photoUrl":"","userId":"16136989389156139825"}},"outputId":"3dffeaad-3f72-4abb-e689-80d71e4f8eee"},"source":["!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 3\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_3 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.995\\\n","    --noise_difficult_ratio 0.5\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/14/2021 09:15:47 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/14/2021 09:15:47 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpbl747h5c\n","100% 433/433 [00:00<00:00, 413792.12B/s]\n","08/14/2021 09:15:47 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpbl747h5c to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 09:15:47 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 09:15:47 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpbl747h5c\n","08/14/2021 09:15:47 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","08/14/2021 09:15:47 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"mantis_10\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","08/14/2021 09:15:48 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmppm4dbyvi\n","100% 231508/231508 [00:00<00:00, 873284.76B/s]\n","08/14/2021 09:15:48 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmppm4dbyvi to cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 09:15:48 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 09:15:48 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmppm4dbyvi\n","08/14/2021 09:15:48 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","08/14/2021 09:15:48 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmplqj821f6\n","100% 440473133/440473133 [00:11<00:00, 38399462.91B/s]\n","08/14/2021 09:16:00 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmplqj821f6 to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 09:16:02 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 09:16:02 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmplqj821f6\n","08/14/2021 09:16:02 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","08/14/2021 09:16:04 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","08/14/2021 09:16:04 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","08/14/2021 09:16:16 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', curriculum_file='drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3', data_dir='drive/MyDrive/Mantis', debug_mode=False, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, eval_all_checkpoints=True, eval_difficult=False, eval_subsize=60000, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, invert_cl_values=True, learning_rate=2e-05, local_rank=-1, logging_steps=300, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, noise_difficult_ratio=0.5, noise_lambda=0.995, num_train_epochs=1.0, output_dir='drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_3', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, pacing_function='root_5', per_gpu_eval_batch_size=64, per_gpu_train_batch_size=64, percentage_data_by_epoch=1.0, reset_clf_weights=False, run_name='run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3', save_aps=False, save_steps=5000, seed=3, server_ip='', server_port='', task_name='mantis_10', tokenizer_name='', use_additive_cl=True, warmup_steps=0, weight_decay=0.0)\n","08/14/2021 09:16:16 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_train_bert-base-uncased_128_mantis_10\n","08/14/2021 09:16:37 - INFO - __main__ -   Using curriculum scoring values from file drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3\n","08/14/2021 09:16:40 - INFO - __main__ -   ***** Running training *****\n","08/14/2021 09:16:40 - INFO - __main__ -     Num examples = 164544\n","08/14/2021 09:16:40 - INFO - __main__ -     Num Epochs = 1\n","08/14/2021 09:16:40 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","08/14/2021 09:16:40 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","08/14/2021 09:16:40 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/14/2021 09:16:40 - INFO - __main__ -     Total optimization steps = 2571\n","08/14/2021 09:16:40 - INFO - __main__ -     percentage by epoch = 1.000000\n","08/14/2021 09:16:40 - INFO - __main__ -     data_loaders = [('pacing_function_root_5', <torch.utils.data.dataloader.DataLoader object at 0x7f26f5a1fed0>)]\n","08/14/2021 09:16:40 - INFO - __main__ -   Starting epoch 1\n","08/14/2021 09:16:40 - INFO - __main__ -   Training with pacing_function_root_5\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","08/14/2021 09:24:59 - INFO - __main__ -   Iter = 300\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","08/14/2021 09:24:59 - INFO - __main__ -   lr = 1.766627771295216e-05\n","08/14/2021 09:24:59 - INFO - __main__ -   loss = 0.5810278496146202\n","08/14/2021 09:24:59 - INFO - __main__ -   Current data iter size: 1717\n","08/14/2021 09:24:59 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 09:25:20 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 09:25:20 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 09:25:20 - INFO - __main__ -     Batch size = 64\n","08/14/2021 09:33:51 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 09:33:51 - INFO - __main__ -     map = 0.7149825458937508\n","08/14/2021 09:33:52 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 82272 length of sample 24435\n","08/14/2021 09:42:25 - INFO - __main__ -   Iter = 600\n","08/14/2021 09:42:25 - INFO - __main__ -   lr = 1.5332555425904317e-05\n","08/14/2021 09:42:25 - INFO - __main__ -   loss = 0.4129712627331416\n","08/14/2021 09:42:25 - INFO - __main__ -   Current data iter size: 1967\n","08/14/2021 09:42:25 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 09:42:42 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 09:42:42 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 09:42:42 - INFO - __main__ -     Batch size = 64\n","08/14/2021 09:51:11 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 09:51:11 - INFO - __main__ -     map = 0.7504909172478736\n","08/14/2021 09:51:12 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 82272 length of sample 6220\n","08/14/2021 09:59:47 - INFO - __main__ -   Iter = 900\n","08/14/2021 09:59:47 - INFO - __main__ -   lr = 1.2998833138856476e-05\n","08/14/2021 09:59:47 - INFO - __main__ -   loss = 0.384313325881958\n","08/14/2021 09:59:47 - INFO - __main__ -   Current data iter size: 2131\n","08/14/2021 09:59:47 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 10:00:04 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 10:00:04 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 10:00:04 - INFO - __main__ -     Batch size = 64\n","08/14/2021 10:08:33 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 10:08:33 - INFO - __main__ -     map = 0.756606130763996\n","08/14/2021 10:08:34 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 82272 length of sample 1498\n","08/14/2021 10:17:11 - INFO - __main__ -   Iter = 1200\n","08/14/2021 10:17:11 - INFO - __main__ -   lr = 1.0665110851808636e-05\n","08/14/2021 10:17:11 - INFO - __main__ -   loss = 0.40003198514382043\n","08/14/2021 10:17:11 - INFO - __main__ -   Current data iter size: 2256\n","08/14/2021 10:17:11 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 10:17:29 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 10:17:29 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 10:17:29 - INFO - __main__ -     Batch size = 64\n","08/14/2021 10:25:57 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 10:25:57 - INFO - __main__ -     map = 0.760605048364998\n","08/14/2021 10:25:59 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 82272 length of sample 352\n","08/14/2021 10:34:37 - INFO - __main__ -   Iter = 1500\n","08/14/2021 10:34:37 - INFO - __main__ -   lr = 8.331388564760793e-06\n","08/14/2021 10:34:37 - INFO - __main__ -   loss = 0.41285388454794886\n","08/14/2021 10:34:37 - INFO - __main__ -   Current data iter size: 2359\n","08/14/2021 10:34:37 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 10:34:53 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 10:34:53 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 10:34:53 - INFO - __main__ -     Batch size = 64\n","08/14/2021 10:43:21 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 10:43:21 - INFO - __main__ -     map = 0.7601882353490987\n","QC: length of D 82272 length of sample 81\n","08/14/2021 10:52:01 - INFO - __main__ -   Iter = 1800\n","08/14/2021 10:52:01 - INFO - __main__ -   lr = 5.9976662777129524e-06\n","08/14/2021 10:52:01 - INFO - __main__ -   loss = 0.42833694751063983\n","08/14/2021 10:52:01 - INFO - __main__ -   Current data iter size: 2446\n","08/14/2021 10:52:01 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 10:52:17 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 10:52:17 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 10:52:17 - INFO - __main__ -     Batch size = 64\n","08/14/2021 11:00:45 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 11:00:45 - INFO - __main__ -     map = 0.7673447675736618\n","08/14/2021 11:00:47 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 82272 length of sample 18\n","08/14/2021 11:09:29 - INFO - __main__ -   Iter = 2100\n","08/14/2021 11:09:29 - INFO - __main__ -   lr = 3.6639439906651113e-06\n","08/14/2021 11:09:29 - INFO - __main__ -   loss = 0.44084478278954825\n","08/14/2021 11:09:29 - INFO - __main__ -   Current data iter size: 2522\n","08/14/2021 11:09:29 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 11:09:46 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 11:09:46 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 11:09:46 - INFO - __main__ -     Batch size = 64\n","08/14/2021 11:18:14 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 11:18:14 - INFO - __main__ -     map = 0.7626425078193134\n","QC: length of D 82272 length of sample 4\n","08/14/2021 11:26:56 - INFO - __main__ -   Iter = 2400\n","08/14/2021 11:26:56 - INFO - __main__ -   lr = 1.3302217036172696e-06\n","08/14/2021 11:26:56 - INFO - __main__ -   loss = 0.4513220287362735\n","08/14/2021 11:26:56 - INFO - __main__ -   Current data iter size: 2571\n","08/14/2021 11:26:56 - INFO - __main__ -   Loading features from cached file drive/MyDrive/Mantis/cached_dev_bert-base-uncased_128_mantis_10\n","08/14/2021 11:27:14 - INFO - __main__ -   ***** Running evaluation  *****\n","08/14/2021 11:27:14 - INFO - __main__ -     Num examples = 60000\n","08/14/2021 11:27:14 - INFO - __main__ -     Batch size = 64\n","08/14/2021 11:35:42 - INFO - __main__ -   ***** Eval results  *****\n","08/14/2021 11:35:42 - INFO - __main__ -     map = 0.7706125299373219\n","08/14/2021 11:35:43 - INFO - __main__ -   Saving best model so far to drive/MyDrive/transformers_cl/mantis_root5_l_995_r_05_seed_3/checkpoint-best_run_cl__bert_bm25_8/preds_dif_c_values_3root_5_seed_3\n","QC: length of D 82272 length of sample 0\n","08/14/2021 11:40:43 - INFO - __main__ -   Finished epoch with 2571 iterations.\n","08/14/2021 11:40:43 - INFO - __main__ -    global_step = 2572, average loss = 0.4402416199793341\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"q48JUnLsI9gv"},"source":["# mantis root_5 with lamdba = 0.999, d_ratio = 0.5 noise \n","# the noise data size of starting iterations can be bigger than 0.5, even 0.6, so this cannot be run...."]},{"cell_type":"code","metadata":{"id":"zsgh1dgdjQLm"},"source":["# mantis root_5 \n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 1\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_999_r_05_seed_1 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.999\\\n","    --noise_difficult_ratio 0.5\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_CKvwGhoKIZv"},"source":["# mantis root_5 \n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 2\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_999_r_05_seed_2 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.999\\\n","    --noise_difficult_ratio 0.5\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vp0DZQh5KJHu"},"source":["# mantis root_5 \n","!python drive/MyDrive/transformers_cl/run_glue_noise.py \\\n","    --model_type bert \\\n","    --model_name_or_path bert-base-uncased \\\n","    --task_name  mantis_10 \\\n","    --do_train \\\n","    --evaluate_during_training \\\n","    --do_lower_case \\\n","    --data_dir drive/MyDrive/Mantis \\\n","    --max_seq_length 128 \\\n","    --per_gpu_eval_batch_size=64   \\\n","    --per_gpu_train_batch_size=64   \\\n","    --learning_rate 2e-5 \\\n","    --num_train_epochs 1 \\\n","    --seed 3\\\n","    --output_dir drive/MyDrive/transformers_cl/mantis_root5_l_999_r_05_seed_3 \\\n","    --logging_steps 300 \\\n","    --curriculum_file  drive/MyDrive/transformers_cl/mantis_10_bert_bm25_8/preds_dif_c_values_3 \\\n","    --pacing_function root_5\\\n","    --use_additive_cl \\\n","    --eval_all_checkpoints \\\n","    --invert_cl_values\\\n","    --noise_lambda 0.999\\\n","    --noise_difficult_ratio 0.5\\\n","    --eval_subsize 60000 \\"],"execution_count":null,"outputs":[]}]}